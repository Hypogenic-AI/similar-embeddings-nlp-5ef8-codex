Reading prompt from stdin...
{"type":"thread.started","thread_id":"019c6419-7554-79c2-bd7e-3aa5a90720fe"}
{"type":"turn.started"}
{"type":"item.completed","item":{"id":"item_0","type":"reasoning","text":"**Starting environment setup**"}}
{"type":"item.started","item":{"id":"item_1","type":"command_execution","command":"/bin/bash -lc pwd","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_1","type":"command_execution","command":"/bin/bash -lc pwd","aggregated_output":"/data/hypogenicai/workspaces/similar-embeddings-nlp-5ef8-codex\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_2","type":"command_execution","command":"/bin/bash -lc 'nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv 2>/dev/null || echo \"NO_GPU\"'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_2","type":"command_execution","command":"/bin/bash -lc 'nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv 2>/dev/null || echo \"NO_GPU\"'","aggregated_output":"name, memory.total [MiB], memory.free [MiB]\nNVIDIA GeForce RTX 3090, 24576 MiB, 24161 MiB\nNVIDIA GeForce RTX 3090, 24576 MiB, 24161 MiB\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_3","type":"reasoning","text":"**Checking environment setup**"}}
{"type":"item.started","item":{"id":"item_4","type":"command_execution","command":"/bin/bash -lc 'ls -a'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_4","type":"command_execution","command":"/bin/bash -lc 'ls -a'","aggregated_output":".\n..\n.claude\n.codex\n.gemini\n.git\n.gitignore\n.idea-explorer\n.resource_finder_complete\n.venv\nREADME.md\nartifacts\ncode\ndatasets\nliterature_review.md\nlogs\npaper_search_results\npapers\npyproject.toml\nresources.md\nresults\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_5","type":"reasoning","text":"**Preparing to read documentation before experiments**\n\nPlanning to activate the virtual environment inline with commands to install dependencies later while first reading literature_review.md and resources.md for context."}}
{"type":"item.started","item":{"id":"item_6","type":"command_execution","command":"/bin/bash -lc \"sed -n '1,200p' literature_review.md\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_6","type":"command_execution","command":"/bin/bash -lc \"sed -n '1,200p' literature_review.md\"","aggregated_output":"# Literature Review\n\n## Research Area Overview\nThis project studies whether words with similar meanings across languages have similar embeddings, especially in multilingual models and in the presence of polysemy. The literature spans cross-lingual word embedding alignment (static embeddings) and multilingual contextual representation learning, plus sense-aware benchmarks (WiC variants) that explicitly test meaning consistency across languages.\n\n## Key Papers\n\n### Word Translation Without Parallel Data (Conneau et al., 2017)\n- Authors: Conneau et al.\n- Year: 2017\n- Source: arXiv:1710.04087\n- Key Contribution: Unsupervised and supervised alignment methods (MUSE) for mapping monolingual embeddings into a shared space.\n- Methodology: Adversarial training + Procrustes refinement; dictionary induction with CSLS.\n- Datasets Used: MUSE bilingual dictionaries; fastText monolingual embeddings.\n- Results: Strong bilingual lexicon induction without parallel data.\n- Code Available: Yes (MUSE).\n- Relevance to Our Research: Provides baseline for measuring cross-lingual similarity of word embeddings.\n\n### A robust self-learning method for fully unsupervised cross-lingual mappings of word embeddings (Artetxe et al., 2018)\n- Authors: Artetxe et al.\n- Year: 2018\n- Source: ACL 2018 (P18-1073)\n- Key Contribution: Self-learning framework for unsupervised cross-lingual mapping (VecMap).\n- Methodology: Iterative refinement with dictionary induction, normalization, and CSLS.\n- Datasets Used: Bilingual dictionaries and word translation benchmarks.\n- Results: Competitive unsupervised alignment across language pairs.\n- Code Available: Yes (VecMap).\n- Relevance to Our Research: Strong baseline for cross-lingual alignment of static embeddings.\n\n### Cross-lingual alignment of contextual word embeddings (Schuster et al., 2019)\n- Authors: Schuster et al.\n- Year: 2019\n- Source: arXiv:1902.09492\n- Key Contribution: Aligns contextual embeddings across languages; demonstrates zero-shot dependency parsing gains.\n- Methodology: Learn a linear mapping between contextual embedding spaces using parallel data.\n- Datasets Used: Parallel corpora and UD parsing benchmarks.\n- Results: Improved cross-lingual transfer with aligned contextual representations.\n- Code Available: Not primary; references standard toolchains.\n- Relevance to Our Research: Directly addresses cross-lingual similarity of contextual embeddings.\n\n### Context-Aware Cross-Lingual Mapping (Aldarmaki and Diab, 2019)\n- Authors: Aldarmaki and Diab\n- Year: 2019\n- Source: arXiv:1903.03243\n- Key Contribution: Context-aware mapping to address sense variation in cross-lingual embeddings.\n- Methodology: Learn mappings using contextualized representations; evaluate alignment quality.\n- Datasets Used: Cross-lingual lexical tasks and contextual datasets.\n- Results: Improved mapping when context is considered.\n- Code Available: Not central; paper focuses on approach.\n- Relevance to Our Research: Aligns with hypothesis about polysemy and embedding similarity.\n\n### Cross-lingual Language Model Pretraining (Lample and Conneau, 2019)\n- Authors: Lample and Conneau\n- Year: 2019\n- Source: arXiv:1901.07291\n- Key Contribution: XLM introduces MLM and TLM objectives for cross-lingual pretraining.\n- Methodology: Transformer pretraining with multilingual corpora; use of parallel data for TLM.\n- Datasets Used: Wikipedia, parallel corpora; evaluation on XNLI and MT.\n- Results: Strong cross-lingual transfer; improved multilingual representations.\n- Code Available: Yes (XLM).\n- Relevance to Our Research: Provides multilingual contextual embeddings for similarity tests.\n\n### Unsupervised Cross-lingual Representation Learning at Scale (Conneau et al., 2019)\n- Authors: Conneau et al.\n- Year: 2019\n- Source: arXiv:1911.02116\n- Key Contribution: XLM-R scales multilingual pretraining without parallel data.\n- Methodology: Large-scale masked LM on multilingual corpora.\n- Datasets Used: CommonCrawl corpora; evaluation on XNLI, MLQA, etc.\n- Results: State-of-the-art multilingual performance.\n- Code Available: Yes (via XLM repo / later Hugging Face models).\n- Relevance to Our Research: Key multilingual model family for embedding similarity analysis.\n\n### Towards Multi-Sense Cross-Lingual Alignment of Contextual Embeddings (Liu et al., 2022)\n- Authors: Liu et al.\n- Year: 2022\n- Source: COLING 2022\n- Key Contribution: Explicit multi-sense alignment for contextual embeddings across languages.\n- Methodology: Sense-aware alignment objectives; evaluation on sense disambiguation tasks.\n- Datasets Used: Sense-aware benchmarks (WiC-style datasets).\n- Results: Better alignment for polysemous words.\n- Code Available: Not central; paper details method.\n- Relevance to Our Research: Directly investigates polysemy and cross-lingual embedding similarity.\n\n### XL-WiC: A Multilingual Benchmark for Word-in-Context Disambiguation (Raganato et al., 2020)\n- Authors: Raganato et al.\n- Year: 2020\n- Source: arXiv:2010.06478\n- Key Contribution: Introduces XL-WiC benchmark spanning multiple languages.\n- Methodology: Word-in-context classification using multilingual datasets.\n- Datasets Used: XL-WiC dataset (WordNet and Wiktionary variants).\n- Results: Establishes baseline performance across languages.\n- Code Available: Yes (dataset and scorer).\n- Relevance to Our Research: Provides evaluation for cross-lingual sense consistency.\n\n### SemEval-2021 Task 2: MCL-WiC (Martelli et al., 2021)\n- Authors: Martelli et al.\n- Year: 2021\n- Source: SemEval 2021\n- Key Contribution: Defines multilingual and cross-lingual WiC task with shared benchmarks.\n- Methodology: Task setup and evaluation for multilingual/cross-lingual sense disambiguation.\n- Datasets Used: MCL-WiC dataset.\n- Results: Task baselines and shared-task outcomes.\n- Code Available: Dataset in task repo.\n- Relevance to Our Research: Primary dataset for cross-lingual sense alignment evaluation.\n\n## Common Methodologies\n- Linear mapping of embedding spaces using Procrustes alignment and CSLS retrieval.\n- Self-learning / iterative dictionary induction for unsupervised alignment.\n- Contextual embedding alignment using parallel data or shared multilingual pretraining.\n- Sense-aware evaluation with WiC-style binary classification tasks.\n\n## Standard Baselines\n- Procrustes alignment with bilingual dictionaries (supervised MUSE / VecMap).\n- Unsupervised alignment with adversarial initialization + CSLS refinement.\n- Multilingual contextual models (XLM, XLM-R) without explicit alignment.\n\n## Evaluation Metrics\n- Bilingual lexicon induction accuracy (top-1/top-5 translation retrieval).\n- Cross-lingual word similarity (Spearman correlation on word pair similarity tasks).\n- WiC accuracy or F1 on sense disambiguation tasks.\n\n## Datasets in the Literature\n- MUSE bilingual dictionaries for word translation and mapping evaluation.\n- XL-WiC for multilingual word-in-context disambiguation.\n- MCL-WiC for multilingual and cross-lingual sense disambiguation.\n\n## Gaps and Opportunities\n- Limited analysis of how polysemy affects alignment quality across languages in multilingual models.\n- Few direct comparisons between static alignment methods and contextual multilingual models on identical sense-focused tasks.\n\n## Recommendations for Our Experiment\n- Recommended datasets: MUSE dictionaries for translation-based similarity; XL-WiC and MCL-WiC for sense-sensitive evaluation.\n- Recommended baselines: MUSE supervised and unsupervised alignment; VecMap unsupervised mapping; XLM/XLM-R contextual embeddings.\n- Recommended metrics: Translation retrieval accuracy; WiC accuracy; cross-lingual similarity correlations.\n- Methodological considerations: Control for polysemy by grouping by sense; compare static vs contextual embeddings under identical evaluation protocol.\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_7","type":"reasoning","text":"**Noting missing documentation file**"}}
{"type":"item.started","item":{"id":"item_8","type":"command_execution","command":"/bin/bash -lc \"sed -n '1,200p' resources.md\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_8","type":"command_execution","command":"/bin/bash -lc \"sed -n '1,200p' resources.md\"","aggregated_output":"# Resources Catalog\n\n## Summary\nThis document catalogs all resources gathered for the research project, including papers, datasets, and code repositories.\n\n## Papers\nTotal papers downloaded: 9\n\n| Title | Authors | Year | File | Key Info |\n|---|---|---|---|---|\n| Word Translation Without Parallel Data | Conneau et al. | 2017 | papers/2017_conneau_word_translation_without_parallel_data.pdf | Unsupervised/supervised alignment (MUSE) |\n| A robust self-learning method for fully unsupervised cross-lingual mappings of word embeddings | Artetxe et al. | 2018 | papers/2018_artetxe_robust_self_learning.pdf | VecMap baseline |\n| Cross-lingual alignment of contextual word embeddings | Schuster et al. | 2019 | papers/2019_schuster_cross_lingual_alignment_contextual_embeddings.pdf | Contextual alignment |\n| Context-Aware Cross-Lingual Mapping | Aldarmaki and Diab | 2019 | papers/2019_aldarmaki_context_aware_cross_lingual_mapping.pdf | Context-aware mapping |\n| Cross-lingual Language Model Pretraining (XLM) | Lample and Conneau | 2019 | papers/2019_lample_conneau_xlm.pdf | Multilingual pretraining |\n| Unsupervised Cross-lingual Representation Learning at Scale (XLM-R) | Conneau et al. | 2019 | papers/2019_conneau_xlm_r.pdf | Large-scale multilingual model |\n| Towards Multi-Sense Cross-Lingual Alignment of Contextual Embeddings | Liu et al. | 2022 | papers/2022_liu_multi_sense_cross_lingual_alignment.pdf | Sense-aware alignment |\n| XL-WiC: A Multilingual Benchmark for Word-in-Context Disambiguation | Raganato et al. | 2020 | papers/2020_xlwic.pdf | WiC benchmark |\n| SemEval-2021 Task 2: Multilingual and Cross-lingual Word-in-Context Disambiguation | Martelli et al. | 2021 | papers/2021_mcl_wic_task.pdf | Task definition and dataset |\n\nSee papers/README.md for detailed descriptions.\n\n## Datasets\nTotal datasets downloaded: 3\n\n| Name | Source | Size | Task | Location | Notes |\n|---|---|---|---|---|---|\n| MUSE Dictionaries | MUSE (Facebook Research) | ~103 MB extracted | Bilingual lexicon induction | datasets/muse_dictionaries/ | 110 dictionaries across language pairs |\n| XL-WiC | XL-WiC project site | ~32 MB extracted | Word-in-context disambiguation | datasets/xlwic/ | WordNet and Wiktionary variants |\n| MCL-WiC | SapienzaNLP | ~8 MB extracted | Multilingual/cross-lingual WiC | datasets/mcl_wic/ | SemEval-2021 Task 2 |\n\nSee datasets/README.md for detailed descriptions.\n\n## Code Repositories\nTotal repositories cloned: 3\n\n| Name | URL | Purpose | Location | Notes |\n|---|---|---|---|---|\n| MUSE | https://github.com/facebookresearch/MUSE | Unsupervised/supervised alignment | code/muse/ | Includes dictionaries and evaluation scripts |\n| VecMap | https://github.com/artetxem/vecmap | Cross-lingual mapping baseline | code/vecmap/ | Strong unsupervised baseline |\n| XLM | https://github.com/facebookresearch/XLM | Multilingual pretraining | code/xlm/ | Includes XLM/XLM-R references |\n\nSee code/README.md for detailed descriptions.\n\n## Resource Gathering Notes\n\nSearch Strategy\n- Attempted paper-finder (service unavailable/timeout), then used targeted manual search for cross-lingual embedding alignment and multilingual contextual models.\n- Prioritized foundational alignment methods and sense-focused benchmarks.\n\nSelection Criteria\n- Direct relevance to cross-lingual embedding similarity and polysemy.\n- Widely used baselines with available code.\n- Benchmarks that evaluate sense consistency across languages.\n\nChallenges Encountered\n- The full MUSE aligned vectors archive is very large (~6.7 GB). Only dictionaries were downloaded.\n\nGaps and Workarounds\n- Did not download aligned vectors; use dictionaries with local fastText vectors or smaller language subsets if needed.\n\n## Recommendations for Experiment Design\n\n1. Primary dataset(s): MUSE dictionaries for translation-based similarity; XL-WiC and MCL-WiC for sense-aware evaluation.\n2. Baseline methods: MUSE supervised and unsupervised alignment; VecMap unsupervised mapping; contextual embeddings from XLM/XLM-R.\n3. Evaluation metrics: Translation retrieval accuracy; WiC accuracy/F1; cross-lingual similarity correlation.\n4. Code to adapt/reuse: MUSE and VecMap for alignment baselines; XLM for contextual embedding extraction.\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_9","type":"reasoning","text":"**Checking existence of planning.md**"}}
{"type":"item.started","item":{"id":"item_10","type":"command_execution","command":"/bin/bash -lc 'ls planning.md 2>/dev/null || echo \"NO_PLANNING\"'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_10","type":"command_execution","command":"/bin/bash -lc 'ls planning.md 2>/dev/null || echo \"NO_PLANNING\"'","aggregated_output":"NO_PLANNING\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_11","type":"reasoning","text":"**Planning documentation setup**"}}
{"type":"item.started","item":{"id":"item_12","type":"command_execution","command":"/bin/bash -lc \"cat > planning.md << 'EOF'\n## Motivation & Novelty Assessment\n\n### Why This Research Matters\nMultilingual models are widely used for cross-lingual retrieval, translation, and multilingual applications, yet it is unclear how well they preserve meaning similarity across languages when words are polysemous. Understanding whether embeddings align on shared senses (vs. averaging across senses) directly impacts bilingual lexicon induction, semantic search, and cross-lingual transfer quality.\n\n### Gap in Existing Work\nPrior work focuses on cross-lingual alignment and evaluates on translation or WiC-style tasks separately, but there is limited direct analysis of how polysemy affects cross-lingual embedding similarity within the same multilingual model under controlled conditions.\n\n### Our Novel Contribution\nWe test whether cross-lingual embedding similarity persists for polysemous words when only one sense aligns across languages, contrasting static alignment baselines with multilingual contextual embeddings using sense-aware benchmarks.\n\n### Experiment Justification\n- Experiment 1: Static embedding alignment (MUSE/VecMap) on bilingual dictionaries to establish baseline cross-lingual similarity for monosemous vs. polysemous words.\n- Experiment 2: Contextual embedding similarity and WiC-style evaluation (XL-WiC, MCL-WiC) to test whether shared senses yield higher similarity in multilingual contextual models.\n- Experiment 3: Sense-conditional similarity analysis by grouping polysemous words by sense match vs. mismatch to quantify the effect of polysemy on alignment.\n\n## Research Question\nDo words with similar meanings in different languages have similar embeddings in multilingual models, and how does polysemy affect cross-lingual embedding similarity when only one sense aligns?\n\n## Background and Motivation\nCross-lingual embedding similarity underpins bilingual lexicon induction and multilingual transfer. While multilingual pretraining improves alignment, polysemy may blur similarity if embeddings aggregate multiple senses. This research aims to quantify that effect using standard dictionaries and sense-aware benchmarks.\n\n## Hypothesis Decomposition\n- H1: For monosemous translation pairs, multilingual embeddings are more similar than for unrelated pairs.\n- H2: For polysemous words where one sense aligns across languages, contextual embeddings in matching contexts yield higher similarity than in mismatched contexts.\n- H3: Static alignment methods show reduced similarity for polysemous pairs compared to monosemous pairs.\n\n## Proposed Methodology\n\n### Approach\nCombine static alignment baselines (MUSE/VecMap) with multilingual contextual embeddings (XLM-R) and evaluate similarity under controlled sense conditions using XL-WiC/MCL-WiC.\n\n### Experimental Steps\n1. Load MUSE dictionaries and identify monosemous vs. polysemous candidates (by WordNet/Wiktionary metadata from XL-WiC/MCL-WiC).\n2. Compute static embedding similarities and translation retrieval accuracy for monosemous vs. polysemous subsets.\n3. Extract contextual embeddings from a multilingual transformer (e.g., XLM-R) for XL-WiC/MCL-WiC contexts; compute cosine similarity across languages for matched vs. mismatched senses.\n4. Compare similarity distributions and WiC accuracy between conditions; perform statistical tests and effect sizes.\n\n### Baselines\n- Static alignment: VecMap and/or MUSE bilingual alignment.\n- Contextual: Multilingual transformer embeddings without additional alignment.\n\n### Evaluation Metrics\n- Cosine similarity distributions between cross-lingual word pairs.\n- Translation retrieval accuracy (top-1/top-5) on MUSE dictionaries.\n- WiC accuracy/F1 on XL-WiC and MCL-WiC.\n\n### Statistical Analysis Plan\n- Two-sample t-test or Mann–Whitney U for similarity distributions.\n- McNemar’s test for paired WiC predictions across conditions.\n- Effect sizes (Cohen’s d) and 95% confidence intervals.\n- Significance threshold α = 0.05 with FDR correction for multiple comparisons.\n\n## Expected Outcomes\nSupport for the hypothesis would be higher similarity for monosemous pairs and for polysemous pairs only in sense-matched contexts. Static embeddings are expected to show weaker discrimination between sense-match and sense-mismatch.\n\n## Timeline and Milestones\n- Phase 2 (Setup/EDA): 1–2 hours\n- Phase 3 (Implementation): 2–3 hours\n- Phase 4 (Experiments): 2–3 hours\n- Phase 5 (Analysis): 1–2 hours\n- Phase 6 (Documentation): 1 hour\n\n## Potential Challenges\n- Sense annotation coverage across languages may be limited.\n- GPU memory constraints for large batch embedding extraction.\n- Aligning wordpieces to target tokens in contextual models.\n\n## Success Criteria\n- Completed experiments with reproducible scripts.\n- Statistically significant differences between sense-matched and mismatched conditions (or well-justified null results).\n- Comprehensive REPORT.md with plots, tables, and error analysis.\nEOF\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_12","type":"command_execution","command":"/bin/bash -lc \"cat > planning.md << 'EOF'\n## Motivation & Novelty Assessment\n\n### Why This Research Matters\nMultilingual models are widely used for cross-lingual retrieval, translation, and multilingual applications, yet it is unclear how well they preserve meaning similarity across languages when words are polysemous. Understanding whether embeddings align on shared senses (vs. averaging across senses) directly impacts bilingual lexicon induction, semantic search, and cross-lingual transfer quality.\n\n### Gap in Existing Work\nPrior work focuses on cross-lingual alignment and evaluates on translation or WiC-style tasks separately, but there is limited direct analysis of how polysemy affects cross-lingual embedding similarity within the same multilingual model under controlled conditions.\n\n### Our Novel Contribution\nWe test whether cross-lingual embedding similarity persists for polysemous words when only one sense aligns across languages, contrasting static alignment baselines with multilingual contextual embeddings using sense-aware benchmarks.\n\n### Experiment Justification\n- Experiment 1: Static embedding alignment (MUSE/VecMap) on bilingual dictionaries to establish baseline cross-lingual similarity for monosemous vs. polysemous words.\n- Experiment 2: Contextual embedding similarity and WiC-style evaluation (XL-WiC, MCL-WiC) to test whether shared senses yield higher similarity in multilingual contextual models.\n- Experiment 3: Sense-conditional similarity analysis by grouping polysemous words by sense match vs. mismatch to quantify the effect of polysemy on alignment.\n\n## Research Question\nDo words with similar meanings in different languages have similar embeddings in multilingual models, and how does polysemy affect cross-lingual embedding similarity when only one sense aligns?\n\n## Background and Motivation\nCross-lingual embedding similarity underpins bilingual lexicon induction and multilingual transfer. While multilingual pretraining improves alignment, polysemy may blur similarity if embeddings aggregate multiple senses. This research aims to quantify that effect using standard dictionaries and sense-aware benchmarks.\n\n## Hypothesis Decomposition\n- H1: For monosemous translation pairs, multilingual embeddings are more similar than for unrelated pairs.\n- H2: For polysemous words where one sense aligns across languages, contextual embeddings in matching contexts yield higher similarity than in mismatched contexts.\n- H3: Static alignment methods show reduced similarity for polysemous pairs compared to monosemous pairs.\n\n## Proposed Methodology\n\n### Approach\nCombine static alignment baselines (MUSE/VecMap) with multilingual contextual embeddings (XLM-R) and evaluate similarity under controlled sense conditions using XL-WiC/MCL-WiC.\n\n### Experimental Steps\n1. Load MUSE dictionaries and identify monosemous vs. polysemous candidates (by WordNet/Wiktionary metadata from XL-WiC/MCL-WiC).\n2. Compute static embedding similarities and translation retrieval accuracy for monosemous vs. polysemous subsets.\n3. Extract contextual embeddings from a multilingual transformer (e.g., XLM-R) for XL-WiC/MCL-WiC contexts; compute cosine similarity across languages for matched vs. mismatched senses.\n4. Compare similarity distributions and WiC accuracy between conditions; perform statistical tests and effect sizes.\n\n### Baselines\n- Static alignment: VecMap and/or MUSE bilingual alignment.\n- Contextual: Multilingual transformer embeddings without additional alignment.\n\n### Evaluation Metrics\n- Cosine similarity distributions between cross-lingual word pairs.\n- Translation retrieval accuracy (top-1/top-5) on MUSE dictionaries.\n- WiC accuracy/F1 on XL-WiC and MCL-WiC.\n\n### Statistical Analysis Plan\n- Two-sample t-test or Mann–Whitney U for similarity distributions.\n- McNemar’s test for paired WiC predictions across conditions.\n- Effect sizes (Cohen’s d) and 95% confidence intervals.\n- Significance threshold α = 0.05 with FDR correction for multiple comparisons.\n\n## Expected Outcomes\nSupport for the hypothesis would be higher similarity for monosemous pairs and for polysemous pairs only in sense-matched contexts. Static embeddings are expected to show weaker discrimination between sense-match and sense-mismatch.\n\n## Timeline and Milestones\n- Phase 2 (Setup/EDA): 1–2 hours\n- Phase 3 (Implementation): 2–3 hours\n- Phase 4 (Experiments): 2–3 hours\n- Phase 5 (Analysis): 1–2 hours\n- Phase 6 (Documentation): 1 hour\n\n## Potential Challenges\n- Sense annotation coverage across languages may be limited.\n- GPU memory constraints for large batch embedding extraction.\n- Aligning wordpieces to target tokens in contextual models.\n\n## Success Criteria\n- Completed experiments with reproducible scripts.\n- Statistically significant differences between sense-matched and mismatched conditions (or well-justified null results).\n- Comprehensive REPORT.md with plots, tables, and error analysis.\nEOF\"","aggregated_output":"","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_13","type":"reasoning","text":"**Verifying current directory before creating results**\n\nI'm confirming the present working directory to ensure results or figures directories are created in the correct location before proceeding."}}
{"type":"item.started","item":{"id":"item_14","type":"command_execution","command":"/bin/bash -lc pwd","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_14","type":"command_execution","command":"/bin/bash -lc pwd","aggregated_output":"/data/hypogenicai/workspaces/similar-embeddings-nlp-5ef8-codex\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_15","type":"reasoning","text":"**Installing dependencies in venv**\n\nI'm activating the virtual environment and installing required packages like numpy, pandas, matplotlib, seaborn, scipy, scikit-learn, torch, transformers, datasets, tqdm, and sentencepiece using uvicorn's add command to ensure a consistent environment."}}
{"type":"item.started","item":{"id":"item_16","type":"command_execution","command":"/bin/bash -lc 'source .venv/bin/activate && uv add numpy pandas matplotlib seaborn scipy scikit-learn torch torchvision torchaudio transformers datasets tqdm sentencepiece accelerate'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_16","type":"command_execution","command":"/bin/bash -lc 'source .venv/bin/activate && uv add numpy pandas matplotlib seaborn scipy scikit-learn torch torchvision torchaudio transformers datasets tqdm sentencepiece accelerate'","aggregated_output":"Resolved 101 packages in 348ms\n   Building research-workspace @ file:///data/hypogenicai/workspaces/similar-embeddings-nlp-5ef8-codex\n  × Failed to build `research-workspace @\n  │ file:///data/hypogenicai/workspaces/similar-embeddings-nlp-5ef8-codex`\n  ├─▶ The build backend returned an error\n  ╰─▶ Call to `hatchling.build.build_editable` failed (exit status: 1)\n\n      [stderr]\n      Traceback (most recent call last):\n        File \"<string>\", line 11, in <module>\n        File\n      \"/data/haokunliu/.cache/builds-v0/.tmpNTkUK6/lib/python3.12/site-packages/hatchling/build.py\",\n      line 83, in build_editable\n          return os.path.basename(next(builder.build(directory=wheel_directory,\n      versions=[\"editable\"])))\n      \n      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        File\n      \"/data/haokunliu/.cache/builds-v0/.tmpNTkUK6/lib/python3.12/site-packages/hatchling/builders/plugin/interface.py\",\n      line 157, in build\n          artifact = version_api[version](directory, **build_data)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        File\n      \"/data/haokunliu/.cache/builds-v0/.tmpNTkUK6/lib/python3.12/site-packages/hatchling/builders/wheel.py\",\n      line 522, in build_editable\n          return self.build_editable_detection(directory, **build_data)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        File\n      \"/data/haokunliu/.cache/builds-v0/.tmpNTkUK6/lib/python3.12/site-packages/hatchling/builders/wheel.py\",\n      line 534, in build_editable_detection\n          for included_file in self.recurse_selected_project_files():\n        File\n      \"/data/haokunliu/.cache/builds-v0/.tmpNTkUK6/lib/python3.12/site-packages/hatchling/builders/plugin/interface.py\",\n      line 182, in recurse_selected_project_files\n          if self.config.only_include:\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n        File \"/data/miniconda3/lib/python3.12/functools.py\", line 995, in\n      __get__\n          val = self.func(instance)\n                ^^^^^^^^^^^^^^^^^^^\n        File\n      \"/data/haokunliu/.cache/builds-v0/.tmpNTkUK6/lib/python3.12/site-packages/hatchling/builders/config.py\",\n      line 715, in only_include\n          only_include = only_include_config.get(\"only-include\",\n      self.default_only_include()) or self.packages\n      \n      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        File\n      \"/data/haokunliu/.cache/builds-v0/.tmpNTkUK6/lib/python3.12/site-packages/hatchling/builders/wheel.py\",\n      line 268, in default_only_include\n          return self.default_file_selection_options.only_include\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        File \"/data/miniconda3/lib/python3.12/functools.py\", line 995, in\n      __get__\n          val = self.func(instance)\n                ^^^^^^^^^^^^^^^^^^^\n        File\n      \"/data/haokunliu/.cache/builds-v0/.tmpNTkUK6/lib/python3.12/site-packages/hatchling/builders/wheel.py\",\n      line 256, in default_file_selection_options\n          raise ValueError(message)\n      ValueError: Unable to determine which files to ship\n      inside the wheel using the following heuristics:\n      https://hatch.pypa.io/latest/plugins/builder/wheel/#default-file-selection\n\n      The most likely cause of this is that there is no directory that matches\n      the name of your project (research_workspace).\n\n      At least one file selection option must be defined\n      in the `tool.hatch.build.targets.wheel` table, see:\n      https://hatch.pypa.io/latest/config/build/\n\n      As an example, if you intend to ship a directory named `foo` that\n      resides within a `src` directory located at the root of your project,\n      you can define the following:\n\n      [tool.hatch.build.targets.wheel]\n      packages = [\"src/foo\"]\n\n      hint: This usually indicates a problem with the package or the build\n      environment.\n  help: If you want to add the package regardless of the failed resolution,\n        provide the `--frozen` flag to skip locking and syncing.\n","exit_code":1,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_17","type":"reasoning","text":"**Switching to pip install due to editable build failure**\n\nThe editable build failed with uv add, so I'll bypass it by using pip install inside the virtual environment and then freeze dependencies to requirements.txt per instructions."}}
{"type":"item.started","item":{"id":"item_18","type":"command_execution","command":"/bin/bash -lc 'source .venv/bin/activate && uv pip install numpy pandas matplotlib seaborn scipy scikit-learn torch torchvision torchaudio transformers datasets tqdm sentencepiece accelerate'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_18","type":"command_execution","command":"/bin/bash -lc 'source .venv/bin/activate && uv pip install numpy pandas matplotlib seaborn scipy scikit-learn torch torchvision torchaudio transformers datasets tqdm sentencepiece accelerate'","aggregated_output":"Resolved 89 packages in 245ms\nInstalled 82 packages in 990ms\n + accelerate==1.12.0\n + aiohappyeyeballs==2.6.1\n + aiohttp==3.13.3\n + aiosignal==1.4.0\n + annotated-doc==0.0.4\n + attrs==25.4.0\n + charset-normalizer==3.4.4\n + click==8.3.1\n + contourpy==1.3.3\n + cuda-bindings==12.9.4\n + cuda-pathfinder==1.3.4\n + cycler==0.12.1\n + datasets==4.5.0\n + dill==0.4.0\n + filelock==3.24.1\n + fonttools==4.61.1\n + frozenlist==1.8.0\n + fsspec==2025.10.0\n + hf-xet==1.2.0\n + huggingface-hub==1.4.1\n + jinja2==3.1.6\n + joblib==1.5.3\n + kiwisolver==1.4.9\n + markdown-it-py==4.0.0\n + markupsafe==3.0.3\n + matplotlib==3.10.8\n + mdurl==0.1.2\n + mpmath==1.3.0\n + multidict==6.7.1\n + multiprocess==0.70.18\n + networkx==3.6.1\n + numpy==2.4.2\n + nvidia-cublas-cu12==12.8.4.1\n + nvidia-cuda-cupti-cu12==12.8.90\n + nvidia-cuda-nvrtc-cu12==12.8.93\n + nvidia-cuda-runtime-cu12==12.8.90\n + nvidia-cudnn-cu12==9.10.2.21\n + nvidia-cufft-cu12==11.3.3.83\n + nvidia-cufile-cu12==1.13.1.3\n + nvidia-curand-cu12==10.3.9.90\n + nvidia-cusolver-cu12==11.7.3.90\n + nvidia-cusparse-cu12==12.5.8.93\n + nvidia-cusparselt-cu12==0.7.1\n + nvidia-nccl-cu12==2.27.5\n + nvidia-nvjitlink-cu12==12.8.93\n + nvidia-nvshmem-cu12==3.4.5\n + nvidia-nvtx-cu12==12.8.90\n + packaging==26.0\n + pandas==3.0.0\n + pillow==12.1.1\n + propcache==0.4.1\n + psutil==7.2.2\n + pyarrow==23.0.0\n + pygments==2.19.2\n + pyparsing==3.3.2\n + python-dateutil==2.9.0.post0\n + pyyaml==6.0.3\n + regex==2026.1.15\n + requests==2.32.5\n + rich==14.3.2\n + safetensors==0.7.0\n + scikit-learn==1.8.0\n + scipy==1.17.0\n + seaborn==0.13.2\n + sentencepiece==0.2.1\n + setuptools==82.0.0\n + shellingham==1.5.4\n + six==1.17.0\n + sympy==1.14.0\n + threadpoolctl==3.6.0\n + tokenizers==0.22.2\n + torch==2.10.0\n + torchaudio==2.10.0\n + torchvision==0.25.0\n + tqdm==4.67.3\n + transformers==5.1.0\n + triton==3.6.0\n + typer==0.23.1\n + typer-slim==0.23.1\n + urllib3==2.6.3\n + xxhash==3.6.0\n + yarl==1.22.0\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_19","type":"reasoning","text":"**Requesting pip freeze output**"}}
{"type":"item.started","item":{"id":"item_20","type":"command_execution","command":"/bin/bash -lc 'source .venv/bin/activate && pip freeze > requirements.txt'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_20","type":"command_execution","command":"/bin/bash -lc 'source .venv/bin/activate && pip freeze > requirements.txt'","aggregated_output":"","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_21","type":"reasoning","text":"**Reviewing dependency management and project structure**\n\nI'm verifying whether pyproject dependencies need updating since pip install didn't update them, noting that requirements.txt is the primary source per instructions. I'll check for a src directory to organize code and plan data preparation and exploratory data analysis with the datasets."}}
{"type":"item.started","item":{"id":"item_22","type":"command_execution","command":"/bin/bash -lc 'ls src 2>/dev/null || echo \"NO_SRC\"'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_22","type":"command_execution","command":"/bin/bash -lc 'ls src 2>/dev/null || echo \"NO_SRC\"'","aggregated_output":"NO_SRC\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_23","type":"reasoning","text":"**Preparing to create src directory**\n\nI'm checking the current working directory before creating the src folder to ensure correct placement."}}
{"type":"item.started","item":{"id":"item_24","type":"command_execution","command":"/bin/bash -lc pwd","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_24","type":"command_execution","command":"/bin/bash -lc pwd","aggregated_output":"/data/hypogenicai/workspaces/similar-embeddings-nlp-5ef8-codex\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_25","type":"command_execution","command":"/bin/bash -lc 'mkdir -p src results figures logs'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_25","type":"command_execution","command":"/bin/bash -lc 'mkdir -p src results figures logs'","aggregated_output":"","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_26","type":"reasoning","text":"**Checking datasets structure**"}}
{"type":"item.started","item":{"id":"item_27","type":"command_execution","command":"/bin/bash -lc 'ls datasets'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_27","type":"command_execution","command":"/bin/bash -lc 'ls datasets'","aggregated_output":"README.md\nmcl_wic\nmcl_wic.zip\nmuse_dictionaries\nmuse_dictionaries.tar.gz\nxlwic\nxlwic_datasets.zip\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_28","type":"reasoning","text":"**Listing dataset directories**"}}
{"type":"item.started","item":{"id":"item_29","type":"command_execution","command":"/bin/bash -lc 'find datasets/mcl_wic -maxdepth 2 -type f | head'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_29","type":"command_execution","command":"/bin/bash -lc 'find datasets/mcl_wic -maxdepth 2 -type f | head'","aggregated_output":"datasets/mcl_wic/samples/mcl_wic_training_en_en_sample.txt\ndatasets/mcl_wic/mcl-wic-master/SemEval-2021_MCL-WiC_results.zip\ndatasets/mcl_wic/mcl-wic-master/SemEval-2021_MCL-WiC_test-gold-data.zip\ndatasets/mcl_wic/mcl-wic-master/SemEval-2021_MCL-WiC_trial.zip\ndatasets/mcl_wic/mcl-wic-master/README.md\ndatasets/mcl_wic/mcl-wic-master/SemEval-2021_MCL-WiC_all-datasets.zip\ndatasets/mcl_wic/mcl-wic-master/SemEval_2021_Task_2__Multilingual_and_Cross_lingual_Word_in_Context_Disambiguation__MCL_WiC___Paper_.pdf\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_30","type":"reasoning","text":"**Preparing to check README for extraction details**"}}
{"type":"item.started","item":{"id":"item_31","type":"command_execution","command":"/bin/bash -lc \"sed -n '1,200p' datasets/mcl_wic/mcl-wic-master/README.md\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_31","type":"command_execution","command":"/bin/bash -lc \"sed -n '1,200p' datasets/mcl_wic/mcl-wic-master/README.md\"","aggregated_output":"## SemEval-2021 Task 2: Multilingual and Cross-lingual Word-in-Context Disambiguation (MCL-WiC)\n<b>Multilingual and Cross-lingual Word-in-Context Disambiguation (MCL-WiC) Task</b>\n\nThe Codalab competition took place at: https://competitions.codalab.org/competitions/27054\n\nLink to the paper: https://raw.githubusercontent.com/SapienzaNLP/mcl-wic/master/SemEval_2021_Task_2__Multilingual_and_Cross_lingual_Word_in_Context_Disambiguation__MCL_WiC___Paper_.pdf\n\n## Citation\n\nPlease cite our work as follows: \n\nMartelli, F., Kalach, N., Tola, G and Navigli, R. [SemEval-2021 Task 2: Multilingual and Cross-lingual Word-in-Context Disambiguation (MCL-WiC)](https://raw.githubusercontent.com/SapienzaNLP/mcl-wic/master/SemEval_2021_Task_2__Multilingual_and_Cross_lingual_Word_in_Context_Disambiguation__MCL_WiC___Paper_.pdf). Proc. of the 15th Workshop on Semantic Evaluation, 2021.\n\nBibTex:\n\n@inproceedings{martelli-etal-2021-mclwic,\ntitle = \"{S}em{E}val-2021 {T}ask 2: {M}ultilingual and {C}ross-lingual {W}ord-in-{C}ontext {D}isambiguation ({MCL}-{W}i{C})\",\nauthor= \"Martelli, Federico and Kalach, Najla and Tola, Gabriele and Navigli, Roberto\",\nbooktitle=\"Proceedings of the Fifteenth Workshop on Semantic Evaluation (SemEval-2021)\",\nyear={2021}\n}\n\n## License\nThis project is released under the CC-BY-NC 4.0 license (see `LICENSE.txt`). If you use the data, please cite: \n\nMartelli, F., Kalach, N., Tola, G and Navigli, R. [SemEval-2021 Task 2: Multilingual and Cross-lingual Word-in-Context Disambiguation (MCL-WiC)](https://raw.githubusercontent.com/SapienzaNLP/mcl-wic/master/SemEval_2021_Task_2__Multilingual_and_Cross_lingual_Word_in_Context_Disambiguation__MCL_WiC___Paper_.pdf). Proc. of the 15th Workshop on Semantic Evaluation, 2021.\n\n## Acknowledgements\nThe authors gratefully acknowledge the support of the <a href=\"http://elex.is\">ELEXIS EU Project</a> No. 731015 and the <a href=\"http://mousse-project.org\">ERC Consolidator Grant MOUSSE</a> No. 726487 under the European\nUnion's Horizon 2020 research and innovation programme.\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_32","type":"reasoning","text":"**Preparing to extract dataset files**\n\nI'll check if the dataset is already extracted before unzipping SemEval-2021_MCL-WiC_all-datasets.zip into datasets/mcl_wic/data to avoid redundant extraction."}}
{"type":"item.started","item":{"id":"item_33","type":"command_execution","command":"/bin/bash -lc 'ls datasets/mcl_wic/mcl-wic-master | grep -i data'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_33","type":"command_execution","command":"/bin/bash -lc 'ls datasets/mcl_wic/mcl-wic-master | grep -i data'","aggregated_output":"SemEval-2021_MCL-WiC_all-datasets.zip\nSemEval-2021_MCL-WiC_test-gold-data.zip\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_34","type":"reasoning","text":"**Planning unzip destination**\n\nI'll unzip files into datasets/mcl_wic/data, considering using the current directory as a reference point."}}
{"type":"item.started","item":{"id":"item_35","type":"command_execution","command":"/bin/bash -lc pwd","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_35","type":"command_execution","command":"/bin/bash -lc pwd","aggregated_output":"/data/hypogenicai/workspaces/similar-embeddings-nlp-5ef8-codex\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_36","type":"command_execution","command":"/bin/bash -lc 'mkdir -p datasets/mcl_wic/data && unzip -q datasets/mcl_wic/mcl-wic-master/SemEval-2021_MCL-WiC_all-datasets.zip -d datasets/mcl_wic/data'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_36","type":"command_execution","command":"/bin/bash -lc 'mkdir -p datasets/mcl_wic/data && unzip -q datasets/mcl_wic/mcl-wic-master/SemEval-2021_MCL-WiC_all-datasets.zip -d datasets/mcl_wic/data'","aggregated_output":"","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_37","type":"reasoning","text":"**Confirming dataset availability**"}}
{"type":"item.started","item":{"id":"item_38","type":"command_execution","command":"/bin/bash -lc 'find datasets/xlwic -maxdepth 2 -type f | head'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_38","type":"command_execution","command":"/bin/bash -lc 'find datasets/xlwic -maxdepth 2 -type f | head'","aggregated_output":"datasets/xlwic/samples/xlwic_train_en_sample.txt\ndatasets/xlwic/xlwic_datasets/.DS_Store\ndatasets/xlwic/xlwic_datasets/README.txt\ndatasets/xlwic/xlwic_datasets/xlwic_scorer.py\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_39","type":"reasoning","text":"**Listing dataset files in subfolders**"}}
{"type":"item.started","item":{"id":"item_40","type":"command_execution","command":"/bin/bash -lc 'find datasets/xlwic/xlwic_datasets -maxdepth 2 -type f | head -n 20'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_40","type":"command_execution","command":"/bin/bash -lc 'find datasets/xlwic/xlwic_datasets -maxdepth 2 -type f | head -n 20'","aggregated_output":"datasets/xlwic/xlwic_datasets/.DS_Store\ndatasets/xlwic/xlwic_datasets/xlwic_wn/.DS_Store\ndatasets/xlwic/xlwic_datasets/README.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wikt/.DS_Store\ndatasets/xlwic/xlwic_datasets/xlwic_scorer.py\ndatasets/xlwic/xlwic_datasets/wic_english/train_en.txt\ndatasets/xlwic/xlwic_datasets/wic_english/valid_en.txt\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_41","type":"command_execution","command":"/bin/bash -lc 'find datasets/xlwic/xlwic_datasets -maxdepth 3 -type f | head -n 60'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_41","type":"command_execution","command":"/bin/bash -lc 'find datasets/xlwic/xlwic_datasets -maxdepth 3 -type f | head -n 60'","aggregated_output":"datasets/xlwic/xlwic_datasets/.DS_Store\ndatasets/xlwic/xlwic_datasets/xlwic_wn/chinese_zh/zh_test_gold.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wn/chinese_zh/zh_test_data.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wn/chinese_zh/.DS_Store\ndatasets/xlwic/xlwic_datasets/xlwic_wn/chinese_zh/zh_valid.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wn/bulgarian_bg/.DS_Store\ndatasets/xlwic/xlwic_datasets/xlwic_wn/bulgarian_bg/bg_test_gold.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wn/bulgarian_bg/bg_test_data.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wn/bulgarian_bg/bg_valid.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wn/estonian_et/et_test_gold.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wn/estonian_et/.DS_Store\ndatasets/xlwic/xlwic_datasets/xlwic_wn/estonian_et/et_test_data.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wn/estonian_et/et_valid.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wn/danish_da/da_test_gold.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wn/danish_da/.DS_Store\ndatasets/xlwic/xlwic_datasets/xlwic_wn/danish_da/da_valid.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wn/danish_da/da_test_data.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wn/japanese_ja/.DS_Store\ndatasets/xlwic/xlwic_datasets/xlwic_wn/japanese_ja/ja_test_data.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wn/japanese_ja/ja_valid.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wn/japanese_ja/ja_test_gold.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wn/croatian_hr/hr_test_gold.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wn/croatian_hr/hr_test_data.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wn/croatian_hr/.DS_Store\ndatasets/xlwic/xlwic_datasets/xlwic_wn/croatian_hr/hr_valid.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wn/.DS_Store\ndatasets/xlwic/xlwic_datasets/xlwic_wn/farsi_fa/.DS_Store\ndatasets/xlwic/xlwic_datasets/xlwic_wn/farsi_fa/fa_test_gold.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wn/farsi_fa/fa_test_data.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wn/farsi_fa/fa_valid.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wn/korean_ko/ko_valid.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wn/korean_ko/ko_test_gold.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wn/korean_ko/.DS_Store\ndatasets/xlwic/xlwic_datasets/xlwic_wn/korean_ko/ko_test_data.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wn/dutch_nl/nl_valid.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wn/dutch_nl/nl_test_gold.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wn/dutch_nl/nl_test_data.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wn/dutch_nl/.DS_Store\ndatasets/xlwic/xlwic_datasets/README.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wikt/.DS_Store\ndatasets/xlwic/xlwic_datasets/xlwic_wikt/german_de/de_valid.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wikt/german_de/de_train.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wikt/german_de/.DS_Store\ndatasets/xlwic/xlwic_datasets/xlwic_wikt/german_de/de_test_gold.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wikt/german_de/de_test_data.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wikt/italian_it/it_test_data.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wikt/italian_it/it_test_gold.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wikt/italian_it/it_train.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wikt/italian_it/.DS_Store\ndatasets/xlwic/xlwic_datasets/xlwic_wikt/italian_it/it_valid.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wikt/french_fr/.DS_Store\ndatasets/xlwic/xlwic_datasets/xlwic_wikt/french_fr/fr_train.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wikt/french_fr/fr_test_gold.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wikt/french_fr/fr_test_data.txt\ndatasets/xlwic/xlwic_datasets/xlwic_wikt/french_fr/fr_valid.txt\ndatasets/xlwic/xlwic_datasets/xlwic_scorer.py\ndatasets/xlwic/xlwic_datasets/wic_english/train_en.txt\ndatasets/xlwic/xlwic_datasets/wic_english/valid_en.txt\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_42","type":"reasoning","text":"**Inspecting MUSE dictionaries**"}}
{"type":"item.started","item":{"id":"item_43","type":"command_execution","command":"/bin/bash -lc 'find datasets/muse_dictionaries -maxdepth 2 -type f | head'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_43","type":"command_execution","command":"/bin/bash -lc 'find datasets/muse_dictionaries -maxdepth 2 -type f | head'","aggregated_output":"datasets/muse_dictionaries/dictionaries/fr-de.0-5000.txt\ndatasets/muse_dictionaries/dictionaries/af-en.5000-6500.txt\ndatasets/muse_dictionaries/dictionaries/en-ur3.5000-6500.txt\ndatasets/muse_dictionaries/dictionaries/en-ur3.0-5000.txt\ndatasets/muse_dictionaries/dictionaries/fi-en.txt\ndatasets/muse_dictionaries/dictionaries/es-fr.txt\ndatasets/muse_dictionaries/dictionaries/de-pt.0-5000.txt\ndatasets/muse_dictionaries/dictionaries/hr-en.txt\ndatasets/muse_dictionaries/dictionaries/it-de.5000-6500.txt\ndatasets/muse_dictionaries/dictionaries/zh-en.0-5000.txt\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_44","type":"reasoning","text":"**Planning multilingual embedding experiments**\n\nI'm deciding to use `xlm-roberta-base` for multilingual contextual embeddings due to GPU limits and will simulate static embeddings by averaging the model's input token embeddings as a baseline, enabling three experiments comparing static and contextual representations within compute constraints."}}
{"type":"item.completed","item":{"id":"item_45","type":"reasoning","text":"**Designing bilingual similarity experiments**\n\nI'm planning to use MUSE dictionaries for a few language pairs to measure cosine similarity between static embeddings derived from the model’s input token vectors for translation and random pairs, and to incorporate polysemy analysis via the MCL-WiC cross-lingual dataset by identifying polysemous words based on context pairs labeled for same or different meanings."}}
{"type":"item.started","item":{"id":"item_46","type":"command_execution","command":"/bin/bash -lc \"sed -n '1,5p' datasets/mcl_wic/samples/mcl_wic_training_en_en_sample.txt\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_46","type":"command_execution","command":"/bin/bash -lc \"sed -n '1,5p' datasets/mcl_wic/samples/mcl_wic_training_en_en_sample.txt\"","aggregated_output":"[\n    {\n        \"id\": \"training.en-en.0\",\n        \"lemma\": \"play\",\n        \"pos\": \"NOUN\",\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_47","type":"reasoning","text":"**Checking JSON sample structure**"}}
{"type":"item.started","item":{"id":"item_48","type":"command_execution","command":"/bin/bash -lc \"sed -n '1,40p' datasets/mcl_wic/samples/mcl_wic_training_en_en_sample.txt\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_48","type":"command_execution","command":"/bin/bash -lc \"sed -n '1,40p' datasets/mcl_wic/samples/mcl_wic_training_en_en_sample.txt\"","aggregated_output":"[\n    {\n        \"id\": \"training.en-en.0\",\n        \"lemma\": \"play\",\n        \"pos\": \"NOUN\",\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_49","type":"reasoning","text":"**Identifying dataset format**\n\nThe dataset appears as a JSON list, and the zip likely contains TSV files, so I'll inspect the extracted contents next."}}
{"type":"item.started","item":{"id":"item_50","type":"command_execution","command":"/bin/bash -lc 'find datasets/mcl_wic/data -maxdepth 3 -type f | head -n 20'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_50","type":"command_execution","command":"/bin/bash -lc 'find datasets/mcl_wic/data -maxdepth 3 -type f | head -n 20'","aggregated_output":"datasets/mcl_wic/data/MCL-WiC/README.txt\ndatasets/mcl_wic/data/MCL-WiC/LICENSE.txt\ndatasets/mcl_wic/data/MCL-WiC/training/training.en-en.data\ndatasets/mcl_wic/data/MCL-WiC/training/training.en-en.gold\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_51","type":"reasoning","text":"**Inspecting data format**"}}
{"type":"item.started","item":{"id":"item_52","type":"command_execution","command":"/bin/bash -lc \"sed -n '1,5p' datasets/mcl_wic/data/MCL-WiC/training/training.en-en.data\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_52","type":"command_execution","command":"/bin/bash -lc \"sed -n '1,5p' datasets/mcl_wic/data/MCL-WiC/training/training.en-en.data\"","aggregated_output":"[\n    {\n        \"id\": \"training.en-en.0\",\n        \"lemma\": \"play\",\n        \"pos\": \"NOUN\",\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_53","type":"reasoning","text":"**Identifying JSON list structure**"}}
{"type":"item.started","item":{"id":"item_54","type":"command_execution","command":"/bin/bash -lc \"python - << 'PY'\nimport json\npath='datasets/mcl_wic/data/MCL-WiC/training/training.en-en.data'\nwith open(path,'r') as f:\n    data=json.load(f)\nprint(type(data), len(data))\nprint(data[0].keys())\nprint(data[0])\nPY\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_54","type":"command_execution","command":"/bin/bash -lc \"python - << 'PY'\nimport json\npath='datasets/mcl_wic/data/MCL-WiC/training/training.en-en.data'\nwith open(path,'r') as f:\n    data=json.load(f)\nprint(type(data), len(data))\nprint(data[0].keys())\nprint(data[0])\nPY\"","aggregated_output":"<class 'list'> 8000\ndict_keys(['id', 'lemma', 'pos', 'sentence1', 'sentence2', 'start1', 'end1', 'start2', 'end2'])\n{'id': 'training.en-en.0', 'lemma': 'play', 'pos': 'NOUN', 'sentence1': 'In that context of coordination and integration, Bolivia holds a key play in any process of infrastructure development.', 'sentence2': 'A musical play on the same subject was also staged in Kathmandu for three days.', 'start1': '69', 'end1': '73', 'start2': '10', 'end2': '14'}\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_55","type":"reasoning","text":"**Questioning gold file presence**\n\nI'm checking whether there is a gold file present to compare test outputs against, which will guide subsequent test validation steps."}}
{"type":"item.started","item":{"id":"item_56","type":"command_execution","command":"/bin/bash -lc \"sed -n '1,5p' datasets/mcl_wic/data/MCL-WiC/training/training.en-en.gold\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_56","type":"command_execution","command":"/bin/bash -lc \"sed -n '1,5p' datasets/mcl_wic/data/MCL-WiC/training/training.en-en.gold\"","aggregated_output":"[\n    {\n        \"id\": \"training.en-en.0\",\n        \"tag\": \"F\"\n    },\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_57","type":"reasoning","text":"**Verifying dataset format for cross-lingual pairs**\n\nI identified that the gold data is a JSON list with id and tag fields and plan to parse it. Next, I'll examine the training.en-fr files to confirm the availability of cross-lingual sentence pairs."}}
{"type":"item.started","item":{"id":"item_58","type":"command_execution","command":"/bin/bash -lc 'ls datasets/mcl_wic/data/MCL-WiC/training | head'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_58","type":"command_execution","command":"/bin/bash -lc 'ls datasets/mcl_wic/data/MCL-WiC/training | head'","aggregated_output":"training.en-en.data\ntraining.en-en.gold\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_59","type":"reasoning","text":"**Checking cross-lingual support**\n\nI'm verifying if the training includes only English or also cross-lingual data for trials and tests."}}
{"type":"item.started","item":{"id":"item_60","type":"command_execution","command":"/bin/bash -lc \"find datasets/mcl_wic/data/MCL-WiC -type f | grep -E '\\\\.data\"'$'\"' | head -n 20\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_60","type":"command_execution","command":"/bin/bash -lc \"find datasets/mcl_wic/data/MCL-WiC -type f | grep -E '\\\\.data\"'$'\"' | head -n 20\"","aggregated_output":"datasets/mcl_wic/data/MCL-WiC/test/crosslingual/test.en-ru.data\ndatasets/mcl_wic/data/MCL-WiC/test/crosslingual/test.en-ar.data\ndatasets/mcl_wic/data/MCL-WiC/test/crosslingual/test.en-zh.data\ndatasets/mcl_wic/data/MCL-WiC/test/crosslingual/test.en-fr.data\ndatasets/mcl_wic/data/MCL-WiC/test/multilingual/test.en-en.data\ndatasets/mcl_wic/data/MCL-WiC/test/multilingual/test.ar-ar.data\ndatasets/mcl_wic/data/MCL-WiC/test/multilingual/test.ru-ru.data\ndatasets/mcl_wic/data/MCL-WiC/test/multilingual/test.zh-zh.data\ndatasets/mcl_wic/data/MCL-WiC/test/multilingual/test.fr-fr.data\ndatasets/mcl_wic/data/MCL-WiC/dev/multilingual/dev.fr-fr.data\ndatasets/mcl_wic/data/MCL-WiC/dev/multilingual/dev.zh-zh.data\ndatasets/mcl_wic/data/MCL-WiC/dev/multilingual/dev.ru-ru.data\ndatasets/mcl_wic/data/MCL-WiC/dev/multilingual/dev.ar-ar.data\ndatasets/mcl_wic/data/MCL-WiC/dev/multilingual/dev.en-en.data\ndatasets/mcl_wic/data/MCL-WiC/training/training.en-en.data\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_61","type":"reasoning","text":"**Checking availability of gold labels**\n\nI’m verifying if gold label files exist to enable crosslingual testing and evaluation."}}
{"type":"item.started","item":{"id":"item_62","type":"command_execution","command":"/bin/bash -lc 'find datasets/mcl_wic/data/MCL-WiC/test/crosslingual -type f | head'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_62","type":"command_execution","command":"/bin/bash -lc 'find datasets/mcl_wic/data/MCL-WiC/test/crosslingual -type f | head'","aggregated_output":"datasets/mcl_wic/data/MCL-WiC/test/crosslingual/test.en-ru.data\ndatasets/mcl_wic/data/MCL-WiC/test/crosslingual/test.en-ar.data\ndatasets/mcl_wic/data/MCL-WiC/test/crosslingual/test.en-zh.data\ndatasets/mcl_wic/data/MCL-WiC/test/crosslingual/test.en-fr.data\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_63","type":"reasoning","text":"**Identifying missing gold data**\n\nI realized the extracted all-datasets archive might not include the gold data for test crosslingual, so I'm unzipping the test-gold archive to access those files."}}
{"type":"item.started","item":{"id":"item_64","type":"command_execution","command":"/bin/bash -lc 'mkdir -p datasets/mcl_wic/data_gold && unzip -q datasets/mcl_wic/mcl-wic-master/SemEval-2021_MCL-WiC_test-gold-data.zip -d datasets/mcl_wic/data_gold'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_64","type":"command_execution","command":"/bin/bash -lc 'mkdir -p datasets/mcl_wic/data_gold && unzip -q datasets/mcl_wic/mcl-wic-master/SemEval-2021_MCL-WiC_test-gold-data.zip -d datasets/mcl_wic/data_gold'","aggregated_output":"","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_65","type":"command_execution","command":"/bin/bash -lc 'find datasets/mcl_wic/data_gold -type f | head'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_65","type":"command_execution","command":"/bin/bash -lc 'find datasets/mcl_wic/data_gold -type f | head'","aggregated_output":"datasets/mcl_wic/data_gold/test.en-fr.gold\ndatasets/mcl_wic/data_gold/test.en-en.gold\ndatasets/mcl_wic/data_gold/test.ar-ar.gold\ndatasets/mcl_wic/data_gold/test.en-zh.gold\ndatasets/mcl_wic/data_gold/test.ru-ru.gold\ndatasets/mcl_wic/data_gold/test.zh-zh.gold\ndatasets/mcl_wic/data_gold/test.en-ru.gold\ndatasets/mcl_wic/data_gold/test.fr-fr.gold\ndatasets/mcl_wic/data_gold/test.en-ar.gold\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_66","type":"reasoning","text":"**Outlining crosslingual embedding evaluation**\n\nI'm planning to evaluate sense alignment by extracting contextual embeddings for target words from XLM-R, then computing cosine similarities across language pairs using thresholds tuned on dev data; experiments will compare similarity distributions for same- and different-sense pairs in crosslingual test sets to validate the method."}}
{"type":"item.completed","item":{"id":"item_67","type":"reasoning","text":"**Defining polysemy categories via WiC lemmas**\n\nI'm planning to identify polysemous lemmas by checking for both same- and different-sense labels in WiC data, then use this classification to compare similarity patterns for polysemous versus monosemous words across crosslingual embeddings and MUSE dictionary pairs."}}
{"type":"item.started","item":{"id":"item_68","type":"command_execution","command":"/bin/bash -lc 'head -n 5 datasets/muse_dictionaries/dictionaries/en-fr.txt 2>/dev/null || head -n 5 datasets/muse_dictionaries/dictionaries/en-fr.0-5000.txt'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_68","type":"command_execution","command":"/bin/bash -lc 'head -n 5 datasets/muse_dictionaries/dictionaries/en-fr.txt 2>/dev/null || head -n 5 datasets/muse_dictionaries/dictionaries/en-fr.0-5000.txt'","aggregated_output":"the le\nthe les\nthe la\nand et\nwas fut\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_69","type":"reasoning","text":"**Outlining experiment script steps**\n\nThe plan details implementing a script to set seeds, log the environment, load datasets and models, compute static and contextual embeddings using token alignment, and then calculate similarities and save results with visualizations, while noting potential dataset size constraints for efficient handling."}}
{"type":"item.started","item":{"id":"item_70","type":"command_execution","command":"/bin/bash -lc \"python - << 'PY'\nimport json, glob\nfrom pathlib import Path\nbase='datasets/mcl_wic/data/MCL-WiC/test/crosslingual'\nfor path in sorted(Path(base).glob('*.data')):\n    data=json.load(open(path))\n    print(path.name, len(data))\nPY\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_70","type":"command_execution","command":"/bin/bash -lc \"python - << 'PY'\nimport json, glob\nfrom pathlib import Path\nbase='datasets/mcl_wic/data/MCL-WiC/test/crosslingual'\nfor path in sorted(Path(base).glob('*.data')):\n    data=json.load(open(path))\n    print(path.name, len(data))\nPY\"","aggregated_output":"test.en-ar.data 1000\ntest.en-fr.data 1000\ntest.en-ru.data 1000\ntest.en-zh.data 1000\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_71","type":"reasoning","text":"**Planning batching and offset handling**\n\nI'm preparing to implement batching for encoding sentences and target spans using tokenizers with offset mappings, planning to select tokens overlapping targets while handling special tokens and fallback cases for unmatched spans."}}
{"type":"item.completed","item":{"id":"item_72","type":"reasoning","text":"**Designing experiment scripts and data processing**\n\nI'm planning to implement Python scripts under src/ to compute static and contextual embeddings with language pairs from MUSE dictionaries, parse gold labels for polysemy from MCL-WiC, log outputs, save results and plots, and handle datasets with batching and logging for clarity and reproducibility."}}
{"type":"item.started","item":{"id":"item_73","type":"command_execution","command":"/bin/bash -lc \"cat > src/run_experiments.py << 'PY'\nimport json\nimport logging\nimport os\nimport random\nfrom dataclasses import dataclass\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Dict, Iterable, List, Tuple\n\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom scipy.stats import mannwhitneyu, ttest_ind\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\nfrom transformers import AutoModel, AutoTokenizer\n\n# -------------------------\n# Reproducibility\n# -------------------------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\ndef setup_logging(log_path: Path):\n    log_path.parent.mkdir(parents=True, exist_ok=True)\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\\\"%(asctime)s | %(levelname)s | %(message)s\\\",\n        handlers=[\n            logging.FileHandler(log_path),\n            logging.StreamHandler(),\n        ],\n    )\n\n@dataclass\nclass MCLWICSample:\n    sample_id: str\n    lemma: str\n    pos: str\n    sentence1: str\n    sentence2: str\n    start1: int\n    end1: int\n    start2: int\n    end2: int\n    label: str  # \\\"T\\\" or \\\"F\\\"\n\n\ndef load_mcl_wic_pair(data_path: Path, gold_path: Path) -> List[MCLWICSample]:\n    data = json.loads(data_path.read_text())\n    gold = {item[\\\"id\\\"]: item[\\\"tag\\\"] for item in json.loads(gold_path.read_text())}\n    samples = []\n    for item in data:\n        label = gold.get(item[\\\"id\\\"], None)\n        if label is None:\n            continue\n        samples.append(\n            MCLWICSample(\n                sample_id=item[\\\"id\\\"],\n                lemma=item[\\\"lemma\\\"],\n                pos=item[\\\"pos\\\"],\n                sentence1=item[\\\"sentence1\\\"],\n                sentence2=item[\\\"sentence2\\\"],\n                start1=int(item[\\\"start1\\\"]),\n                end1=int(item[\\\"end1\\\"]),\n                start2=int(item[\\\"start2\\\"]),\n                end2=int(item[\\\"end2\\\"]),\n                label=label,\n            )\n        )\n    return samples\n\n\ndef load_mcl_wic_training(data_path: Path, gold_path: Path) -> List[MCLWICSample]:\n    return load_mcl_wic_pair(data_path, gold_path)\n\n\ndef build_polysemy_lexicon(samples: Iterable[MCLWICSample]) -> Dict[str, str]:\n    # Mark lemma as polysemous if it appears with both T and F labels\n    lemma_labels: Dict[str, set] = {}\n    for s in samples:\n        lemma_labels.setdefault(s.lemma, set()).add(s.label)\n    lexicon = {}\n    for lemma, labels in lemma_labels.items():\n        if len(labels) >= 2:\n            lexicon[lemma] = \\\"polysemous\\\"\n        else:\n            lexicon[lemma] = \\\"monosemous\\\"\n    return lexicon\n\n\ndef find_dictionary_file(base_dir: Path, lang_pair: str) -> Path:\n    # Try exact, then subsets\n    candidates = [\n        base_dir / f\\\"{lang_pair}.txt\\\",\n        base_dir / f\\\"{lang_pair}.0-5000.txt\\\",\n        base_dir / f\\\"{lang_pair}.5000-6500.txt\\\",\n    ]\n    for c in candidates:\n        if c.exists():\n            return c\n    # Try reverse pair\n    src, tgt = lang_pair.split(\\\"-\\\")\n    rev = f\\\"{tgt}-{src}\\\"\n    candidates = [\n        base_dir / f\\\"{rev}.txt\\\",\n        base_dir / f\\\"{rev}.0-5000.txt\\\",\n        base_dir / f\\\"{rev}.5000-6500.txt\\\",\n    ]\n    for c in candidates:\n        if c.exists():\n            return c\n    raise FileNotFoundError(f\\\"No dictionary file found for {lang_pair}\\\")\n\n\ndef load_dictionary_pairs(path: Path, limit: int = 2000) -> List[Tuple[str, str]]:\n    pairs = []\n    with path.open(\\\"r\\\", encoding=\\\"utf-8\\\") as f:\n        for line in f:\n            line = line.strip()\n            if not line:\n                continue\n            parts = line.split()\n            if len(parts) < 2:\n                continue\n            pairs.append((parts[0], parts[1]))\n            if len(pairs) >= limit:\n                break\n    return pairs\n\n\ndef mean_pool_span(hidden_states: torch.Tensor, offsets: List[Tuple[int, int]], start: int, end: int) -> torch.Tensor:\n    # Identify token indices overlapping the character span\n    idxs = []\n    for i, (s, e) in enumerate(offsets):\n        if s == e == 0:\n            continue\n        if s < end and e > start:\n            idxs.append(i)\n    if not idxs:\n        # fallback to closest token by start\n        distances = [abs(s - start) for s, e in offsets]\n        if distances:\n            idxs = [int(np.argmin(distances))]\n        else:\n            idxs = [0]\n    vec = hidden_states[idxs].mean(dim=0)\n    return vec\n\n\ndef cosine_sim(a: torch.Tensor, b: torch.Tensor) -> float:\n    return torch.nn.functional.cosine_similarity(a, b, dim=0).item()\n\n\ndef get_static_word_embedding(word: str, tokenizer, embedding_matrix: torch.Tensor) -> torch.Tensor:\n    tokens = tokenizer(word, add_special_tokens=False, return_tensors=\\\"pt\\\")\n    input_ids = tokens[\\\"input_ids\\\"][0]\n    if input_ids.numel() == 0:\n        return torch.zeros(embedding_matrix.shape[1])\n    vecs = embedding_matrix[input_ids]\n    return vecs.mean(dim=0)\n\n\ndef compute_static_similarity(\n    model, tokenizer, pairs: List[Tuple[str, str]], polysemy_map: Dict[str, str]\n) -> pd.DataFrame:\n    embedding_matrix = model.get_input_embeddings().weight.detach().cpu()\n    records = []\n    for src, tgt in tqdm(pairs, desc=\\\"Static sim\\\"):\n        src_vec = get_static_word_embedding(src, tokenizer, embedding_matrix)\n        tgt_vec = get_static_word_embedding(tgt, tokenizer, embedding_matrix)\n        sim = cosine_sim(src_vec, tgt_vec)\n        poly = polysemy_map.get(src, \\\"unknown\\\")\n        records.append({\\\"src\\\": src, \\\"tgt\\\": tgt, \\\"cosine\\\": sim, \\\"polysemy\\\": poly, \\\"pair_type\\\": \\\"translation\\\"})\n    # mismatched baseline by shuffling targets\n    shuffled = pairs.copy()\n    random.shuffle(shuffled)\n    for (src, _), (_, tgt) in tqdm(zip(pairs, shuffled), total=len(pairs), desc=\\\"Static sim (mismatch)\\\"):\n        src_vec = get_static_word_embedding(src, tokenizer, embedding_matrix)\n        tgt_vec = get_static_word_embedding(tgt, tokenizer, embedding_matrix)\n        sim = cosine_sim(src_vec, tgt_vec)\n        poly = polysemy_map.get(src, \\\"unknown\\\")\n        records.append({\\\"src\\\": src, \\\"tgt\\\": tgt, \\\"cosine\\\": sim, \\\"polysemy\\\": poly, \\\"pair_type\\\": \\\"mismatch\\\"})\n    return pd.DataFrame(records)\n\n\ndef batch_contextual_embeddings(\n    model,\n    tokenizer,\n    sentences: List[str],\n    spans: List[Tuple[int, int]],\n    device: torch.device,\n    max_length: int = 128,\n    batch_size: int = 64,\n) -> List[torch.Tensor]:\n    outputs = []\n    for i in tqdm(range(0, len(sentences), batch_size), desc=\\\"Contextual batches\\\"):\n        batch_sents = sentences[i : i + batch_size]\n        batch_spans = spans[i : i + batch_size]\n        enc = tokenizer(\n            batch_sents,\n            return_offsets_mapping=True,\n            padding=True,\n            truncation=True,\n            max_length=max_length,\n            return_tensors=\\\"pt\\\",\n        )\n        offsets = enc.pop(\\\"offset_mapping\\\")\n        enc = {k: v.to(device) for k, v in enc.items()}\n        with torch.no_grad():\n            hidden = model(**enc).last_hidden_state  # [B, T, H]\n        for j in range(hidden.size(0)):\n            h = hidden[j].detach().cpu()\n            offs = offsets[j].tolist()\n            start, end = batch_spans[j]\n            vec = mean_pool_span(h, offs, start, end)\n            outputs.append(vec)\n    return outputs\n\n\ndef compute_contextual_similarity(samples: List[MCLWICSample], model, tokenizer, device, batch_size: int) -> pd.DataFrame:\n    sentences1 = [s.sentence1 for s in samples]\n    spans1 = [(s.start1, s.end1) for s in samples]\n    sentences2 = [s.sentence2 for s in samples]\n    spans2 = [(s.start2, s.end2) for s in samples]\n\n    emb1 = batch_contextual_embeddings(model, tokenizer, sentences1, spans1, device, batch_size=batch_size)\n    emb2 = batch_contextual_embeddings(model, tokenizer, sentences2, spans2, device, batch_size=batch_size)\n\n    records = []\n    for s, v1, v2 in zip(samples, emb1, emb2):\n        sim = cosine_sim(v1, v2)\n        records.append(\n            {\n                \\\"id\\\": s.sample_id,\n                \\\"lemma\\\": s.lemma,\n                \\\"pos\\\": s.pos,\n                \\\"label\\\": s.label,\n                \\\"cosine\\\": sim,\n            }\n        )\n    return pd.DataFrame(records)\n\n\ndef stats_summary(df: pd.DataFrame, group_col: str, value_col: str) -> Dict:\n    summary = {}\n    for group, sub in df.groupby(group_col):\n        summary[group] = {\n            \\\"count\\\": int(len(sub)),\n            \\\"mean\\\": float(sub[value_col].mean()),\n            \\\"std\\\": float(sub[value_col].std()),\n            \\\"min\\\": float(sub[value_col].min()),\n            \\\"max\\\": float(sub[value_col].max()),\n        }\n    return summary\n\n\ndef main():\n    setup_logging(Path(\\\"logs/experiment.log\\\"))\n    logging.info(\\\"Starting experiments\\\")\n\n    device = torch.device(\\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\")\n    logging.info(f\\\"Device: {device}\\\")\n\n    # Model\n    model_name = \\\"xlm-roberta-base\\\"\n    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n    model = AutoModel.from_pretrained(model_name)\n    model.to(device)\n    model.eval()\n\n    # Batch size based on GPU memory (24GB -> 64-128)\n    batch_size = 64 if device.type == \\\"cuda\\\" else 16\n\n    # Load MCL-WiC training for polysemy lexicon\n    train_data = Path(\\\"datasets/mcl_wic/data/MCL-WiC/training/training.en-en.data\\\")\n    train_gold = Path(\\\"datasets/mcl_wic/data/MCL-WiC/training/training.en-en.gold\\\")\n    train_samples = load_mcl_wic_training(train_data, train_gold)\n    polysemy_map = build_polysemy_lexicon(train_samples)\n    logging.info(f\\\"Polysemy lexicon size: {len(polysemy_map)}\\\")\n\n    # Static similarity from MUSE dictionaries\n    dict_dir = Path(\\\"datasets/muse_dictionaries/dictionaries\\\")\n    lang_pairs = [\\\"en-fr\\\", \\\"en-ru\\\", \\\"en-zh\\\", \\\"en-ar\\\"]\n    static_frames = []\n    for lp in lang_pairs:\n        try:\n            dict_path = find_dictionary_file(dict_dir, lp)\n        except FileNotFoundError:\n            logging.warning(f\\\"Skipping {lp}: dictionary not found\\\")\n            continue\n        pairs = load_dictionary_pairs(dict_path, limit=2000)\n        df = compute_static_similarity(model, tokenizer, pairs, polysemy_map)\n        df[\\\"lang_pair\\\"] = lp\n        static_frames.append(df)\n    static_df = pd.concat(static_frames, ignore_index=True)\n    static_df.to_csv(\\\"results/static_similarity.csv\\\", index=False)\n\n    # Contextual similarity on MCL-WiC cross-lingual test sets\n    cross_base = Path(\\\"datasets/mcl_wic/data/MCL-WiC/test/crosslingual\\\")\n    gold_base = Path(\\\"datasets/mcl_wic/data_gold\\\")\n    contextual_frames = []\n    for lp in lang_pairs:\n        data_path = cross_base / f\\\"test.{lp}.data\\\"\n        gold_path = gold_base / f\\\"test.{lp}.gold\\\"\n        if not data_path.exists() or not gold_path.exists():\n            logging.warning(f\\\"Skipping {lp}: data or gold missing\\\")\n            continue\n        samples = load_mcl_wic_pair(data_path, gold_path)\n        df = compute_contextual_similarity(samples, model, tokenizer, device, batch_size=batch_size)\n        df[\\\"lang_pair\\\"] = lp\n        contextual_frames.append(df)\n    contextual_df = pd.concat(contextual_frames, ignore_index=True)\n    contextual_df.to_csv(\\\"results/contextual_similarity.csv\\\", index=False)\n\n    # Threshold-based WiC prediction (simple baseline): optimize on dev.en-en\n    dev_data = Path(\\\"datasets/mcl_wic/data/MCL-WiC/dev/multilingual/dev.en-en.data\\\")\n    dev_gold = Path(\\\"datasets/mcl_wic/data/MCL-WiC/dev/multilingual/dev.en-en.gold\\\")\n    if dev_data.exists() and dev_gold.exists():\n        dev_samples = load_mcl_wic_pair(dev_data, dev_gold)\n        dev_df = compute_contextual_similarity(dev_samples, model, tokenizer, device, batch_size=batch_size)\n        # Search threshold on dev\n        best_thr, best_acc = 0.0, 0.0\n        for thr in np.linspace(-1, 1, 81):\n            preds = [\\\"T\\\" if c >= thr else \\\"F\\\" for c in dev_df[\\\"cosine\\\"]]\n            acc = accuracy_score(dev_df[\\\"label\\\"], preds)\n            if acc > best_acc:\n                best_acc = acc\n                best_thr = thr\n    else:\n        best_thr, best_acc = 0.0, None\n\n    # Apply threshold to cross-lingual\n    contextual_df[\\\"pred\\\"] = [\\\"T\\\" if c >= best_thr else \\\"F\\\" for c in contextual_df[\\\"cosine\\\"]]\n    overall_acc = accuracy_score(contextual_df[\\\"label\\\"], contextual_df[\\\"pred\\\"])\n\n    # Polysemy grouping for contextual results\n    contextual_df[\\\"polysemy\\\"] = contextual_df[\\\"lemma\\\"].map(polysemy_map).fillna(\\\"unknown\\\")\n\n    # Statistical tests\n    stats = {\n        \\\"static_similarity\\\": stats_summary(static_df, \\\"pair_type\\\", \\\"cosine\\\"),\n        \\\"contextual_similarity\\\": stats_summary(contextual_df, \\\"label\\\", \\\"cosine\\\"),\n        \\\"polysemy_contextual\\\": stats_summary(contextual_df, \\\"polysemy\\\", \\\"cosine\\\"),\n    }\n\n    # t-test and Mann–Whitney for contextual T vs F\n    t_vals = contextual_df[contextual_df[\\\"label\\\"] == \\\"T\\\"][\\\"cosine\\\"]\n    f_vals = contextual_df[contextual_df[\\\"label\\\"] == \\\"F\\\"][\\\"cosine\\\"]\n    ttest = ttest_ind(t_vals, f_vals, equal_var=False)\n    mwu = mannwhitneyu(t_vals, f_vals, alternative=\\\"two-sided\\\")\n    stats[\\\"contextual_ttest\\\"] = {\\\"t\\\": float(ttest.statistic), \\\"p\\\": float(ttest.pvalue)}\n    stats[\\\"contextual_mwu\\\"] = {\\\"u\\\": float(mwu.statistic), \\\"p\\\": float(mwu.pvalue)}\n\n    # Static similarity polysemy comparison\n    poly_static = static_df[static_df[\\\"polysemy\\\"] == \\\"polysemous\\\"][\\\"cosine\\\"]\n    mono_static = static_df[static_df[\\\"polysemy\\\"] == \\\"monosemous\\\"][\\\"cosine\\\"]\n    if len(poly_static) > 0 and len(mono_static) > 0:\n        ttest_static = ttest_ind(poly_static, mono_static, equal_var=False)\n        stats[\\\"static_polysemy_ttest\\\"] = {\\\"t\\\": float(ttest_static.statistic), \\\"p\\\": float(ttest_static.pvalue)}\n\n    results = {\n        \\\"timestamp\\\": datetime.now().isoformat(),\n        \\\"model\\\": model_name,\n        \\\"device\\\": str(device),\n        \\\"batch_size\\\": batch_size,\n        \\\"dev_threshold\\\": best_thr,\n        \\\"dev_accuracy\\\": best_acc,\n        \\\"crosslingual_accuracy\\\": float(overall_acc),\n        \\\"stats\\\": stats,\n    }\n\n    Path(\\\"results\\\").mkdir(exist_ok=True)\n    with open(\\\"results/metrics.json\\\", \\\"w\\\") as f:\n        json.dump(results, f, indent=2)\n\n    # Basic plots\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n\n    plt.figure(figsize=(7, 4))\n    sns.histplot(data=contextual_df, x=\\\"cosine\\\", hue=\\\"label\\\", bins=40, stat=\\\"density\\\", common_norm=False)\n    plt.title(\\\"Contextual cosine similarity by label (T vs F)\\\")\n    plt.tight_layout()\n    plt.savefig(\\\"figures/contextual_similarity_hist.png\\\", dpi=200)\n    plt.close()\n\n    plt.figure(figsize=(7, 4))\n    sns.boxplot(data=contextual_df, x=\\\"label\\\", y=\\\"cosine\\\")\n    plt.title(\\\"Contextual similarity by label\\\")\n    plt.tight_layout()\n    plt.savefig(\\\"figures/contextual_similarity_box.png\\\", dpi=200)\n    plt.close()\n\n    plt.figure(figsize=(7, 4))\n    sns.boxplot(data=static_df, x=\\\"pair_type\\\", y=\\\"cosine\\\")\n    plt.title(\\\"Static similarity: translation vs mismatch\\\")\n    plt.tight_layout()\n    plt.savefig(\\\"figures/static_similarity_box.png\\\", dpi=200)\n    plt.close()\n\n    plt.figure(figsize=(7, 4))\n    sns.boxplot(data=contextual_df, x=\\\"polysemy\\\", y=\\\"cosine\\\")\n    plt.title(\\\"Contextual similarity by polysemy class\\\")\n    plt.tight_layout()\n    plt.savefig(\\\"figures/contextual_similarity_polysemy.png\\\", dpi=200)\n    plt.close()\n\n    logging.info(\\\"Experiments completed\\\")\n\n\nif __name__ == \\\"__main__\\\":\n    main()\nPY\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_73","type":"command_execution","command":"/bin/bash -lc \"cat > src/run_experiments.py << 'PY'\nimport json\nimport logging\nimport os\nimport random\nfrom dataclasses import dataclass\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Dict, Iterable, List, Tuple\n\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom scipy.stats import mannwhitneyu, ttest_ind\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\nfrom transformers import AutoModel, AutoTokenizer\n\n# -------------------------\n# Reproducibility\n# -------------------------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\ndef setup_logging(log_path: Path):\n    log_path.parent.mkdir(parents=True, exist_ok=True)\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\\\"%(asctime)s | %(levelname)s | %(message)s\\\",\n        handlers=[\n            logging.FileHandler(log_path),\n            logging.StreamHandler(),\n        ],\n    )\n\n@dataclass\nclass MCLWICSample:\n    sample_id: str\n    lemma: str\n    pos: str\n    sentence1: str\n    sentence2: str\n    start1: int\n    end1: int\n    start2: int\n    end2: int\n    label: str  # \\\"T\\\" or \\\"F\\\"\n\n\ndef load_mcl_wic_pair(data_path: Path, gold_path: Path) -> List[MCLWICSample]:\n    data = json.loads(data_path.read_text())\n    gold = {item[\\\"id\\\"]: item[\\\"tag\\\"] for item in json.loads(gold_path.read_text())}\n    samples = []\n    for item in data:\n        label = gold.get(item[\\\"id\\\"], None)\n        if label is None:\n            continue\n        samples.append(\n            MCLWICSample(\n                sample_id=item[\\\"id\\\"],\n                lemma=item[\\\"lemma\\\"],\n                pos=item[\\\"pos\\\"],\n                sentence1=item[\\\"sentence1\\\"],\n                sentence2=item[\\\"sentence2\\\"],\n                start1=int(item[\\\"start1\\\"]),\n                end1=int(item[\\\"end1\\\"]),\n                start2=int(item[\\\"start2\\\"]),\n                end2=int(item[\\\"end2\\\"]),\n                label=label,\n            )\n        )\n    return samples\n\n\ndef load_mcl_wic_training(data_path: Path, gold_path: Path) -> List[MCLWICSample]:\n    return load_mcl_wic_pair(data_path, gold_path)\n\n\ndef build_polysemy_lexicon(samples: Iterable[MCLWICSample]) -> Dict[str, str]:\n    # Mark lemma as polysemous if it appears with both T and F labels\n    lemma_labels: Dict[str, set] = {}\n    for s in samples:\n        lemma_labels.setdefault(s.lemma, set()).add(s.label)\n    lexicon = {}\n    for lemma, labels in lemma_labels.items():\n        if len(labels) >= 2:\n            lexicon[lemma] = \\\"polysemous\\\"\n        else:\n            lexicon[lemma] = \\\"monosemous\\\"\n    return lexicon\n\n\ndef find_dictionary_file(base_dir: Path, lang_pair: str) -> Path:\n    # Try exact, then subsets\n    candidates = [\n        base_dir / f\\\"{lang_pair}.txt\\\",\n        base_dir / f\\\"{lang_pair}.0-5000.txt\\\",\n        base_dir / f\\\"{lang_pair}.5000-6500.txt\\\",\n    ]\n    for c in candidates:\n        if c.exists():\n            return c\n    # Try reverse pair\n    src, tgt = lang_pair.split(\\\"-\\\")\n    rev = f\\\"{tgt}-{src}\\\"\n    candidates = [\n        base_dir / f\\\"{rev}.txt\\\",\n        base_dir / f\\\"{rev}.0-5000.txt\\\",\n        base_dir / f\\\"{rev}.5000-6500.txt\\\",\n    ]\n    for c in candidates:\n        if c.exists():\n            return c\n    raise FileNotFoundError(f\\\"No dictionary file found for {lang_pair}\\\")\n\n\ndef load_dictionary_pairs(path: Path, limit: int = 2000) -> List[Tuple[str, str]]:\n    pairs = []\n    with path.open(\\\"r\\\", encoding=\\\"utf-8\\\") as f:\n        for line in f:\n            line = line.strip()\n            if not line:\n                continue\n            parts = line.split()\n            if len(parts) < 2:\n                continue\n            pairs.append((parts[0], parts[1]))\n            if len(pairs) >= limit:\n                break\n    return pairs\n\n\ndef mean_pool_span(hidden_states: torch.Tensor, offsets: List[Tuple[int, int]], start: int, end: int) -> torch.Tensor:\n    # Identify token indices overlapping the character span\n    idxs = []\n    for i, (s, e) in enumerate(offsets):\n        if s == e == 0:\n            continue\n        if s < end and e > start:\n            idxs.append(i)\n    if not idxs:\n        # fallback to closest token by start\n        distances = [abs(s - start) for s, e in offsets]\n        if distances:\n            idxs = [int(np.argmin(distances))]\n        else:\n            idxs = [0]\n    vec = hidden_states[idxs].mean(dim=0)\n    return vec\n\n\ndef cosine_sim(a: torch.Tensor, b: torch.Tensor) -> float:\n    return torch.nn.functional.cosine_similarity(a, b, dim=0).item()\n\n\ndef get_static_word_embedding(word: str, tokenizer, embedding_matrix: torch.Tensor) -> torch.Tensor:\n    tokens = tokenizer(word, add_special_tokens=False, return_tensors=\\\"pt\\\")\n    input_ids = tokens[\\\"input_ids\\\"][0]\n    if input_ids.numel() == 0:\n        return torch.zeros(embedding_matrix.shape[1])\n    vecs = embedding_matrix[input_ids]\n    return vecs.mean(dim=0)\n\n\ndef compute_static_similarity(\n    model, tokenizer, pairs: List[Tuple[str, str]], polysemy_map: Dict[str, str]\n) -> pd.DataFrame:\n    embedding_matrix = model.get_input_embeddings().weight.detach().cpu()\n    records = []\n    for src, tgt in tqdm(pairs, desc=\\\"Static sim\\\"):\n        src_vec = get_static_word_embedding(src, tokenizer, embedding_matrix)\n        tgt_vec = get_static_word_embedding(tgt, tokenizer, embedding_matrix)\n        sim = cosine_sim(src_vec, tgt_vec)\n        poly = polysemy_map.get(src, \\\"unknown\\\")\n        records.append({\\\"src\\\": src, \\\"tgt\\\": tgt, \\\"cosine\\\": sim, \\\"polysemy\\\": poly, \\\"pair_type\\\": \\\"translation\\\"})\n    # mismatched baseline by shuffling targets\n    shuffled = pairs.copy()\n    random.shuffle(shuffled)\n    for (src, _), (_, tgt) in tqdm(zip(pairs, shuffled), total=len(pairs), desc=\\\"Static sim (mismatch)\\\"):\n        src_vec = get_static_word_embedding(src, tokenizer, embedding_matrix)\n        tgt_vec = get_static_word_embedding(tgt, tokenizer, embedding_matrix)\n        sim = cosine_sim(src_vec, tgt_vec)\n        poly = polysemy_map.get(src, \\\"unknown\\\")\n        records.append({\\\"src\\\": src, \\\"tgt\\\": tgt, \\\"cosine\\\": sim, \\\"polysemy\\\": poly, \\\"pair_type\\\": \\\"mismatch\\\"})\n    return pd.DataFrame(records)\n\n\ndef batch_contextual_embeddings(\n    model,\n    tokenizer,\n    sentences: List[str],\n    spans: List[Tuple[int, int]],\n    device: torch.device,\n    max_length: int = 128,\n    batch_size: int = 64,\n) -> List[torch.Tensor]:\n    outputs = []\n    for i in tqdm(range(0, len(sentences), batch_size), desc=\\\"Contextual batches\\\"):\n        batch_sents = sentences[i : i + batch_size]\n        batch_spans = spans[i : i + batch_size]\n        enc = tokenizer(\n            batch_sents,\n            return_offsets_mapping=True,\n            padding=True,\n            truncation=True,\n            max_length=max_length,\n            return_tensors=\\\"pt\\\",\n        )\n        offsets = enc.pop(\\\"offset_mapping\\\")\n        enc = {k: v.to(device) for k, v in enc.items()}\n        with torch.no_grad():\n            hidden = model(**enc).last_hidden_state  # [B, T, H]\n        for j in range(hidden.size(0)):\n            h = hidden[j].detach().cpu()\n            offs = offsets[j].tolist()\n            start, end = batch_spans[j]\n            vec = mean_pool_span(h, offs, start, end)\n            outputs.append(vec)\n    return outputs\n\n\ndef compute_contextual_similarity(samples: List[MCLWICSample], model, tokenizer, device, batch_size: int) -> pd.DataFrame:\n    sentences1 = [s.sentence1 for s in samples]\n    spans1 = [(s.start1, s.end1) for s in samples]\n    sentences2 = [s.sentence2 for s in samples]\n    spans2 = [(s.start2, s.end2) for s in samples]\n\n    emb1 = batch_contextual_embeddings(model, tokenizer, sentences1, spans1, device, batch_size=batch_size)\n    emb2 = batch_contextual_embeddings(model, tokenizer, sentences2, spans2, device, batch_size=batch_size)\n\n    records = []\n    for s, v1, v2 in zip(samples, emb1, emb2):\n        sim = cosine_sim(v1, v2)\n        records.append(\n            {\n                \\\"id\\\": s.sample_id,\n                \\\"lemma\\\": s.lemma,\n                \\\"pos\\\": s.pos,\n                \\\"label\\\": s.label,\n                \\\"cosine\\\": sim,\n            }\n        )\n    return pd.DataFrame(records)\n\n\ndef stats_summary(df: pd.DataFrame, group_col: str, value_col: str) -> Dict:\n    summary = {}\n    for group, sub in df.groupby(group_col):\n        summary[group] = {\n            \\\"count\\\": int(len(sub)),\n            \\\"mean\\\": float(sub[value_col].mean()),\n            \\\"std\\\": float(sub[value_col].std()),\n            \\\"min\\\": float(sub[value_col].min()),\n            \\\"max\\\": float(sub[value_col].max()),\n        }\n    return summary\n\n\ndef main():\n    setup_logging(Path(\\\"logs/experiment.log\\\"))\n    logging.info(\\\"Starting experiments\\\")\n\n    device = torch.device(\\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\")\n    logging.info(f\\\"Device: {device}\\\")\n\n    # Model\n    model_name = \\\"xlm-roberta-base\\\"\n    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n    model = AutoModel.from_pretrained(model_name)\n    model.to(device)\n    model.eval()\n\n    # Batch size based on GPU memory (24GB -> 64-128)\n    batch_size = 64 if device.type == \\\"cuda\\\" else 16\n\n    # Load MCL-WiC training for polysemy lexicon\n    train_data = Path(\\\"datasets/mcl_wic/data/MCL-WiC/training/training.en-en.data\\\")\n    train_gold = Path(\\\"datasets/mcl_wic/data/MCL-WiC/training/training.en-en.gold\\\")\n    train_samples = load_mcl_wic_training(train_data, train_gold)\n    polysemy_map = build_polysemy_lexicon(train_samples)\n    logging.info(f\\\"Polysemy lexicon size: {len(polysemy_map)}\\\")\n\n    # Static similarity from MUSE dictionaries\n    dict_dir = Path(\\\"datasets/muse_dictionaries/dictionaries\\\")\n    lang_pairs = [\\\"en-fr\\\", \\\"en-ru\\\", \\\"en-zh\\\", \\\"en-ar\\\"]\n    static_frames = []\n    for lp in lang_pairs:\n        try:\n            dict_path = find_dictionary_file(dict_dir, lp)\n        except FileNotFoundError:\n            logging.warning(f\\\"Skipping {lp}: dictionary not found\\\")\n            continue\n        pairs = load_dictionary_pairs(dict_path, limit=2000)\n        df = compute_static_similarity(model, tokenizer, pairs, polysemy_map)\n        df[\\\"lang_pair\\\"] = lp\n        static_frames.append(df)\n    static_df = pd.concat(static_frames, ignore_index=True)\n    static_df.to_csv(\\\"results/static_similarity.csv\\\", index=False)\n\n    # Contextual similarity on MCL-WiC cross-lingual test sets\n    cross_base = Path(\\\"datasets/mcl_wic/data/MCL-WiC/test/crosslingual\\\")\n    gold_base = Path(\\\"datasets/mcl_wic/data_gold\\\")\n    contextual_frames = []\n    for lp in lang_pairs:\n        data_path = cross_base / f\\\"test.{lp}.data\\\"\n        gold_path = gold_base / f\\\"test.{lp}.gold\\\"\n        if not data_path.exists() or not gold_path.exists():\n            logging.warning(f\\\"Skipping {lp}: data or gold missing\\\")\n            continue\n        samples = load_mcl_wic_pair(data_path, gold_path)\n        df = compute_contextual_similarity(samples, model, tokenizer, device, batch_size=batch_size)\n        df[\\\"lang_pair\\\"] = lp\n        contextual_frames.append(df)\n    contextual_df = pd.concat(contextual_frames, ignore_index=True)\n    contextual_df.to_csv(\\\"results/contextual_similarity.csv\\\", index=False)\n\n    # Threshold-based WiC prediction (simple baseline): optimize on dev.en-en\n    dev_data = Path(\\\"datasets/mcl_wic/data/MCL-WiC/dev/multilingual/dev.en-en.data\\\")\n    dev_gold = Path(\\\"datasets/mcl_wic/data/MCL-WiC/dev/multilingual/dev.en-en.gold\\\")\n    if dev_data.exists() and dev_gold.exists():\n        dev_samples = load_mcl_wic_pair(dev_data, dev_gold)\n        dev_df = compute_contextual_similarity(dev_samples, model, tokenizer, device, batch_size=batch_size)\n        # Search threshold on dev\n        best_thr, best_acc = 0.0, 0.0\n        for thr in np.linspace(-1, 1, 81):\n            preds = [\\\"T\\\" if c >= thr else \\\"F\\\" for c in dev_df[\\\"cosine\\\"]]\n            acc = accuracy_score(dev_df[\\\"label\\\"], preds)\n            if acc > best_acc:\n                best_acc = acc\n                best_thr = thr\n    else:\n        best_thr, best_acc = 0.0, None\n\n    # Apply threshold to cross-lingual\n    contextual_df[\\\"pred\\\"] = [\\\"T\\\" if c >= best_thr else \\\"F\\\" for c in contextual_df[\\\"cosine\\\"]]\n    overall_acc = accuracy_score(contextual_df[\\\"label\\\"], contextual_df[\\\"pred\\\"])\n\n    # Polysemy grouping for contextual results\n    contextual_df[\\\"polysemy\\\"] = contextual_df[\\\"lemma\\\"].map(polysemy_map).fillna(\\\"unknown\\\")\n\n    # Statistical tests\n    stats = {\n        \\\"static_similarity\\\": stats_summary(static_df, \\\"pair_type\\\", \\\"cosine\\\"),\n        \\\"contextual_similarity\\\": stats_summary(contextual_df, \\\"label\\\", \\\"cosine\\\"),\n        \\\"polysemy_contextual\\\": stats_summary(contextual_df, \\\"polysemy\\\", \\\"cosine\\\"),\n    }\n\n    # t-test and Mann–Whitney for contextual T vs F\n    t_vals = contextual_df[contextual_df[\\\"label\\\"] == \\\"T\\\"][\\\"cosine\\\"]\n    f_vals = contextual_df[contextual_df[\\\"label\\\"] == \\\"F\\\"][\\\"cosine\\\"]\n    ttest = ttest_ind(t_vals, f_vals, equal_var=False)\n    mwu = mannwhitneyu(t_vals, f_vals, alternative=\\\"two-sided\\\")\n    stats[\\\"contextual_ttest\\\"] = {\\\"t\\\": float(ttest.statistic), \\\"p\\\": float(ttest.pvalue)}\n    stats[\\\"contextual_mwu\\\"] = {\\\"u\\\": float(mwu.statistic), \\\"p\\\": float(mwu.pvalue)}\n\n    # Static similarity polysemy comparison\n    poly_static = static_df[static_df[\\\"polysemy\\\"] == \\\"polysemous\\\"][\\\"cosine\\\"]\n    mono_static = static_df[static_df[\\\"polysemy\\\"] == \\\"monosemous\\\"][\\\"cosine\\\"]\n    if len(poly_static) > 0 and len(mono_static) > 0:\n        ttest_static = ttest_ind(poly_static, mono_static, equal_var=False)\n        stats[\\\"static_polysemy_ttest\\\"] = {\\\"t\\\": float(ttest_static.statistic), \\\"p\\\": float(ttest_static.pvalue)}\n\n    results = {\n        \\\"timestamp\\\": datetime.now().isoformat(),\n        \\\"model\\\": model_name,\n        \\\"device\\\": str(device),\n        \\\"batch_size\\\": batch_size,\n        \\\"dev_threshold\\\": best_thr,\n        \\\"dev_accuracy\\\": best_acc,\n        \\\"crosslingual_accuracy\\\": float(overall_acc),\n        \\\"stats\\\": stats,\n    }\n\n    Path(\\\"results\\\").mkdir(exist_ok=True)\n    with open(\\\"results/metrics.json\\\", \\\"w\\\") as f:\n        json.dump(results, f, indent=2)\n\n    # Basic plots\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n\n    plt.figure(figsize=(7, 4))\n    sns.histplot(data=contextual_df, x=\\\"cosine\\\", hue=\\\"label\\\", bins=40, stat=\\\"density\\\", common_norm=False)\n    plt.title(\\\"Contextual cosine similarity by label (T vs F)\\\")\n    plt.tight_layout()\n    plt.savefig(\\\"figures/contextual_similarity_hist.png\\\", dpi=200)\n    plt.close()\n\n    plt.figure(figsize=(7, 4))\n    sns.boxplot(data=contextual_df, x=\\\"label\\\", y=\\\"cosine\\\")\n    plt.title(\\\"Contextual similarity by label\\\")\n    plt.tight_layout()\n    plt.savefig(\\\"figures/contextual_similarity_box.png\\\", dpi=200)\n    plt.close()\n\n    plt.figure(figsize=(7, 4))\n    sns.boxplot(data=static_df, x=\\\"pair_type\\\", y=\\\"cosine\\\")\n    plt.title(\\\"Static similarity: translation vs mismatch\\\")\n    plt.tight_layout()\n    plt.savefig(\\\"figures/static_similarity_box.png\\\", dpi=200)\n    plt.close()\n\n    plt.figure(figsize=(7, 4))\n    sns.boxplot(data=contextual_df, x=\\\"polysemy\\\", y=\\\"cosine\\\")\n    plt.title(\\\"Contextual similarity by polysemy class\\\")\n    plt.tight_layout()\n    plt.savefig(\\\"figures/contextual_similarity_polysemy.png\\\", dpi=200)\n    plt.close()\n\n    logging.info(\\\"Experiments completed\\\")\n\n\nif __name__ == \\\"__main__\\\":\n    main()\nPY\"","aggregated_output":"","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_74","type":"reasoning","text":"**Planning data checks and experiment run**\n\nConsidering adding an EDA and data quality checks script to handle preparation and logging separately. Next, I'll activate the environment and run experiments via the main script as instructed."}}
{"type":"item.started","item":{"id":"item_75","type":"command_execution","command":"/bin/bash -lc pwd","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_75","type":"command_execution","command":"/bin/bash -lc pwd","aggregated_output":"/data/hypogenicai/workspaces/similar-embeddings-nlp-5ef8-codex\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_76","type":"command_execution","command":"/bin/bash -lc 'source .venv/bin/activate && python src/run_experiments.py'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_77","type":"reasoning","text":"**Polling process status**"}}
{"type":"item.completed","item":{"id":"item_78","type":"reasoning","text":"**Waiting for more output**"}}
{"type":"item.completed","item":{"id":"item_76","type":"command_execution","command":"/bin/bash -lc 'source .venv/bin/activate && python src/run_experiments.py'","aggregated_output":"2026-02-15 19:42:40,291 | INFO | Starting experiments\n2026-02-15 19:42:40,579 | INFO | Device: cuda\n2026-02-15 19:42:40,660 | INFO | HTTP Request: HEAD https://huggingface.co/xlm-roberta-base/resolve/main/config.json \"HTTP/1.1 200 OK\"\n2026-02-15 19:42:40,709 | INFO | HTTP Request: GET https://huggingface.co/xlm-roberta-base/resolve/main/config.json \"HTTP/1.1 200 OK\"\n2026-02-15 19:42:40,762 | INFO | HTTP Request: HEAD https://huggingface.co/xlm-roberta-base/resolve/main/tokenizer_config.json \"HTTP/1.1 200 OK\"\n2026-02-15 19:42:40,802 | INFO | HTTP Request: GET https://huggingface.co/xlm-roberta-base/resolve/main/tokenizer_config.json \"HTTP/1.1 200 OK\"\nWarning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n2026-02-15 19:42:40,802 | WARNING | Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n2026-02-15 19:42:40,842 | INFO | HTTP Request: GET https://huggingface.co/api/models/xlm-roberta-base/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 307 Temporary Redirect\"\n2026-02-15 19:42:40,878 | INFO | HTTP Request: GET https://huggingface.co/api/models/FacebookAI/xlm-roberta-base/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n2026-02-15 19:42:40,916 | INFO | HTTP Request: GET https://huggingface.co/api/models/xlm-roberta-base/tree/main?recursive=true&expand=false \"HTTP/1.1 307 Temporary Redirect\"\n2026-02-15 19:42:40,958 | INFO | HTTP Request: GET https://huggingface.co/api/models/FacebookAI/xlm-roberta-base/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n2026-02-15 19:42:41,005 | INFO | HTTP Request: HEAD https://huggingface.co/xlm-roberta-base/resolve/main/sentencepiece.bpe.model \"HTTP/1.1 200 OK\"\n2026-02-15 19:42:41,041 | INFO | HTTP Request: GET https://huggingface.co/xlm-roberta-base/resolve/main/sentencepiece.bpe.model \"HTTP/1.1 200 OK\"\n2026-02-15 19:42:41,194 | INFO | HTTP Request: HEAD https://huggingface.co/xlm-roberta-base/resolve/main/tokenizer.json \"HTTP/1.1 200 OK\"\n2026-02-15 19:42:41,236 | INFO | HTTP Request: GET https://huggingface.co/xlm-roberta-base/resolve/main/tokenizer.json \"HTTP/1.1 200 OK\"\n2026-02-15 19:42:41,422 | INFO | HTTP Request: HEAD https://huggingface.co/xlm-roberta-base/resolve/main/added_tokens.json \"HTTP/1.1 404 Not Found\"\n2026-02-15 19:42:41,464 | INFO | HTTP Request: HEAD https://huggingface.co/xlm-roberta-base/resolve/main/special_tokens_map.json \"HTTP/1.1 404 Not Found\"\n2026-02-15 19:42:41,566 | INFO | HTTP Request: HEAD https://huggingface.co/xlm-roberta-base/resolve/main/chat_template.jinja \"HTTP/1.1 404 Not Found\"\n2026-02-15 19:42:43,523 | INFO | HTTP Request: GET https://huggingface.co/api/models/xlm-roberta-base \"HTTP/1.1 307 Temporary Redirect\"\n2026-02-15 19:42:43,566 | INFO | HTTP Request: GET https://huggingface.co/api/models/FacebookAI/xlm-roberta-base \"HTTP/1.1 200 OK\"\n2026-02-15 19:42:43,623 | INFO | HTTP Request: HEAD https://huggingface.co/xlm-roberta-base/resolve/main/config.json \"HTTP/1.1 200 OK\"\n2026-02-15 19:42:44,292 | INFO | HTTP Request: HEAD https://huggingface.co/xlm-roberta-base/resolve/main/model.safetensors \"HTTP/1.1 302 Found\"\n2026-02-15 19:42:44,337 | INFO | HTTP Request: GET https://huggingface.co/api/models/FacebookAI/xlm-roberta-base/xet-read-token/e73636d4f797dec63c3081bb6ed5c7b0bb3f2089 \"HTTP/1.1 200 OK\"\n\rLoading weights:   0%|          | 0/199 [00:00<?, ?it/s]\rLoading weights:   1%|          | 1/199 [00:00<00:00, 20360.70it/s, Materializing param=embeddings.LayerNorm.bias]\rLoading weights:   1%|          | 1/199 [00:00<00:00, 7898.88it/s, Materializing param=embeddings.LayerNorm.bias] \rLoading weights:   1%|          | 2/199 [00:00<00:00, 7724.32it/s, Materializing param=embeddings.LayerNorm.weight]\rLoading weights:   1%|          | 2/199 [00:00<00:00, 6369.48it/s, Materializing param=embeddings.LayerNorm.weight]\rLoading weights:   2%|▏         | 3/199 [00:00<00:00, 6174.15it/s, Materializing param=embeddings.position_embeddings.weight]\rLoading weights:   2%|▏         | 3/199 [00:00<00:00, 5523.67it/s, Materializing param=embeddings.position_embeddings.weight]\rLoading weights:   2%|▏         | 4/199 [00:00<00:00, 5917.89it/s, Materializing param=embeddings.token_type_embeddings.weight]\rLoading weights:   2%|▏         | 4/199 [00:00<00:00, 5491.72it/s, Materializing param=embeddings.token_type_embeddings.weight]\rLoading weights:   3%|▎         | 5/199 [00:00<00:00, 5940.94it/s, Materializing param=embeddings.word_embeddings.weight]      \rLoading weights:   3%|▎         | 5/199 [00:00<00:00, 5608.86it/s, Materializing param=embeddings.word_embeddings.weight]\rLoading weights:   3%|▎         | 6/199 [00:00<00:00, 5903.31it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]\rLoading weights:   3%|▎         | 6/199 [00:00<00:00, 5607.36it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]\rLoading weights:   4%|▎         | 7/199 [00:00<00:00, 5689.95it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\rLoading weights:   4%|▎         | 7/199 [00:00<00:00, 5444.12it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\rLoading weights:   4%|▍         | 8/199 [00:00<00:00, 4317.35it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]      \rLoading weights:   4%|▍         | 8/199 [00:00<00:00, 4194.30it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]\rLoading weights:   5%|▍         | 9/199 [00:00<00:00, 3065.51it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\rLoading weights:   5%|▍         | 9/199 [00:00<00:00, 3007.15it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\rLoading weights:   5%|▌         | 10/199 [00:00<00:00, 3189.83it/s, Materializing param=encoder.layer.0.attention.self.key.bias]     \rLoading weights:   5%|▌         | 10/199 [00:00<00:00, 3135.93it/s, Materializing param=encoder.layer.0.attention.self.key.bias]\rLoading weights:   6%|▌         | 11/199 [00:00<00:00, 2949.96it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\rLoading weights:   6%|▌         | 11/199 [00:00<00:00, 2906.66it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\rLoading weights:   6%|▌         | 12/199 [00:00<00:00, 2831.28it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\rLoading weights:   6%|▌         | 12/199 [00:00<00:00, 2795.12it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\rLoading weights:   7%|▋         | 13/199 [00:00<00:00, 2934.97it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\rLoading weights:   7%|▋         | 13/199 [00:00<00:00, 2899.70it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\rLoading weights:   7%|▋         | 14/199 [00:00<00:00, 3020.74it/s, Materializing param=encoder.layer.0.attention.self.value.bias]  \rLoading weights:   7%|▋         | 14/199 [00:00<00:00, 2985.42it/s, Materializing param=encoder.layer.0.attention.self.value.bias]\rLoading weights:   8%|▊         | 15/199 [00:00<00:00, 3099.85it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\rLoading weights:   8%|▊         | 15/199 [00:00<00:00, 3065.41it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\rLoading weights:   8%|▊         | 16/199 [00:00<00:00, 2511.09it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]    \rLoading weights:   8%|▊         | 16/199 [00:00<00:00, 2427.35it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]\rLoading weights:   9%|▊         | 17/199 [00:00<00:00, 2492.77it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\rLoading weights:   9%|▊         | 17/199 [00:00<00:00, 2465.62it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\rLoading weights:   9%|▉         | 18/199 [00:00<00:00, 2501.49it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]    \rLoading weights:   9%|▉         | 18/199 [00:00<00:00, 2401.85it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]\rLoading weights:  10%|▉         | 19/199 [00:00<00:00, 2229.89it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\rLoading weights:  10%|▉         | 19/199 [00:00<00:00, 2075.04it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\rLoading weights:  10%|█         | 20/199 [00:00<00:00, 2131.09it/s, Materializing param=encoder.layer.0.output.dense.bias]      \rLoading weights:  10%|█         | 20/199 [00:00<00:00, 2089.84it/s, Materializing param=encoder.layer.0.output.dense.bias]\rLoading weights:  11%|█         | 21/199 [00:00<00:00, 2148.41it/s, Materializing param=encoder.layer.0.output.dense.weight]\rLoading weights:  11%|█         | 21/199 [00:00<00:00, 2110.72it/s, Materializing param=encoder.layer.0.output.dense.weight]\rLoading weights:  11%|█         | 22/199 [00:00<00:00, 2167.90it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\rLoading weights:  11%|█         | 22/199 [00:00<00:00, 2151.53it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\rLoading weights:  12%|█▏        | 23/199 [00:00<00:00, 2149.15it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]\rLoading weights:  12%|█▏        | 23/199 [00:00<00:00, 2024.32it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]\rLoading weights:  12%|█▏        | 24/199 [00:00<00:00, 2033.68it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]      \rLoading weights:  12%|█▏        | 24/199 [00:00<00:00, 1971.35it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]\rLoading weights:  13%|█▎        | 25/199 [00:00<00:00, 2011.73it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\rLoading weights:  13%|█▎        | 25/199 [00:00<00:00, 1977.18it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\rLoading weights:  13%|█▎        | 26/199 [00:00<00:00, 1952.66it/s, Materializing param=encoder.layer.1.attention.self.key.bias]      \rLoading weights:  13%|█▎        | 26/199 [00:00<00:00, 1863.78it/s, Materializing param=encoder.layer.1.attention.self.key.bias]\rLoading weights:  14%|█▎        | 27/199 [00:00<00:00, 1905.86it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\rLoading weights:  14%|█▎        | 27/199 [00:00<00:00, 1878.92it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\rLoading weights:  14%|█▍        | 28/199 [00:00<00:00, 1903.78it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\rLoading weights:  14%|█▍        | 28/199 [00:00<00:00, 1860.71it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\rLoading weights:  15%|█▍        | 29/199 [00:00<00:00, 1868.63it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\rLoading weights:  15%|█▍        | 29/199 [00:00<00:00, 1835.25it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\rLoading weights:  15%|█▌        | 30/199 [00:00<00:00, 1862.84it/s, Materializing param=encoder.layer.1.attention.self.value.bias]  \rLoading weights:  15%|█▌        | 30/199 [00:00<00:00, 1853.26it/s, Materializing param=encoder.layer.1.attention.self.value.bias]\rLoading weights:  16%|█▌        | 31/199 [00:00<00:00, 1811.26it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\rLoading weights:  16%|█▌        | 31/199 [00:00<00:00, 1793.20it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\rLoading weights:  16%|█▌        | 32/199 [00:00<00:00, 1798.42it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]    \rLoading weights:  16%|█▌        | 32/199 [00:00<00:00, 1789.26it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]\rLoading weights:  17%|█▋        | 33/199 [00:00<00:00, 1808.29it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\rLoading weights:  17%|█▋        | 33/199 [00:00<00:00, 1796.21it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\rLoading weights:  17%|█▋        | 34/199 [00:00<00:00, 1803.66it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]    \rLoading weights:  17%|█▋        | 34/199 [00:00<00:00, 1789.27it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]\rLoading weights:  18%|█▊        | 35/199 [00:00<00:00, 1814.08it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\rLoading weights:  18%|█▊        | 35/199 [00:00<00:00, 1789.29it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\rLoading weights:  18%|█▊        | 36/199 [00:00<00:00, 1808.39it/s, Materializing param=encoder.layer.1.output.dense.bias]      \rLoading weights:  18%|█▊        | 36/199 [00:00<00:00, 1793.03it/s, Materializing param=encoder.layer.1.output.dense.bias]\rLoading weights:  19%|█▊        | 37/199 [00:00<00:00, 1786.43it/s, Materializing param=encoder.layer.1.output.dense.weight]\rLoading weights:  19%|█▊        | 37/199 [00:00<00:00, 1774.81it/s, Materializing param=encoder.layer.1.output.dense.weight]\rLoading weights:  19%|█▉        | 38/199 [00:00<00:00, 1803.27it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\rLoading weights:  19%|█▉        | 38/199 [00:00<00:00, 1791.93it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\rLoading weights:  20%|█▉        | 39/199 [00:00<00:00, 1817.94it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\rLoading weights:  20%|█▉        | 39/199 [00:00<00:00, 1811.91it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\rLoading weights:  20%|██        | 40/199 [00:00<00:00, 1835.90it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]      \rLoading weights:  20%|██        | 40/199 [00:00<00:00, 1823.31it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]\rLoading weights:  21%|██        | 41/199 [00:00<00:00, 1842.50it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\rLoading weights:  21%|██        | 41/199 [00:00<00:00, 1828.81it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\rLoading weights:  21%|██        | 42/199 [00:00<00:00, 1848.74it/s, Materializing param=encoder.layer.2.attention.self.key.bias]      \rLoading weights:  21%|██        | 42/199 [00:00<00:00, 1827.09it/s, Materializing param=encoder.layer.2.attention.self.key.bias]\rLoading weights:  22%|██▏       | 43/199 [00:00<00:00, 1848.54it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\rLoading weights:  22%|██▏       | 43/199 [00:00<00:00, 1843.07it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\rLoading weights:  22%|██▏       | 44/199 [00:00<00:00, 1868.06it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\rLoading weights:  22%|██▏       | 44/199 [00:00<00:00, 1822.69it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\rLoading weights:  23%|██▎       | 45/199 [00:00<00:00, 1774.22it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\rLoading weights:  23%|██▎       | 45/199 [00:00<00:00, 1754.97it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\rLoading weights:  23%|██▎       | 46/199 [00:00<00:00, 1762.02it/s, Materializing param=encoder.layer.2.attention.self.value.bias]  \rLoading weights:  23%|██▎       | 46/199 [00:00<00:00, 1725.08it/s, Materializing param=encoder.layer.2.attention.self.value.bias]\rLoading weights:  24%|██▎       | 47/199 [00:00<00:00, 1721.50it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\rLoading weights:  24%|██▎       | 47/199 [00:00<00:00, 1693.18it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\rLoading weights:  24%|██▍       | 48/199 [00:00<00:00, 1709.16it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]    \rLoading weights:  24%|██▍       | 48/199 [00:00<00:00, 1696.75it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]\rLoading weights:  25%|██▍       | 49/199 [00:00<00:00, 1715.22it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\rLoading weights:  25%|██▍       | 49/199 [00:00<00:00, 1692.78it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\rLoading weights:  25%|██▌       | 50/199 [00:00<00:00, 1689.56it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]    \rLoading weights:  25%|██▌       | 50/199 [00:00<00:00, 1675.54it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]\rLoading weights:  26%|██▌       | 51/199 [00:00<00:00, 1668.87it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\rLoading weights:  26%|██▌       | 51/199 [00:00<00:00, 1648.35it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\rLoading weights:  26%|██▌       | 52/199 [00:00<00:00, 1632.11it/s, Materializing param=encoder.layer.2.output.dense.bias]      \rLoading weights:  26%|██▌       | 52/199 [00:00<00:00, 1624.11it/s, Materializing param=encoder.layer.2.output.dense.bias]\rLoading weights:  27%|██▋       | 53/199 [00:00<00:00, 1619.50it/s, Materializing param=encoder.layer.2.output.dense.weight]\rLoading weights:  27%|██▋       | 53/199 [00:00<00:00, 1613.38it/s, Materializing param=encoder.layer.2.output.dense.weight]\rLoading weights:  27%|██▋       | 54/199 [00:00<00:00, 1621.17it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\rLoading weights:  27%|██▋       | 54/199 [00:00<00:00, 1614.63it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\rLoading weights:  28%|██▊       | 55/199 [00:00<00:00, 1621.13it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\rLoading weights:  28%|██▊       | 55/199 [00:00<00:00, 1601.28it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\rLoading weights:  28%|██▊       | 56/199 [00:00<00:00, 1601.18it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]      \rLoading weights:  28%|██▊       | 56/199 [00:00<00:00, 1585.32it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]\rLoading weights:  29%|██▊       | 57/199 [00:00<00:00, 1594.92it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\rLoading weights:  29%|██▊       | 57/199 [00:00<00:00, 1581.15it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\rLoading weights:  29%|██▉       | 58/199 [00:00<00:00, 1597.36it/s, Materializing param=encoder.layer.3.attention.self.key.bias]      \rLoading weights:  29%|██▉       | 58/199 [00:00<00:00, 1589.35it/s, Materializing param=encoder.layer.3.attention.self.key.bias]\rLoading weights:  30%|██▉       | 59/199 [00:00<00:00, 1578.09it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\rLoading weights:  30%|██▉       | 59/199 [00:00<00:00, 1564.57it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\rLoading weights:  30%|███       | 60/199 [00:00<00:00, 1562.43it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\rLoading weights:  30%|███       | 60/199 [00:00<00:00, 1552.34it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\rLoading weights:  31%|███       | 61/199 [00:00<00:00, 1566.01it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\rLoading weights:  31%|███       | 61/199 [00:00<00:00, 1561.85it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\rLoading weights:  31%|███       | 62/199 [00:00<00:00, 1572.48it/s, Materializing param=encoder.layer.3.attention.self.value.bias]  \rLoading weights:  31%|███       | 62/199 [00:00<00:00, 1565.24it/s, Materializing param=encoder.layer.3.attention.self.value.bias]\rLoading weights:  32%|███▏      | 63/199 [00:00<00:00, 1573.27it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\rLoading weights:  32%|███▏      | 63/199 [00:00<00:00, 1558.26it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\rLoading weights:  32%|███▏      | 64/199 [00:00<00:00, 1556.43it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]    \rLoading weights:  32%|███▏      | 64/199 [00:00<00:00, 1549.65it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]\rLoading weights:  33%|███▎      | 65/199 [00:00<00:00, 1550.03it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\rLoading weights:  33%|███▎      | 65/199 [00:00<00:00, 1526.50it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\rLoading weights:  33%|███▎      | 66/199 [00:00<00:00, 1540.02it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]    \rLoading weights:  33%|███▎      | 66/199 [00:00<00:00, 1532.69it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]\rLoading weights:  34%|███▎      | 67/199 [00:00<00:00, 1541.39it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\rLoading weights:  34%|███▎      | 67/199 [00:00<00:00, 1520.38it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\rLoading weights:  34%|███▍      | 68/199 [00:00<00:00, 1535.93it/s, Materializing param=encoder.layer.3.output.dense.bias]      \rLoading weights:  34%|███▍      | 68/199 [00:00<00:00, 1526.70it/s, Materializing param=encoder.layer.3.output.dense.bias]\rLoading weights:  35%|███▍      | 69/199 [00:00<00:00, 1540.99it/s, Materializing param=encoder.layer.3.output.dense.weight]\rLoading weights:  35%|███▍      | 69/199 [00:00<00:00, 1538.25it/s, Materializing param=encoder.layer.3.output.dense.weight]\rLoading weights:  35%|███▌      | 70/199 [00:00<00:00, 1545.07it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\rLoading weights:  35%|███▌      | 70/199 [00:00<00:00, 1537.49it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\rLoading weights:  36%|███▌      | 71/199 [00:00<00:00, 1547.11it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\rLoading weights:  36%|███▌      | 71/199 [00:00<00:00, 1543.23it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\rLoading weights:  36%|███▌      | 72/199 [00:00<00:00, 1559.98it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]      \rLoading weights:  36%|███▌      | 72/199 [00:00<00:00, 1557.70it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]\rLoading weights:  37%|███▋      | 73/199 [00:00<00:00, 1574.56it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\rLoading weights:  37%|███▋      | 73/199 [00:00<00:00, 1572.27it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\rLoading weights:  37%|███▋      | 74/199 [00:00<00:00, 1589.01it/s, Materializing param=encoder.layer.4.attention.self.key.bias]      \rLoading weights:  37%|███▋      | 74/199 [00:00<00:00, 1586.66it/s, Materializing param=encoder.layer.4.attention.self.key.bias]\rLoading weights:  38%|███▊      | 75/199 [00:00<00:00, 1603.38it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\rLoading weights:  38%|███▊      | 75/199 [00:00<00:00, 1601.04it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\rLoading weights:  38%|███▊      | 76/199 [00:00<00:00, 1617.70it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\rLoading weights:  38%|███▊      | 76/199 [00:00<00:00, 1615.37it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\rLoading weights:  39%|███▊      | 77/199 [00:00<00:00, 1631.79it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\rLoading weights:  39%|███▊      | 77/199 [00:00<00:00, 1629.44it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\rLoading weights:  39%|███▉      | 78/199 [00:00<00:00, 1645.88it/s, Materializing param=encoder.layer.4.attention.self.value.bias]  \rLoading weights:  39%|███▉      | 78/199 [00:00<00:00, 1643.54it/s, Materializing param=encoder.layer.4.attention.self.value.bias]\rLoading weights:  40%|███▉      | 79/199 [00:00<00:00, 1659.85it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\rLoading weights:  40%|███▉      | 79/199 [00:00<00:00, 1657.47it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\rLoading weights:  40%|████      | 80/199 [00:00<00:00, 1673.64it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]    \rLoading weights:  40%|████      | 80/199 [00:00<00:00, 1671.34it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]\rLoading weights:  41%|████      | 81/199 [00:00<00:00, 1687.70it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\rLoading weights:  41%|████      | 81/199 [00:00<00:00, 1685.39it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\rLoading weights:  41%|████      | 82/199 [00:00<00:00, 1702.11it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]    \rLoading weights:  41%|████      | 82/199 [00:00<00:00, 1699.79it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]\rLoading weights:  42%|████▏     | 83/199 [00:00<00:00, 1715.83it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\rLoading weights:  42%|████▏     | 83/199 [00:00<00:00, 1713.45it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\rLoading weights:  42%|████▏     | 84/199 [00:00<00:00, 1729.42it/s, Materializing param=encoder.layer.4.output.dense.bias]      \rLoading weights:  42%|████▏     | 84/199 [00:00<00:00, 1727.04it/s, Materializing param=encoder.layer.4.output.dense.bias]\rLoading weights:  43%|████▎     | 85/199 [00:00<00:00, 1742.92it/s, Materializing param=encoder.layer.4.output.dense.weight]\rLoading weights:  43%|████▎     | 85/199 [00:00<00:00, 1740.53it/s, Materializing param=encoder.layer.4.output.dense.weight]\rLoading weights:  43%|████▎     | 86/199 [00:00<00:00, 1756.25it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\rLoading weights:  43%|████▎     | 86/199 [00:00<00:00, 1753.75it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\rLoading weights:  44%|████▎     | 87/199 [00:00<00:00, 1769.07it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\rLoading weights:  44%|████▎     | 87/199 [00:00<00:00, 1765.48it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\rLoading weights:  44%|████▍     | 88/199 [00:00<00:00, 1780.74it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]      \rLoading weights:  44%|████▍     | 88/199 [00:00<00:00, 1778.23it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]\rLoading weights:  45%|████▍     | 89/199 [00:00<00:00, 1793.45it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\rLoading weights:  45%|████▍     | 89/199 [00:00<00:00, 1790.98it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\rLoading weights:  45%|████▌     | 90/199 [00:00<00:00, 1806.18it/s, Materializing param=encoder.layer.5.attention.self.key.bias]      \rLoading weights:  45%|████▌     | 90/199 [00:00<00:00, 1803.73it/s, Materializing param=encoder.layer.5.attention.self.key.bias]\rLoading weights:  46%|████▌     | 91/199 [00:00<00:00, 1818.87it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\rLoading weights:  46%|████▌     | 91/199 [00:00<00:00, 1816.43it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\rLoading weights:  46%|████▌     | 92/199 [00:00<00:00, 1831.29it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\rLoading weights:  46%|████▌     | 92/199 [00:00<00:00, 1828.70it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\rLoading weights:  47%|████▋     | 93/199 [00:00<00:00, 1843.35it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\rLoading weights:  47%|████▋     | 93/199 [00:00<00:00, 1840.93it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\rLoading weights:  47%|████▋     | 94/199 [00:00<00:00, 1855.79it/s, Materializing param=encoder.layer.5.attention.self.value.bias]  \rLoading weights:  47%|████▋     | 94/199 [00:00<00:00, 1853.34it/s, Materializing param=encoder.layer.5.attention.self.value.bias]\rLoading weights:  48%|████▊     | 95/199 [00:00<00:00, 1868.07it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\rLoading weights:  48%|████▊     | 95/199 [00:00<00:00, 1865.65it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\rLoading weights:  48%|████▊     | 96/199 [00:00<00:00, 1880.29it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]    \rLoading weights:  48%|████▊     | 96/199 [00:00<00:00, 1877.83it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]\rLoading weights:  49%|████▊     | 97/199 [00:00<00:00, 1892.32it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\rLoading weights:  49%|████▊     | 97/199 [00:00<00:00, 1889.75it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\rLoading weights:  49%|████▉     | 98/199 [00:00<00:00, 1904.29it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]    \rLoading weights:  49%|████▉     | 98/199 [00:00<00:00, 1901.76it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]\rLoading weights:  50%|████▉     | 99/199 [00:00<00:00, 1915.90it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\rLoading weights:  50%|████▉     | 99/199 [00:00<00:00, 1913.38it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\rLoading weights:  50%|█████     | 100/199 [00:00<00:00, 1927.79it/s, Materializing param=encoder.layer.5.output.dense.bias]     \rLoading weights:  50%|█████     | 100/199 [00:00<00:00, 1925.30it/s, Materializing param=encoder.layer.5.output.dense.bias]\rLoading weights:  51%|█████     | 101/199 [00:00<00:00, 1939.65it/s, Materializing param=encoder.layer.5.output.dense.weight]\rLoading weights:  51%|█████     | 101/199 [00:00<00:00, 1937.18it/s, Materializing param=encoder.layer.5.output.dense.weight]\rLoading weights:  51%|█████▏    | 102/199 [00:00<00:00, 1951.23it/s, Materializing param=encoder.layer.6.attention.output.LayerNorm.bias]\rLoading weights:  51%|█████▏    | 102/199 [00:00<00:00, 1948.67it/s, Materializing param=encoder.layer.6.attention.output.LayerNorm.bias]\rLoading weights:  52%|█████▏    | 103/199 [00:00<00:00, 1962.60it/s, Materializing param=encoder.layer.6.attention.output.LayerNorm.weight]\rLoading weights:  52%|█████▏    | 103/199 [00:00<00:00, 1959.99it/s, Materializing param=encoder.layer.6.attention.output.LayerNorm.weight]\rLoading weights:  52%|█████▏    | 104/199 [00:00<00:00, 1973.85it/s, Materializing param=encoder.layer.6.attention.output.dense.bias]      \rLoading weights:  52%|█████▏    | 104/199 [00:00<00:00, 1971.26it/s, Materializing param=encoder.layer.6.attention.output.dense.bias]\rLoading weights:  53%|█████▎    | 105/199 [00:00<00:00, 1984.99it/s, Materializing param=encoder.layer.6.attention.output.dense.weight]\rLoading weights:  53%|█████▎    | 105/199 [00:00<00:00, 1982.27it/s, Materializing param=encoder.layer.6.attention.output.dense.weight]\rLoading weights:  53%|█████▎    | 106/199 [00:00<00:00, 1996.49it/s, Materializing param=encoder.layer.6.attention.self.key.bias]      \rLoading weights:  53%|█████▎    | 106/199 [00:00<00:00, 1994.05it/s, Materializing param=encoder.layer.6.attention.self.key.bias]\rLoading weights:  54%|█████▍    | 107/199 [00:00<00:00, 2007.31it/s, Materializing param=encoder.layer.6.attention.self.key.weight]\rLoading weights:  54%|█████▍    | 107/199 [00:00<00:00, 2004.71it/s, Materializing param=encoder.layer.6.attention.self.key.weight]\rLoading weights:  54%|█████▍    | 108/199 [00:00<00:00, 2018.18it/s, Materializing param=encoder.layer.6.attention.self.query.bias]\rLoading weights:  54%|█████▍    | 108/199 [00:00<00:00, 2015.62it/s, Materializing param=encoder.layer.6.attention.self.query.bias]\rLoading weights:  55%|█████▍    | 109/199 [00:00<00:00, 2029.10it/s, Materializing param=encoder.layer.6.attention.self.query.weight]\rLoading weights:  55%|█████▍    | 109/199 [00:00<00:00, 2026.45it/s, Materializing param=encoder.layer.6.attention.self.query.weight]\rLoading weights:  55%|█████▌    | 110/199 [00:00<00:00, 2039.83it/s, Materializing param=encoder.layer.6.attention.self.value.bias]  \rLoading weights:  55%|█████▌    | 110/199 [00:00<00:00, 2037.37it/s, Materializing param=encoder.layer.6.attention.self.value.bias]\rLoading weights:  56%|█████▌    | 111/199 [00:00<00:00, 2051.38it/s, Materializing param=encoder.layer.6.attention.self.value.weight]\rLoading weights:  56%|█████▌    | 111/199 [00:00<00:00, 2048.87it/s, Materializing param=encoder.layer.6.attention.self.value.weight]\rLoading weights:  56%|█████▋    | 112/199 [00:00<00:00, 2062.19it/s, Materializing param=encoder.layer.6.intermediate.dense.bias]    \rLoading weights:  56%|█████▋    | 112/199 [00:00<00:00, 2059.62it/s, Materializing param=encoder.layer.6.intermediate.dense.bias]\rLoading weights:  57%|█████▋    | 113/199 [00:00<00:00, 2072.83it/s, Materializing param=encoder.layer.6.intermediate.dense.weight]\rLoading weights:  57%|█████▋    | 113/199 [00:00<00:00, 2070.24it/s, Materializing param=encoder.layer.6.intermediate.dense.weight]\rLoading weights:  57%|█████▋    | 114/199 [00:00<00:00, 2084.02it/s, Materializing param=encoder.layer.6.output.LayerNorm.bias]    \rLoading weights:  57%|█████▋    | 114/199 [00:00<00:00, 2081.59it/s, Materializing param=encoder.layer.6.output.LayerNorm.bias]\rLoading weights:  58%|█████▊    | 115/199 [00:00<00:00, 2095.39it/s, Materializing param=encoder.layer.6.output.LayerNorm.weight]\rLoading weights:  58%|█████▊    | 115/199 [00:00<00:00, 2092.95it/s, Materializing param=encoder.layer.6.output.LayerNorm.weight]\rLoading weights:  58%|█████▊    | 116/199 [00:00<00:00, 2106.73it/s, Materializing param=encoder.layer.6.output.dense.bias]      \rLoading weights:  58%|█████▊    | 116/199 [00:00<00:00, 2104.22it/s, Materializing param=encoder.layer.6.output.dense.bias]\rLoading weights:  59%|█████▉    | 117/199 [00:00<00:00, 2117.96it/s, Materializing param=encoder.layer.6.output.dense.weight]\rLoading weights:  59%|█████▉    | 117/199 [00:00<00:00, 2115.55it/s, Materializing param=encoder.layer.6.output.dense.weight]\rLoading weights:  59%|█████▉    | 118/199 [00:00<00:00, 2128.52it/s, Materializing param=encoder.layer.7.attention.output.LayerNorm.bias]\rLoading weights:  59%|█████▉    | 118/199 [00:00<00:00, 2125.85it/s, Materializing param=encoder.layer.7.attention.output.LayerNorm.bias]\rLoading weights:  60%|█████▉    | 119/199 [00:00<00:00, 2138.90it/s, Materializing param=encoder.layer.7.attention.output.LayerNorm.weight]\rLoading weights:  60%|█████▉    | 119/199 [00:00<00:00, 2136.06it/s, Materializing param=encoder.layer.7.attention.output.LayerNorm.weight]\rLoading weights:  60%|██████    | 120/199 [00:00<00:00, 2148.80it/s, Materializing param=encoder.layer.7.attention.output.dense.bias]      \rLoading weights:  60%|██████    | 120/199 [00:00<00:00, 2146.29it/s, Materializing param=encoder.layer.7.attention.output.dense.bias]\rLoading weights:  61%|██████    | 121/199 [00:00<00:00, 2159.33it/s, Materializing param=encoder.layer.7.attention.output.dense.weight]\rLoading weights:  61%|██████    | 121/199 [00:00<00:00, 2156.85it/s, Materializing param=encoder.layer.7.attention.output.dense.weight]\rLoading weights:  61%|██████▏   | 122/199 [00:00<00:00, 2169.94it/s, Materializing param=encoder.layer.7.attention.self.key.bias]      \rLoading weights:  61%|██████▏   | 122/199 [00:00<00:00, 2167.48it/s, Materializing param=encoder.layer.7.attention.self.key.bias]\rLoading weights:  62%|██████▏   | 123/199 [00:00<00:00, 2180.35it/s, Materializing param=encoder.layer.7.attention.self.key.weight]\rLoading weights:  62%|██████▏   | 123/199 [00:00<00:00, 2177.76it/s, Materializing param=encoder.layer.7.attention.self.key.weight]\rLoading weights:  62%|██████▏   | 124/199 [00:00<00:00, 2190.36it/s, Materializing param=encoder.layer.7.attention.self.query.bias]\rLoading weights:  62%|██████▏   | 124/199 [00:00<00:00, 2187.78it/s, Materializing param=encoder.layer.7.attention.self.query.bias]\rLoading weights:  63%|██████▎   | 125/199 [00:00<00:00, 2200.56it/s, Materializing param=encoder.layer.7.attention.self.query.weight]\rLoading weights:  63%|██████▎   | 125/199 [00:00<00:00, 2198.07it/s, Materializing param=encoder.layer.7.attention.self.query.weight]\rLoading weights:  63%|██████▎   | 126/199 [00:00<00:00, 2210.88it/s, Materializing param=encoder.layer.7.attention.self.value.bias]  \rLoading weights:  63%|██████▎   | 126/199 [00:00<00:00, 2208.40it/s, Materializing param=encoder.layer.7.attention.self.value.bias]\rLoading weights:  64%|██████▍   | 127/199 [00:00<00:00, 2221.11it/s, Materializing param=encoder.layer.7.attention.self.value.weight]\rLoading weights:  64%|██████▍   | 127/199 [00:00<00:00, 2217.17it/s, Materializing param=encoder.layer.7.attention.self.value.weight]\rLoading weights:  64%|██████▍   | 128/199 [00:00<00:00, 2229.73it/s, Materializing param=encoder.layer.7.intermediate.dense.bias]    \rLoading weights:  64%|██████▍   | 128/199 [00:00<00:00, 2227.23it/s, Materializing param=encoder.layer.7.intermediate.dense.bias]\rLoading weights:  65%|██████▍   | 129/199 [00:00<00:00, 2239.93it/s, Materializing param=encoder.layer.7.intermediate.dense.weight]\rLoading weights:  65%|██████▍   | 129/199 [00:00<00:00, 2237.42it/s, Materializing param=encoder.layer.7.intermediate.dense.weight]\rLoading weights:  65%|██████▌   | 130/199 [00:00<00:00, 2249.86it/s, Materializing param=encoder.layer.7.output.LayerNorm.bias]    \rLoading weights:  65%|██████▌   | 130/199 [00:00<00:00, 2247.27it/s, Materializing param=encoder.layer.7.output.LayerNorm.bias]\rLoading weights:  66%|██████▌   | 131/199 [00:00<00:00, 2259.17it/s, Materializing param=encoder.layer.7.output.LayerNorm.weight]\rLoading weights:  66%|██████▌   | 131/199 [00:00<00:00, 2256.54it/s, Materializing param=encoder.layer.7.output.LayerNorm.weight]\rLoading weights:  66%|██████▋   | 132/199 [00:00<00:00, 2267.58it/s, Materializing param=encoder.layer.7.output.dense.bias]      \rLoading weights:  66%|██████▋   | 132/199 [00:00<00:00, 2264.36it/s, Materializing param=encoder.layer.7.output.dense.bias]\rLoading weights:  67%|██████▋   | 133/199 [00:00<00:00, 2275.90it/s, Materializing param=encoder.layer.7.output.dense.weight]\rLoading weights:  67%|██████▋   | 133/199 [00:00<00:00, 2273.71it/s, Materializing param=encoder.layer.7.output.dense.weight]\rLoading weights:  67%|██████▋   | 134/199 [00:00<00:00, 2287.71it/s, Materializing param=encoder.layer.8.attention.output.LayerNorm.bias]\rLoading weights:  67%|██████▋   | 134/199 [00:00<00:00, 2285.96it/s, Materializing param=encoder.layer.8.attention.output.LayerNorm.bias]\rLoading weights:  68%|██████▊   | 135/199 [00:00<00:00, 2299.42it/s, Materializing param=encoder.layer.8.attention.output.LayerNorm.weight]\rLoading weights:  68%|██████▊   | 135/199 [00:00<00:00, 2297.48it/s, Materializing param=encoder.layer.8.attention.output.LayerNorm.weight]\rLoading weights:  68%|██████▊   | 136/199 [00:00<00:00, 2310.11it/s, Materializing param=encoder.layer.8.attention.output.dense.bias]      \rLoading weights:  68%|██████▊   | 136/199 [00:00<00:00, 2308.14it/s, Materializing param=encoder.layer.8.attention.output.dense.bias]\rLoading weights:  69%|██████▉   | 137/199 [00:00<00:00, 2321.75it/s, Materializing param=encoder.layer.8.attention.output.dense.weight]\rLoading weights:  69%|██████▉   | 137/199 [00:00<00:00, 2319.91it/s, Materializing param=encoder.layer.8.attention.output.dense.weight]\rLoading weights:  69%|██████▉   | 138/199 [00:00<00:00, 2332.89it/s, Materializing param=encoder.layer.8.attention.self.key.bias]      \rLoading weights:  69%|██████▉   | 138/199 [00:00<00:00, 2330.92it/s, Materializing param=encoder.layer.8.attention.self.key.bias]\rLoading weights:  70%|██████▉   | 139/199 [00:00<00:00, 2343.64it/s, Materializing param=encoder.layer.8.attention.self.key.weight]\rLoading weights:  70%|██████▉   | 139/199 [00:00<00:00, 2341.62it/s, Materializing param=encoder.layer.8.attention.self.key.weight]\rLoading weights:  70%|███████   | 140/199 [00:00<00:00, 2354.29it/s, Materializing param=encoder.layer.8.attention.self.query.bias]\rLoading weights:  70%|███████   | 140/199 [00:00<00:00, 2352.32it/s, Materializing param=encoder.layer.8.attention.self.query.bias]\rLoading weights:  71%|███████   | 141/199 [00:00<00:00, 2364.82it/s, Materializing param=encoder.layer.8.attention.self.query.weight]\rLoading weights:  71%|███████   | 141/199 [00:00<00:00, 2362.79it/s, Materializing param=encoder.layer.8.attention.self.query.weight]\rLoading weights:  71%|███████▏  | 142/199 [00:00<00:00, 2375.69it/s, Materializing param=encoder.layer.8.attention.self.value.bias]  \rLoading weights:  71%|███████▏  | 142/199 [00:00<00:00, 2373.84it/s, Materializing param=encoder.layer.8.attention.self.value.bias]\rLoading weights:  72%|███████▏  | 143/199 [00:00<00:00, 2386.70it/s, Materializing param=encoder.layer.8.attention.self.value.weight]\rLoading weights:  72%|███████▏  | 143/199 [00:00<00:00, 2384.75it/s, Materializing param=encoder.layer.8.attention.self.value.weight]\rLoading weights:  72%|███████▏  | 144/199 [00:00<00:00, 2397.57it/s, Materializing param=encoder.layer.8.intermediate.dense.bias]    \rLoading weights:  72%|███████▏  | 144/199 [00:00<00:00, 2395.65it/s, Materializing param=encoder.layer.8.intermediate.dense.bias]\rLoading weights:  73%|███████▎  | 145/199 [00:00<00:00, 2408.75it/s, Materializing param=encoder.layer.8.intermediate.dense.weight]\rLoading weights:  73%|███████▎  | 145/199 [00:00<00:00, 2406.87it/s, Materializing param=encoder.layer.8.intermediate.dense.weight]\rLoading weights:  73%|███████▎  | 146/199 [00:00<00:00, 2419.86it/s, Materializing param=encoder.layer.8.output.LayerNorm.bias]    \rLoading weights:  73%|███████▎  | 146/199 [00:00<00:00, 2417.85it/s, Materializing param=encoder.layer.8.output.LayerNorm.bias]\rLoading weights:  74%|███████▍  | 147/199 [00:00<00:00, 2430.55it/s, Materializing param=encoder.layer.8.output.LayerNorm.weight]\rLoading weights:  74%|███████▍  | 147/199 [00:00<00:00, 2428.66it/s, Materializing param=encoder.layer.8.output.LayerNorm.weight]\rLoading weights:  74%|███████▍  | 148/199 [00:00<00:00, 2441.60it/s, Materializing param=encoder.layer.8.output.dense.bias]      \rLoading weights:  74%|███████▍  | 148/199 [00:00<00:00, 2439.65it/s, Materializing param=encoder.layer.8.output.dense.bias]\rLoading weights:  75%|███████▍  | 149/199 [00:00<00:00, 2452.05it/s, Materializing param=encoder.layer.8.output.dense.weight]\rLoading weights:  75%|███████▍  | 149/199 [00:00<00:00, 2450.14it/s, Materializing param=encoder.layer.8.output.dense.weight]\rLoading weights:  75%|███████▌  | 150/199 [00:00<00:00, 2463.16it/s, Materializing param=encoder.layer.9.attention.output.LayerNorm.bias]\rLoading weights:  75%|███████▌  | 150/199 [00:00<00:00, 2461.23it/s, Materializing param=encoder.layer.9.attention.output.LayerNorm.bias]\rLoading weights:  76%|███████▌  | 151/199 [00:00<00:00, 2473.51it/s, Materializing param=encoder.layer.9.attention.output.LayerNorm.weight]\rLoading weights:  76%|███████▌  | 151/199 [00:00<00:00, 2471.53it/s, Materializing param=encoder.layer.9.attention.output.LayerNorm.weight]\rLoading weights:  76%|███████▋  | 152/199 [00:00<00:00, 2483.10it/s, Materializing param=encoder.layer.9.attention.output.dense.bias]      \rLoading weights:  76%|███████▋  | 152/199 [00:00<00:00, 2481.02it/s, Materializing param=encoder.layer.9.attention.output.dense.bias]\rLoading weights:  77%|███████▋  | 153/199 [00:00<00:00, 2493.22it/s, Materializing param=encoder.layer.9.attention.output.dense.weight]\rLoading weights:  77%|███████▋  | 153/199 [00:00<00:00, 2491.19it/s, Materializing param=encoder.layer.9.attention.output.dense.weight]\rLoading weights:  77%|███████▋  | 154/199 [00:00<00:00, 2503.40it/s, Materializing param=encoder.layer.9.attention.self.key.bias]      \rLoading weights:  77%|███████▋  | 154/199 [00:00<00:00, 2501.38it/s, Materializing param=encoder.layer.9.attention.self.key.bias]\rLoading weights:  78%|███████▊  | 155/199 [00:00<00:00, 2513.57it/s, Materializing param=encoder.layer.9.attention.self.key.weight]\rLoading weights:  78%|███████▊  | 155/199 [00:00<00:00, 2511.58it/s, Materializing param=encoder.layer.9.attention.self.key.weight]\rLoading weights:  78%|███████▊  | 156/199 [00:00<00:00, 2523.72it/s, Materializing param=encoder.layer.9.attention.self.query.bias]\rLoading weights:  78%|███████▊  | 156/199 [00:00<00:00, 2521.70it/s, Materializing param=encoder.layer.9.attention.self.query.bias]\rLoading weights:  79%|███████▉  | 157/199 [00:00<00:00, 2533.80it/s, Materializing param=encoder.layer.9.attention.self.query.weight]\rLoading weights:  79%|███████▉  | 157/199 [00:00<00:00, 2531.78it/s, Materializing param=encoder.layer.9.attention.self.query.weight]\rLoading weights:  79%|███████▉  | 158/199 [00:00<00:00, 2543.90it/s, Materializing param=encoder.layer.9.attention.self.value.bias]  \rLoading weights:  79%|███████▉  | 158/199 [00:00<00:00, 2541.88it/s, Materializing param=encoder.layer.9.attention.self.value.bias]\rLoading weights:  80%|███████▉  | 159/199 [00:00<00:00, 2553.88it/s, Materializing param=encoder.layer.9.attention.self.value.weight]\rLoading weights:  80%|███████▉  | 159/199 [00:00<00:00, 2551.85it/s, Materializing param=encoder.layer.9.attention.self.value.weight]\rLoading weights:  80%|████████  | 160/199 [00:00<00:00, 2563.82it/s, Materializing param=encoder.layer.9.intermediate.dense.bias]    \rLoading weights:  80%|████████  | 160/199 [00:00<00:00, 2561.82it/s, Materializing param=encoder.layer.9.intermediate.dense.bias]\rLoading weights:  81%|████████  | 161/199 [00:00<00:00, 2573.79it/s, Materializing param=encoder.layer.9.intermediate.dense.weight]\rLoading weights:  81%|████████  | 161/199 [00:00<00:00, 2571.68it/s, Materializing param=encoder.layer.9.intermediate.dense.weight]\rLoading weights:  81%|████████▏ | 162/199 [00:00<00:00, 2583.64it/s, Materializing param=encoder.layer.9.output.LayerNorm.bias]    \rLoading weights:  81%|████████▏ | 162/199 [00:00<00:00, 2581.64it/s, Materializing param=encoder.layer.9.output.LayerNorm.bias]\rLoading weights:  82%|████████▏ | 163/199 [00:00<00:00, 2593.59it/s, Materializing param=encoder.layer.9.output.LayerNorm.weight]\rLoading weights:  82%|████████▏ | 163/199 [00:00<00:00, 2591.61it/s, Materializing param=encoder.layer.9.output.LayerNorm.weight]\rLoading weights:  82%|████████▏ | 164/199 [00:00<00:00, 2603.50it/s, Materializing param=encoder.layer.9.output.dense.bias]      \rLoading weights:  82%|████████▏ | 164/199 [00:00<00:00, 2601.51it/s, Materializing param=encoder.layer.9.output.dense.bias]\rLoading weights:  83%|████████▎ | 165/199 [00:00<00:00, 2613.50it/s, Materializing param=encoder.layer.9.output.dense.weight]\rLoading weights:  83%|████████▎ | 165/199 [00:00<00:00, 2611.56it/s, Materializing param=encoder.layer.9.output.dense.weight]\rLoading weights:  83%|████████▎ | 166/199 [00:00<00:00, 2623.73it/s, Materializing param=encoder.layer.10.attention.output.LayerNorm.bias]\rLoading weights:  83%|████████▎ | 166/199 [00:00<00:00, 2621.73it/s, Materializing param=encoder.layer.10.attention.output.LayerNorm.bias]\rLoading weights:  84%|████████▍ | 167/199 [00:00<00:00, 2633.42it/s, Materializing param=encoder.layer.10.attention.output.LayerNorm.weight]\rLoading weights:  84%|████████▍ | 167/199 [00:00<00:00, 2631.29it/s, Materializing param=encoder.layer.10.attention.output.LayerNorm.weight]\rLoading weights:  84%|████████▍ | 168/199 [00:00<00:00, 2642.57it/s, Materializing param=encoder.layer.10.attention.output.dense.bias]      \rLoading weights:  84%|████████▍ | 168/199 [00:00<00:00, 2640.54it/s, Materializing param=encoder.layer.10.attention.output.dense.bias]\rLoading weights:  85%|████████▍ | 169/199 [00:00<00:00, 2652.50it/s, Materializing param=encoder.layer.10.attention.output.dense.weight]\rLoading weights:  85%|████████▍ | 169/199 [00:00<00:00, 2650.52it/s, Materializing param=encoder.layer.10.attention.output.dense.weight]\rLoading weights:  85%|████████▌ | 170/199 [00:00<00:00, 2662.03it/s, Materializing param=encoder.layer.10.attention.self.key.bias]      \rLoading weights:  85%|████████▌ | 170/199 [00:00<00:00, 2659.95it/s, Materializing param=encoder.layer.10.attention.self.key.bias]\rLoading weights:  86%|████████▌ | 171/199 [00:00<00:00, 2671.78it/s, Materializing param=encoder.layer.10.attention.self.key.weight]\rLoading weights:  86%|████████▌ | 171/199 [00:00<00:00, 2669.79it/s, Materializing param=encoder.layer.10.attention.self.key.weight]\rLoading weights:  86%|████████▋ | 172/199 [00:00<00:00, 2681.60it/s, Materializing param=encoder.layer.10.attention.self.query.bias]\rLoading weights:  86%|████████▋ | 172/199 [00:00<00:00, 2679.59it/s, Materializing param=encoder.layer.10.attention.self.query.bias]\rLoading weights:  87%|████████▋ | 173/199 [00:00<00:00, 2691.10it/s, Materializing param=encoder.layer.10.attention.self.query.weight]\rLoading weights:  87%|████████▋ | 173/199 [00:00<00:00, 2689.08it/s, Materializing param=encoder.layer.10.attention.self.query.weight]\rLoading weights:  87%|████████▋ | 174/199 [00:00<00:00, 2700.51it/s, Materializing param=encoder.layer.10.attention.self.value.bias]  \rLoading weights:  87%|████████▋ | 174/199 [00:00<00:00, 2698.35it/s, Materializing param=encoder.layer.10.attention.self.value.bias]\rLoading weights:  88%|████████▊ | 175/199 [00:00<00:00, 2709.36it/s, Materializing param=encoder.layer.10.attention.self.value.weight]\rLoading weights:  88%|████████▊ | 175/199 [00:00<00:00, 2707.25it/s, Materializing param=encoder.layer.10.attention.self.value.weight]\rLoading weights:  88%|████████▊ | 176/199 [00:00<00:00, 2718.48it/s, Materializing param=encoder.layer.10.intermediate.dense.bias]    \rLoading weights:  88%|████████▊ | 176/199 [00:00<00:00, 2716.49it/s, Materializing param=encoder.layer.10.intermediate.dense.bias]\rLoading weights:  89%|████████▉ | 177/199 [00:00<00:00, 2728.11it/s, Materializing param=encoder.layer.10.intermediate.dense.weight]\rLoading weights:  89%|████████▉ | 177/199 [00:00<00:00, 2726.08it/s, Materializing param=encoder.layer.10.intermediate.dense.weight]\rLoading weights:  89%|████████▉ | 178/199 [00:00<00:00, 2736.67it/s, Materializing param=encoder.layer.10.output.LayerNorm.bias]    \rLoading weights:  89%|████████▉ | 178/199 [00:00<00:00, 2734.53it/s, Materializing param=encoder.layer.10.output.LayerNorm.bias]\rLoading weights:  90%|████████▉ | 179/199 [00:00<00:00, 2744.77it/s, Materializing param=encoder.layer.10.output.LayerNorm.weight]\rLoading weights:  90%|████████▉ | 179/199 [00:00<00:00, 2742.63it/s, Materializing param=encoder.layer.10.output.LayerNorm.weight]\rLoading weights:  90%|█████████ | 180/199 [00:00<00:00, 2753.88it/s, Materializing param=encoder.layer.10.output.dense.bias]      \rLoading weights:  90%|█████████ | 180/199 [00:00<00:00, 2751.86it/s, Materializing param=encoder.layer.10.output.dense.bias]\rLoading weights:  91%|█████████ | 181/199 [00:00<00:00, 2763.58it/s, Materializing param=encoder.layer.10.output.dense.weight]\rLoading weights:  91%|█████████ | 181/199 [00:00<00:00, 2761.60it/s, Materializing param=encoder.layer.10.output.dense.weight]\rLoading weights:  91%|█████████▏| 182/199 [00:00<00:00, 2772.85it/s, Materializing param=encoder.layer.11.attention.output.LayerNorm.bias]\rLoading weights:  91%|█████████▏| 182/199 [00:00<00:00, 2770.74it/s, Materializing param=encoder.layer.11.attention.output.LayerNorm.bias]\rLoading weights:  92%|█████████▏| 183/199 [00:00<00:00, 2781.62it/s, Materializing param=encoder.layer.11.attention.output.LayerNorm.weight]\rLoading weights:  92%|█████████▏| 183/199 [00:00<00:00, 2779.58it/s, Materializing param=encoder.layer.11.attention.output.LayerNorm.weight]\rLoading weights:  92%|█████████▏| 184/199 [00:00<00:00, 2791.03it/s, Materializing param=encoder.layer.11.attention.output.dense.bias]      \rLoading weights:  92%|█████████▏| 184/199 [00:00<00:00, 2789.00it/s, Materializing param=encoder.layer.11.attention.output.dense.bias]\rLoading weights:  93%|█████████▎| 185/199 [00:00<00:00, 2800.14it/s, Materializing param=encoder.layer.11.attention.output.dense.weight]\rLoading weights:  93%|█████████▎| 185/199 [00:00<00:00, 2798.10it/s, Materializing param=encoder.layer.11.attention.output.dense.weight]\rLoading weights:  93%|█████████▎| 186/199 [00:00<00:00, 2809.23it/s, Materializing param=encoder.layer.11.attention.self.key.bias]      \rLoading weights:  93%|█████████▎| 186/199 [00:00<00:00, 2807.16it/s, Materializing param=encoder.layer.11.attention.self.key.bias]\rLoading weights:  94%|█████████▍| 187/199 [00:00<00:00, 2817.95it/s, Materializing param=encoder.layer.11.attention.self.key.weight]\rLoading weights:  94%|█████████▍| 187/199 [00:00<00:00, 2815.81it/s, Materializing param=encoder.layer.11.attention.self.key.weight]\rLoading weights:  94%|█████████▍| 188/199 [00:00<00:00, 2826.26it/s, Materializing param=encoder.layer.11.attention.self.query.bias]\rLoading weights:  94%|█████████▍| 188/199 [00:00<00:00, 2824.18it/s, Materializing param=encoder.layer.11.attention.self.query.bias]\rLoading weights:  95%|█████████▍| 189/199 [00:00<00:00, 2834.89it/s, Materializing param=encoder.layer.11.attention.self.query.weight]\rLoading weights:  95%|█████████▍| 189/199 [00:00<00:00, 2832.73it/s, Materializing param=encoder.layer.11.attention.self.query.weight]\rLoading weights:  95%|█████████▌| 190/199 [00:00<00:00, 2843.39it/s, Materializing param=encoder.layer.11.attention.self.value.bias]  \rLoading weights:  95%|█████████▌| 190/199 [00:00<00:00, 2841.22it/s, Materializing param=encoder.layer.11.attention.self.value.bias]\rLoading weights:  96%|█████████▌| 191/199 [00:00<00:00, 2851.93it/s, Materializing param=encoder.layer.11.attention.self.value.weight]\rLoading weights:  96%|█████████▌| 191/199 [00:00<00:00, 2849.87it/s, Materializing param=encoder.layer.11.attention.self.value.weight]\rLoading weights:  96%|█████████▋| 192/199 [00:00<00:00, 2860.78it/s, Materializing param=encoder.layer.11.intermediate.dense.bias]    \rLoading weights:  96%|█████████▋| 192/199 [00:00<00:00, 2858.73it/s, Materializing param=encoder.layer.11.intermediate.dense.bias]\rLoading weights:  97%|█████████▋| 193/199 [00:00<00:00, 2869.99it/s, Materializing param=encoder.layer.11.intermediate.dense.weight]\rLoading weights:  97%|█████████▋| 193/199 [00:00<00:00, 2867.99it/s, Materializing param=encoder.layer.11.intermediate.dense.weight]\rLoading weights:  97%|█████████▋| 194/199 [00:00<00:00, 2878.81it/s, Materializing param=encoder.layer.11.output.LayerNorm.bias]    \rLoading weights:  97%|█████████▋| 194/199 [00:00<00:00, 2876.67it/s, Materializing param=encoder.layer.11.output.LayerNorm.bias]\rLoading weights:  98%|█████████▊| 195/199 [00:00<00:00, 2887.41it/s, Materializing param=encoder.layer.11.output.LayerNorm.weight]\rLoading weights:  98%|█████████▊| 195/199 [00:00<00:00, 2885.11it/s, Materializing param=encoder.layer.11.output.LayerNorm.weight]\rLoading weights:  98%|█████████▊| 196/199 [00:00<00:00, 2896.08it/s, Materializing param=encoder.layer.11.output.dense.bias]      \rLoading weights:  98%|█████████▊| 196/199 [00:00<00:00, 2893.85it/s, Materializing param=encoder.layer.11.output.dense.bias]\rLoading weights:  99%|█████████▉| 197/199 [00:00<00:00, 2904.30it/s, Materializing param=encoder.layer.11.output.dense.weight]\rLoading weights:  99%|█████████▉| 197/199 [00:00<00:00, 2902.18it/s, Materializing param=encoder.layer.11.output.dense.weight]\rLoading weights:  99%|█████████▉| 198/199 [00:00<00:00, 2912.67it/s, Materializing param=pooler.dense.bias]                   \rLoading weights:  99%|█████████▉| 198/199 [00:00<00:00, 2910.54it/s, Materializing param=pooler.dense.bias]\rLoading weights: 100%|██████████| 199/199 [00:00<00:00, 2921.65it/s, Materializing param=pooler.dense.weight]\rLoading weights: 100%|██████████| 199/199 [00:00<00:00, 2919.39it/s, Materializing param=pooler.dense.weight]\rLoading weights: 100%|██████████| 199/199 [00:00<00:00, 2914.87it/s, Materializing param=pooler.dense.weight]\n\u001b[1mXLMRobertaModel LOAD REPORT\u001b[0m from: xlm-roberta-base\nKey                       | Status     |  | \n--------------------------+------------+--+-\nlm_head.layer_norm.bias   | UNEXPECTED |  | \nlm_head.dense.weight      | UNEXPECTED |  | \nlm_head.dense.bias        | UNEXPECTED |  | \nlm_head.bias              | UNEXPECTED |  | \nlm_head.layer_norm.weight | UNEXPECTED |  | \n\n\u001b[3mNotes:\n- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n2026-02-15 19:42:52,473 | INFO | Polysemy lexicon size: 3726\n\rStatic sim:   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim:  18%|█▊        | 363/2000 [00:00<00:00, 3626.68it/s]\rStatic sim:  38%|███▊      | 755/2000 [00:00<00:00, 3796.32it/s]\rStatic sim:  59%|█████▊    | 1174/2000 [00:00<00:00, 3973.04it/s]\rStatic sim:  80%|███████▉  | 1593/2000 [00:00<00:00, 4057.71it/s]\rStatic sim: 100%|██████████| 2000/2000 [00:00<00:00, 4014.74it/s]\n\rStatic sim (mismatch):   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim (mismatch):  22%|██▏       | 445/2000 [00:00<00:00, 4448.08it/s]\rStatic sim (mismatch):  44%|████▍     | 890/2000 [00:00<00:00, 4413.16it/s]\rStatic sim (mismatch):  67%|██████▋   | 1341/2000 [00:00<00:00, 4452.61it/s]\rStatic sim (mismatch):  89%|████████▉ | 1788/2000 [00:00<00:00, 4458.10it/s]\rStatic sim (mismatch): 100%|██████████| 2000/2000 [00:00<00:00, 4435.14it/s]\n\rStatic sim:   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim:  21%|██        | 411/2000 [00:00<00:00, 4104.33it/s]\rStatic sim:  43%|████▎     | 851/2000 [00:00<00:00, 4276.57it/s]\rStatic sim:  64%|██████▍   | 1287/2000 [00:00<00:00, 4310.02it/s]\rStatic sim:  86%|████████▋ | 1727/2000 [00:00<00:00, 4344.23it/s]\rStatic sim: 100%|██████████| 2000/2000 [00:00<00:00, 4290.33it/s]\n\rStatic sim (mismatch):   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim (mismatch):  23%|██▎       | 465/2000 [00:00<00:00, 4645.98it/s]\rStatic sim (mismatch):  46%|████▋     | 930/2000 [00:00<00:00, 4612.26it/s]\rStatic sim (mismatch):  70%|██████▉   | 1392/2000 [00:00<00:00, 4570.23it/s]\rStatic sim (mismatch):  93%|█████████▎| 1854/2000 [00:00<00:00, 4586.37it/s]\rStatic sim (mismatch): 100%|██████████| 2000/2000 [00:00<00:00, 4567.13it/s]\n\rStatic sim:   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim:  22%|██▎       | 450/2000 [00:00<00:00, 4498.74it/s]\rStatic sim:  45%|████▌     | 900/2000 [00:00<00:00, 4432.27it/s]\rStatic sim:  67%|██████▋   | 1344/2000 [00:00<00:00, 4365.35it/s]\rStatic sim:  89%|████████▉ | 1781/2000 [00:00<00:00, 4253.26it/s]\rStatic sim: 100%|██████████| 2000/2000 [00:00<00:00, 4289.61it/s]\n\rStatic sim (mismatch):   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim (mismatch):  23%|██▎       | 452/2000 [00:00<00:00, 4514.61it/s]\rStatic sim (mismatch):  45%|████▌     | 904/2000 [00:00<00:00, 4446.27it/s]\rStatic sim (mismatch):  67%|██████▋   | 1349/2000 [00:00<00:00, 4435.80it/s]\rStatic sim (mismatch):  90%|█████████ | 1800/2000 [00:00<00:00, 4461.54it/s]\rStatic sim (mismatch): 100%|██████████| 2000/2000 [00:00<00:00, 4442.10it/s]\n\rStatic sim:   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim:  21%|██▏       | 427/2000 [00:00<00:00, 4264.48it/s]\rStatic sim:  44%|████▍     | 876/2000 [00:00<00:00, 4396.84it/s]\rStatic sim:  66%|██████▋   | 1327/2000 [00:00<00:00, 4446.06it/s]\rStatic sim:  89%|████████▉ | 1778/2000 [00:00<00:00, 4469.72it/s]\rStatic sim: 100%|██████████| 2000/2000 [00:00<00:00, 4348.07it/s]\n\rStatic sim (mismatch):   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim (mismatch):  22%|██▏       | 439/2000 [00:00<00:00, 4387.18it/s]\rStatic sim (mismatch):  44%|████▍     | 882/2000 [00:00<00:00, 4411.41it/s]\rStatic sim (mismatch):  66%|██████▋   | 1327/2000 [00:00<00:00, 4425.85it/s]\rStatic sim (mismatch):  89%|████████▊ | 1773/2000 [00:00<00:00, 4437.14it/s]\rStatic sim (mismatch): 100%|██████████| 2000/2000 [00:00<00:00, 4422.77it/s]\nTraceback (most recent call last):\n  File \"/data/hypogenicai/workspaces/similar-embeddings-nlp-5ef8-codex/src/run_experiments.py\", line 416, in <module>\n    main()\n  File \"/data/hypogenicai/workspaces/similar-embeddings-nlp-5ef8-codex/src/run_experiments.py\", line 312, in main\n    samples = load_mcl_wic_pair(data_path, gold_path)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/hypogenicai/workspaces/similar-embeddings-nlp-5ef8-codex/src/run_experiments.py\", line 67, in load_mcl_wic_pair\n    start1=int(item[\"start1\"]),\n               ~~~~^^^^^^^^^^\nKeyError: 'start1'\n","exit_code":1,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_79","type":"reasoning","text":"**Inspecting data entry**\n\nI'm viewing a sample data entry to understand the error in cross-lingual data format by checking its fields and structure."}}
{"type":"item.started","item":{"id":"item_80","type":"command_execution","command":"/bin/bash -lc \"python - << 'PY'\nimport json\nfrom pathlib import Path\npath=Path('datasets/mcl_wic/data/MCL-WiC/test/crosslingual/test.en-fr.data')\nitem=json.load(open(path))[0]\nprint(item)\nPY\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_80","type":"command_execution","command":"/bin/bash -lc \"python - << 'PY'\nimport json\nfrom pathlib import Path\npath=Path('datasets/mcl_wic/data/MCL-WiC/test/crosslingual/test.en-fr.data')\nitem=json.load(open(path))[0]\nprint(item)\nPY\"","aggregated_output":"{'id': 'test.en-fr.0', 'lemma': 'gently', 'pos': 'ADV', 'sentence1': \"Unfortunately, that pressure seemed to have had some effect, and the Islamic Republic of Iran had been treated more gently in the 2008 Chairman's working paper.\", 'sentence2': \"Pendant cette décennie, les prix réels des produits de base ont augmenté modérément dans l'ensemble.\", 'ranges1': '116-122', 'ranges2': '73-83'}\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_81","type":"reasoning","text":"**Adapting function to handle dual range formats**\n\nI'm updating the load function to support both separate start-end keys and combined range strings by parsing as needed, ensuring compatibility with crosslingual data formats."}}
{"type":"item.completed","item":{"id":"item_82","type":"file_change","changes":[{"path":"/data/hypogenicai/workspaces/similar-embeddings-nlp-5ef8-codex/src/run_experiments.py","kind":"update"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_83","type":"reasoning","text":"**Preparing to re-run script**"}}
{"type":"item.started","item":{"id":"item_84","type":"command_execution","command":"/bin/bash -lc 'source .venv/bin/activate && python src/run_experiments.py'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_85","type":"reasoning","text":"**Pausing briefly**"}}
{"type":"item.completed","item":{"id":"item_84","type":"command_execution","command":"/bin/bash -lc 'source .venv/bin/activate && python src/run_experiments.py'","aggregated_output":"2026-02-15 19:43:21,451 | INFO | Starting experiments\n2026-02-15 19:43:21,753 | INFO | Device: cuda\n2026-02-15 19:43:21,832 | INFO | HTTP Request: HEAD https://huggingface.co/xlm-roberta-base/resolve/main/config.json \"HTTP/1.1 200 OK\"\n2026-02-15 19:43:21,879 | INFO | HTTP Request: HEAD https://huggingface.co/xlm-roberta-base/resolve/main/tokenizer_config.json \"HTTP/1.1 200 OK\"\n2026-02-15 19:43:21,918 | INFO | HTTP Request: GET https://huggingface.co/api/models/xlm-roberta-base/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 307 Temporary Redirect\"\n2026-02-15 19:43:21,955 | INFO | HTTP Request: GET https://huggingface.co/api/models/FacebookAI/xlm-roberta-base/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n2026-02-15 19:43:21,996 | INFO | HTTP Request: GET https://huggingface.co/api/models/xlm-roberta-base/tree/main?recursive=true&expand=false \"HTTP/1.1 307 Temporary Redirect\"\n2026-02-15 19:43:22,037 | INFO | HTTP Request: GET https://huggingface.co/api/models/FacebookAI/xlm-roberta-base/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n2026-02-15 19:43:23,939 | INFO | HTTP Request: GET https://huggingface.co/api/models/xlm-roberta-base \"HTTP/1.1 307 Temporary Redirect\"\n2026-02-15 19:43:23,981 | INFO | HTTP Request: GET https://huggingface.co/api/models/FacebookAI/xlm-roberta-base \"HTTP/1.1 200 OK\"\n2026-02-15 19:43:24,038 | INFO | HTTP Request: HEAD https://huggingface.co/xlm-roberta-base/resolve/main/config.json \"HTTP/1.1 200 OK\"\nWarning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n2026-02-15 19:43:24,039 | WARNING | Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n\rLoading weights:   0%|          | 0/199 [00:00<?, ?it/s]\rLoading weights:   1%|          | 1/199 [00:00<00:00, 16194.22it/s, Materializing param=embeddings.LayerNorm.bias]\rLoading weights:   1%|          | 1/199 [00:00<00:00, 6887.20it/s, Materializing param=embeddings.LayerNorm.bias] \rLoading weights:   1%|          | 2/199 [00:00<00:00, 6955.73it/s, Materializing param=embeddings.LayerNorm.weight]\rLoading weights:   1%|          | 2/199 [00:00<00:00, 5862.06it/s, Materializing param=embeddings.LayerNorm.weight]\rLoading weights:   2%|▏         | 3/199 [00:00<00:00, 6257.04it/s, Materializing param=embeddings.position_embeddings.weight]\rLoading weights:   2%|▏         | 3/199 [00:00<00:00, 5592.41it/s, Materializing param=embeddings.position_embeddings.weight]\rLoading weights:   2%|▏         | 4/199 [00:00<00:00, 6091.94it/s, Materializing param=embeddings.token_type_embeddings.weight]\rLoading weights:   2%|▏         | 4/199 [00:00<00:00, 5650.80it/s, Materializing param=embeddings.token_type_embeddings.weight]\rLoading weights:   3%|▎         | 5/199 [00:00<00:00, 6052.39it/s, Materializing param=embeddings.word_embeddings.weight]      \rLoading weights:   3%|▎         | 5/199 [00:00<00:00, 5701.88it/s, Materializing param=embeddings.word_embeddings.weight]\rLoading weights:   3%|▎         | 6/199 [00:00<00:00, 6007.60it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]\rLoading weights:   3%|▎         | 6/199 [00:00<00:00, 5689.76it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]\rLoading weights:   4%|▎         | 7/199 [00:00<00:00, 5824.27it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\rLoading weights:   4%|▎         | 7/199 [00:00<00:00, 5575.41it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\rLoading weights:   4%|▍         | 8/199 [00:00<00:00, 5751.53it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]      \rLoading weights:   4%|▍         | 8/199 [00:00<00:00, 5538.86it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]\rLoading weights:   5%|▍         | 9/199 [00:00<00:00, 5699.64it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\rLoading weights:   5%|▍         | 9/199 [00:00<00:00, 5461.33it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\rLoading weights:   5%|▌         | 10/199 [00:00<00:00, 5571.60it/s, Materializing param=encoder.layer.0.attention.self.key.bias]     \rLoading weights:   5%|▌         | 10/199 [00:00<00:00, 5412.70it/s, Materializing param=encoder.layer.0.attention.self.key.bias]\rLoading weights:   6%|▌         | 11/199 [00:00<00:00, 5541.36it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\rLoading weights:   6%|▌         | 11/199 [00:00<00:00, 5398.71it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\rLoading weights:   6%|▌         | 12/199 [00:00<00:00, 3372.30it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\rLoading weights:   6%|▌         | 12/199 [00:00<00:00, 3318.06it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\rLoading weights:   7%|▋         | 13/199 [00:00<00:00, 3456.92it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\rLoading weights:   7%|▋         | 13/199 [00:00<00:00, 3406.81it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\rLoading weights:   7%|▋         | 14/199 [00:00<00:00, 3518.08it/s, Materializing param=encoder.layer.0.attention.self.value.bias]  \rLoading weights:   7%|▋         | 14/199 [00:00<00:00, 3471.28it/s, Materializing param=encoder.layer.0.attention.self.value.bias]\rLoading weights:   8%|▊         | 15/199 [00:00<00:00, 3586.10it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\rLoading weights:   8%|▊         | 15/199 [00:00<00:00, 3541.69it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\rLoading weights:   8%|▊         | 16/199 [00:00<00:00, 3648.01it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]    \rLoading weights:   8%|▊         | 16/199 [00:00<00:00, 3603.74it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]\rLoading weights:   9%|▊         | 17/199 [00:00<00:00, 3710.23it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\rLoading weights:   9%|▊         | 17/199 [00:00<00:00, 3667.67it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\rLoading weights:   9%|▉         | 18/199 [00:00<00:00, 3786.42it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]    \rLoading weights:   9%|▉         | 18/199 [00:00<00:00, 3744.54it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]\rLoading weights:  10%|▉         | 19/199 [00:00<00:00, 3838.72it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\rLoading weights:  10%|▉         | 19/199 [00:00<00:00, 3798.10it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\rLoading weights:  10%|█         | 20/199 [00:00<00:00, 3906.77it/s, Materializing param=encoder.layer.0.output.dense.bias]      \rLoading weights:  10%|█         | 20/199 [00:00<00:00, 3869.82it/s, Materializing param=encoder.layer.0.output.dense.bias]\rLoading weights:  11%|█         | 21/199 [00:00<00:00, 3969.73it/s, Materializing param=encoder.layer.0.output.dense.weight]\rLoading weights:  11%|█         | 21/199 [00:00<00:00, 3932.16it/s, Materializing param=encoder.layer.0.output.dense.weight]\rLoading weights:  11%|█         | 22/199 [00:00<00:00, 3700.46it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\rLoading weights:  11%|█         | 22/199 [00:00<00:00, 3665.48it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\rLoading weights:  12%|█▏        | 23/199 [00:00<00:00, 3754.39it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]\rLoading weights:  12%|█▏        | 23/199 [00:00<00:00, 3723.52it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]\rLoading weights:  12%|█▏        | 24/199 [00:00<00:00, 3813.58it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]      \rLoading weights:  12%|█▏        | 24/199 [00:00<00:00, 3783.77it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]\rLoading weights:  13%|█▎        | 25/199 [00:00<00:00, 3534.72it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\rLoading weights:  13%|█▎        | 25/199 [00:00<00:00, 3419.57it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\rLoading weights:  13%|█▎        | 26/199 [00:00<00:00, 3438.82it/s, Materializing param=encoder.layer.1.attention.self.key.bias]      \rLoading weights:  13%|█▎        | 26/199 [00:00<00:00, 3189.40it/s, Materializing param=encoder.layer.1.attention.self.key.bias]\rLoading weights:  14%|█▎        | 27/199 [00:00<00:00, 3234.04it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\rLoading weights:  14%|█▎        | 27/199 [00:00<00:00, 3138.32it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\rLoading weights:  14%|█▍        | 28/199 [00:00<00:00, 3111.34it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\rLoading weights:  14%|█▍        | 28/199 [00:00<00:00, 3085.59it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\rLoading weights:  15%|█▍        | 29/199 [00:00<00:00, 3119.56it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\rLoading weights:  15%|█▍        | 29/199 [00:00<00:00, 3092.83it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\rLoading weights:  15%|█▌        | 30/199 [00:00<00:00, 3140.94it/s, Materializing param=encoder.layer.1.attention.self.value.bias]  \rLoading weights:  15%|█▌        | 30/199 [00:00<00:00, 3052.92it/s, Materializing param=encoder.layer.1.attention.self.value.bias]\rLoading weights:  16%|█▌        | 31/199 [00:00<00:00, 3084.78it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\rLoading weights:  16%|█▌        | 31/199 [00:00<00:00, 3062.04it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\rLoading weights:  16%|█▌        | 32/199 [00:00<00:00, 3052.69it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]    \rLoading weights:  16%|█▌        | 32/199 [00:00<00:00, 3030.98it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]\rLoading weights:  17%|█▋        | 33/199 [00:00<00:00, 2907.02it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\rLoading weights:  17%|█▋        | 33/199 [00:00<00:00, 2888.10it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\rLoading weights:  17%|█▋        | 34/199 [00:00<00:00, 2890.28it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]    \rLoading weights:  17%|█▋        | 34/199 [00:00<00:00, 2872.41it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]\rLoading weights:  18%|█▊        | 35/199 [00:00<00:00, 2919.26it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\rLoading weights:  18%|█▊        | 35/199 [00:00<00:00, 2903.32it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\rLoading weights:  18%|█▊        | 36/199 [00:00<00:00, 2950.91it/s, Materializing param=encoder.layer.1.output.dense.bias]      \rLoading weights:  18%|█▊        | 36/199 [00:00<00:00, 2935.76it/s, Materializing param=encoder.layer.1.output.dense.bias]\rLoading weights:  19%|█▊        | 37/199 [00:00<00:00, 2982.52it/s, Materializing param=encoder.layer.1.output.dense.weight]\rLoading weights:  19%|█▊        | 37/199 [00:00<00:00, 2967.12it/s, Materializing param=encoder.layer.1.output.dense.weight]\rLoading weights:  19%|█▉        | 38/199 [00:00<00:00, 2875.25it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\rLoading weights:  19%|█▉        | 38/199 [00:00<00:00, 2859.72it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\rLoading weights:  20%|█▉        | 39/199 [00:00<00:00, 2690.03it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\rLoading weights:  20%|█▉        | 39/199 [00:00<00:00, 2648.78it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\rLoading weights:  20%|██        | 40/199 [00:00<00:00, 2580.16it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]      \rLoading weights:  20%|██        | 40/199 [00:00<00:00, 2540.81it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]\rLoading weights:  21%|██        | 41/199 [00:00<00:00, 2519.66it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\rLoading weights:  21%|██        | 41/199 [00:00<00:00, 2415.97it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\rLoading weights:  21%|██        | 42/199 [00:00<00:00, 2434.44it/s, Materializing param=encoder.layer.2.attention.self.key.bias]      \rLoading weights:  21%|██        | 42/199 [00:00<00:00, 2374.55it/s, Materializing param=encoder.layer.2.attention.self.key.bias]\rLoading weights:  22%|██▏       | 43/199 [00:00<00:00, 2337.75it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\rLoading weights:  22%|██▏       | 43/199 [00:00<00:00, 2292.03it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\rLoading weights:  22%|██▏       | 44/199 [00:00<00:00, 2274.18it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\rLoading weights:  22%|██▏       | 44/199 [00:00<00:00, 2265.49it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\rLoading weights:  23%|██▎       | 45/199 [00:00<00:00, 2296.77it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\rLoading weights:  23%|██▎       | 45/199 [00:00<00:00, 2288.25it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\rLoading weights:  23%|██▎       | 46/199 [00:00<00:00, 2298.74it/s, Materializing param=encoder.layer.2.attention.self.value.bias]  \rLoading weights:  23%|██▎       | 46/199 [00:00<00:00, 2243.41it/s, Materializing param=encoder.layer.2.attention.self.value.bias]\rLoading weights:  24%|██▎       | 47/199 [00:00<00:00, 2068.89it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\rLoading weights:  24%|██▎       | 47/199 [00:00<00:00, 2035.63it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\rLoading weights:  24%|██▍       | 48/199 [00:00<00:00, 2015.18it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]    \rLoading weights:  24%|██▍       | 48/199 [00:00<00:00, 1981.42it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]\rLoading weights:  25%|██▍       | 49/199 [00:00<00:00, 1935.02it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\rLoading weights:  25%|██▍       | 49/199 [00:00<00:00, 1855.25it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\rLoading weights:  25%|██▌       | 50/199 [00:00<00:00, 1863.16it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]    \rLoading weights:  25%|██▌       | 50/199 [00:00<00:00, 1849.63it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]\rLoading weights:  26%|██▌       | 51/199 [00:00<00:00, 1840.78it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\rLoading weights:  26%|██▌       | 51/199 [00:00<00:00, 1835.64it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\rLoading weights:  26%|██▌       | 52/199 [00:00<00:00, 1854.28it/s, Materializing param=encoder.layer.2.output.dense.bias]      \rLoading weights:  26%|██▌       | 52/199 [00:00<00:00, 1842.20it/s, Materializing param=encoder.layer.2.output.dense.bias]\rLoading weights:  27%|██▋       | 53/199 [00:00<00:00, 1860.56it/s, Materializing param=encoder.layer.2.output.dense.weight]\rLoading weights:  27%|██▋       | 53/199 [00:00<00:00, 1855.72it/s, Materializing param=encoder.layer.2.output.dense.weight]\rLoading weights:  27%|██▋       | 54/199 [00:00<00:00, 1865.90it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\rLoading weights:  27%|██▋       | 54/199 [00:00<00:00, 1858.41it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\rLoading weights:  28%|██▊       | 55/199 [00:00<00:00, 1879.80it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\rLoading weights:  28%|██▊       | 55/199 [00:00<00:00, 1874.10it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\rLoading weights:  28%|██▊       | 56/199 [00:00<00:00, 1829.28it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]      \rLoading weights:  28%|██▊       | 56/199 [00:00<00:00, 1824.29it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]\rLoading weights:  29%|██▊       | 57/199 [00:00<00:00, 1843.41it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\rLoading weights:  29%|██▊       | 57/199 [00:00<00:00, 1814.26it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\rLoading weights:  29%|██▉       | 58/199 [00:00<00:00, 1811.07it/s, Materializing param=encoder.layer.3.attention.self.key.bias]      \rLoading weights:  29%|██▉       | 58/199 [00:00<00:00, 1807.06it/s, Materializing param=encoder.layer.3.attention.self.key.bias]\rLoading weights:  30%|██▉       | 59/199 [00:00<00:00, 1823.33it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\rLoading weights:  30%|██▉       | 59/199 [00:00<00:00, 1790.88it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\rLoading weights:  30%|███       | 60/199 [00:00<00:00, 1811.64it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\rLoading weights:  30%|███       | 60/199 [00:00<00:00, 1807.88it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\rLoading weights:  31%|███       | 61/199 [00:00<00:00, 1812.12it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\rLoading weights:  31%|███       | 61/199 [00:00<00:00, 1800.47it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\rLoading weights:  31%|███       | 62/199 [00:00<00:00, 1808.03it/s, Materializing param=encoder.layer.3.attention.self.value.bias]  \rLoading weights:  31%|███       | 62/199 [00:00<00:00, 1797.80it/s, Materializing param=encoder.layer.3.attention.self.value.bias]\rLoading weights:  32%|███▏      | 63/199 [00:00<00:00, 1808.41it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\rLoading weights:  32%|███▏      | 63/199 [00:00<00:00, 1802.83it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\rLoading weights:  32%|███▏      | 64/199 [00:00<00:00, 1795.87it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]    \rLoading weights:  32%|███▏      | 64/199 [00:00<00:00, 1792.11it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]\rLoading weights:  33%|███▎      | 65/199 [00:00<00:00, 1777.48it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\rLoading weights:  33%|███▎      | 65/199 [00:00<00:00, 1766.64it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\rLoading weights:  33%|███▎      | 66/199 [00:00<00:00, 1738.91it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]    \rLoading weights:  33%|███▎      | 66/199 [00:00<00:00, 1735.58it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]\rLoading weights:  34%|███▎      | 67/199 [00:00<00:00, 1736.17it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\rLoading weights:  34%|███▎      | 67/199 [00:00<00:00, 1723.50it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\rLoading weights:  34%|███▍      | 68/199 [00:00<00:00, 1737.83it/s, Materializing param=encoder.layer.3.output.dense.bias]      \rLoading weights:  34%|███▍      | 68/199 [00:00<00:00, 1728.54it/s, Materializing param=encoder.layer.3.output.dense.bias]\rLoading weights:  35%|███▍      | 69/199 [00:00<00:00, 1728.94it/s, Materializing param=encoder.layer.3.output.dense.weight]\rLoading weights:  35%|███▍      | 69/199 [00:00<00:00, 1725.85it/s, Materializing param=encoder.layer.3.output.dense.weight]\rLoading weights:  35%|███▌      | 70/199 [00:00<00:00, 1743.81it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\rLoading weights:  35%|███▌      | 70/199 [00:00<00:00, 1737.88it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\rLoading weights:  36%|███▌      | 71/199 [00:00<00:00, 1742.12it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\rLoading weights:  36%|███▌      | 71/199 [00:00<00:00, 1738.82it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\rLoading weights:  36%|███▌      | 72/199 [00:00<00:00, 1753.20it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]      \rLoading weights:  36%|███▌      | 72/199 [00:00<00:00, 1745.07it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]\rLoading weights:  37%|███▋      | 73/199 [00:00<00:00, 1750.37it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\rLoading weights:  37%|███▋      | 73/199 [00:00<00:00, 1732.19it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\rLoading weights:  37%|███▋      | 74/199 [00:00<00:00, 1733.29it/s, Materializing param=encoder.layer.4.attention.self.key.bias]      \rLoading weights:  37%|███▋      | 74/199 [00:00<00:00, 1712.40it/s, Materializing param=encoder.layer.4.attention.self.key.bias]\rLoading weights:  38%|███▊      | 75/199 [00:00<00:00, 1721.88it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\rLoading weights:  38%|███▊      | 75/199 [00:00<00:00, 1719.07it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\rLoading weights:  38%|███▊      | 76/199 [00:00<00:00, 1716.08it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\rLoading weights:  38%|███▊      | 76/199 [00:00<00:00, 1698.94it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\rLoading weights:  39%|███▊      | 77/199 [00:00<00:00, 1711.52it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\rLoading weights:  39%|███▊      | 77/199 [00:00<00:00, 1708.69it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\rLoading weights:  39%|███▉      | 78/199 [00:00<00:00, 1715.19it/s, Materializing param=encoder.layer.4.attention.self.value.bias]  \rLoading weights:  39%|███▉      | 78/199 [00:00<00:00, 1703.20it/s, Materializing param=encoder.layer.4.attention.self.value.bias]\rLoading weights:  40%|███▉      | 79/199 [00:00<00:00, 1709.81it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\rLoading weights:  40%|███▉      | 79/199 [00:00<00:00, 1703.61it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\rLoading weights:  40%|████      | 80/199 [00:00<00:00, 1707.74it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]    \rLoading weights:  40%|████      | 80/199 [00:00<00:00, 1703.49it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]\rLoading weights:  41%|████      | 81/199 [00:00<00:00, 1702.38it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\rLoading weights:  41%|████      | 81/199 [00:00<00:00, 1687.59it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\rLoading weights:  41%|████      | 82/199 [00:00<00:00, 1695.01it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]    \rLoading weights:  41%|████      | 82/199 [00:00<00:00, 1690.44it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]\rLoading weights:  42%|████▏     | 83/199 [00:00<00:00, 1695.81it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\rLoading weights:  42%|████▏     | 83/199 [00:00<00:00, 1675.32it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\rLoading weights:  42%|████▏     | 84/199 [00:00<00:00, 1689.60it/s, Materializing param=encoder.layer.4.output.dense.bias]      \rLoading weights:  42%|████▏     | 84/199 [00:00<00:00, 1687.16it/s, Materializing param=encoder.layer.4.output.dense.bias]\rLoading weights:  43%|████▎     | 85/199 [00:00<00:00, 1700.89it/s, Materializing param=encoder.layer.4.output.dense.weight]\rLoading weights:  43%|████▎     | 85/199 [00:00<00:00, 1698.52it/s, Materializing param=encoder.layer.4.output.dense.weight]\rLoading weights:  43%|████▎     | 86/199 [00:00<00:00, 1713.39it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\rLoading weights:  43%|████▎     | 86/199 [00:00<00:00, 1711.12it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\rLoading weights:  44%|████▎     | 87/199 [00:00<00:00, 1726.32it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\rLoading weights:  44%|████▎     | 87/199 [00:00<00:00, 1723.92it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\rLoading weights:  44%|████▍     | 88/199 [00:00<00:00, 1738.96it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]      \rLoading weights:  44%|████▍     | 88/199 [00:00<00:00, 1736.70it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]\rLoading weights:  45%|████▍     | 89/199 [00:00<00:00, 1751.83it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\rLoading weights:  45%|████▍     | 89/199 [00:00<00:00, 1749.45it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\rLoading weights:  45%|████▌     | 90/199 [00:00<00:00, 1764.32it/s, Materializing param=encoder.layer.5.attention.self.key.bias]      \rLoading weights:  45%|████▌     | 90/199 [00:00<00:00, 1761.92it/s, Materializing param=encoder.layer.5.attention.self.key.bias]\rLoading weights:  46%|████▌     | 91/199 [00:00<00:00, 1776.94it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\rLoading weights:  46%|████▌     | 91/199 [00:00<00:00, 1774.58it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\rLoading weights:  46%|████▌     | 92/199 [00:00<00:00, 1788.72it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\rLoading weights:  46%|████▌     | 92/199 [00:00<00:00, 1786.26it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\rLoading weights:  47%|████▋     | 93/199 [00:00<00:00, 1800.93it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\rLoading weights:  47%|████▋     | 93/199 [00:00<00:00, 1798.41it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\rLoading weights:  47%|████▋     | 94/199 [00:00<00:00, 1812.89it/s, Materializing param=encoder.layer.5.attention.self.value.bias]  \rLoading weights:  47%|████▋     | 94/199 [00:00<00:00, 1810.50it/s, Materializing param=encoder.layer.5.attention.self.value.bias]\rLoading weights:  48%|████▊     | 95/199 [00:00<00:00, 1825.31it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\rLoading weights:  48%|████▊     | 95/199 [00:00<00:00, 1822.97it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\rLoading weights:  48%|████▊     | 96/199 [00:00<00:00, 1837.23it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]    \rLoading weights:  48%|████▊     | 96/199 [00:00<00:00, 1834.87it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]\rLoading weights:  49%|████▊     | 97/199 [00:00<00:00, 1849.61it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\rLoading weights:  49%|████▊     | 97/199 [00:00<00:00, 1847.39it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\rLoading weights:  49%|████▉     | 98/199 [00:00<00:00, 1862.56it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]    \rLoading weights:  49%|████▉     | 98/199 [00:00<00:00, 1860.37it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]\rLoading weights:  50%|████▉     | 99/199 [00:00<00:00, 1875.10it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\rLoading weights:  50%|████▉     | 99/199 [00:00<00:00, 1872.71it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\rLoading weights:  50%|█████     | 100/199 [00:00<00:00, 1886.55it/s, Materializing param=encoder.layer.5.output.dense.bias]     \rLoading weights:  50%|█████     | 100/199 [00:00<00:00, 1884.18it/s, Materializing param=encoder.layer.5.output.dense.bias]\rLoading weights:  51%|█████     | 101/199 [00:00<00:00, 1898.84it/s, Materializing param=encoder.layer.5.output.dense.weight]\rLoading weights:  51%|█████     | 101/199 [00:00<00:00, 1896.59it/s, Materializing param=encoder.layer.5.output.dense.weight]\rLoading weights:  51%|█████▏    | 102/199 [00:00<00:00, 1911.24it/s, Materializing param=encoder.layer.6.attention.output.LayerNorm.bias]\rLoading weights:  51%|█████▏    | 102/199 [00:00<00:00, 1908.88it/s, Materializing param=encoder.layer.6.attention.output.LayerNorm.bias]\rLoading weights:  52%|█████▏    | 103/199 [00:00<00:00, 1923.33it/s, Materializing param=encoder.layer.6.attention.output.LayerNorm.weight]\rLoading weights:  52%|█████▏    | 103/199 [00:00<00:00, 1920.49it/s, Materializing param=encoder.layer.6.attention.output.LayerNorm.weight]\rLoading weights:  52%|█████▏    | 104/199 [00:00<00:00, 1934.68it/s, Materializing param=encoder.layer.6.attention.output.dense.bias]      \rLoading weights:  52%|█████▏    | 104/199 [00:00<00:00, 1932.30it/s, Materializing param=encoder.layer.6.attention.output.dense.bias]\rLoading weights:  53%|█████▎    | 105/199 [00:00<00:00, 1946.57it/s, Materializing param=encoder.layer.6.attention.output.dense.weight]\rLoading weights:  53%|█████▎    | 105/199 [00:00<00:00, 1944.24it/s, Materializing param=encoder.layer.6.attention.output.dense.weight]\rLoading weights:  53%|█████▎    | 106/199 [00:00<00:00, 1958.06it/s, Materializing param=encoder.layer.6.attention.self.key.bias]      \rLoading weights:  53%|█████▎    | 106/199 [00:00<00:00, 1955.49it/s, Materializing param=encoder.layer.6.attention.self.key.bias]\rLoading weights:  54%|█████▍    | 107/199 [00:00<00:00, 1968.82it/s, Materializing param=encoder.layer.6.attention.self.key.weight]\rLoading weights:  54%|█████▍    | 107/199 [00:00<00:00, 1966.39it/s, Materializing param=encoder.layer.6.attention.self.key.weight]\rLoading weights:  54%|█████▍    | 108/199 [00:00<00:00, 1979.89it/s, Materializing param=encoder.layer.6.attention.self.query.bias]\rLoading weights:  54%|█████▍    | 108/199 [00:00<00:00, 1977.37it/s, Materializing param=encoder.layer.6.attention.self.query.bias]\rLoading weights:  55%|█████▍    | 109/199 [00:00<00:00, 1990.59it/s, Materializing param=encoder.layer.6.attention.self.query.weight]\rLoading weights:  55%|█████▍    | 109/199 [00:00<00:00, 1988.12it/s, Materializing param=encoder.layer.6.attention.self.query.weight]\rLoading weights:  55%|█████▌    | 110/199 [00:00<00:00, 2001.59it/s, Materializing param=encoder.layer.6.attention.self.value.bias]  \rLoading weights:  55%|█████▌    | 110/199 [00:00<00:00, 1999.10it/s, Materializing param=encoder.layer.6.attention.self.value.bias]\rLoading weights:  56%|█████▌    | 111/199 [00:00<00:00, 2012.25it/s, Materializing param=encoder.layer.6.attention.self.value.weight]\rLoading weights:  56%|█████▌    | 111/199 [00:00<00:00, 2009.79it/s, Materializing param=encoder.layer.6.attention.self.value.weight]\rLoading weights:  56%|█████▋    | 112/199 [00:00<00:00, 2022.78it/s, Materializing param=encoder.layer.6.intermediate.dense.bias]    \rLoading weights:  56%|█████▋    | 112/199 [00:00<00:00, 2020.27it/s, Materializing param=encoder.layer.6.intermediate.dense.bias]\rLoading weights:  57%|█████▋    | 113/199 [00:00<00:00, 2033.25it/s, Materializing param=encoder.layer.6.intermediate.dense.weight]\rLoading weights:  57%|█████▋    | 113/199 [00:00<00:00, 2030.74it/s, Materializing param=encoder.layer.6.intermediate.dense.weight]\rLoading weights:  57%|█████▋    | 114/199 [00:00<00:00, 2043.42it/s, Materializing param=encoder.layer.6.output.LayerNorm.bias]    \rLoading weights:  57%|█████▋    | 114/199 [00:00<00:00, 2040.96it/s, Materializing param=encoder.layer.6.output.LayerNorm.bias]\rLoading weights:  58%|█████▊    | 115/199 [00:00<00:00, 2054.42it/s, Materializing param=encoder.layer.6.output.LayerNorm.weight]\rLoading weights:  58%|█████▊    | 115/199 [00:00<00:00, 2052.03it/s, Materializing param=encoder.layer.6.output.LayerNorm.weight]\rLoading weights:  58%|█████▊    | 116/199 [00:00<00:00, 2065.61it/s, Materializing param=encoder.layer.6.output.dense.bias]      \rLoading weights:  58%|█████▊    | 116/199 [00:00<00:00, 2063.21it/s, Materializing param=encoder.layer.6.output.dense.bias]\rLoading weights:  59%|█████▉    | 117/199 [00:00<00:00, 2076.70it/s, Materializing param=encoder.layer.6.output.dense.weight]\rLoading weights:  59%|█████▉    | 117/199 [00:00<00:00, 2074.29it/s, Materializing param=encoder.layer.6.output.dense.weight]\rLoading weights:  59%|█████▉    | 118/199 [00:00<00:00, 2087.77it/s, Materializing param=encoder.layer.7.attention.output.LayerNorm.bias]\rLoading weights:  59%|█████▉    | 118/199 [00:00<00:00, 2085.36it/s, Materializing param=encoder.layer.7.attention.output.LayerNorm.bias]\rLoading weights:  60%|█████▉    | 119/199 [00:00<00:00, 2098.58it/s, Materializing param=encoder.layer.7.attention.output.LayerNorm.weight]\rLoading weights:  60%|█████▉    | 119/199 [00:00<00:00, 2096.15it/s, Materializing param=encoder.layer.7.attention.output.LayerNorm.weight]\rLoading weights:  60%|██████    | 120/199 [00:00<00:00, 2109.43it/s, Materializing param=encoder.layer.7.attention.output.dense.bias]      \rLoading weights:  60%|██████    | 120/199 [00:00<00:00, 2106.99it/s, Materializing param=encoder.layer.7.attention.output.dense.bias]\rLoading weights:  61%|██████    | 121/199 [00:00<00:00, 2120.08it/s, Materializing param=encoder.layer.7.attention.output.dense.weight]\rLoading weights:  61%|██████    | 121/199 [00:00<00:00, 2117.57it/s, Materializing param=encoder.layer.7.attention.output.dense.weight]\rLoading weights:  61%|██████▏   | 122/199 [00:00<00:00, 2130.71it/s, Materializing param=encoder.layer.7.attention.self.key.bias]      \rLoading weights:  61%|██████▏   | 122/199 [00:00<00:00, 2128.40it/s, Materializing param=encoder.layer.7.attention.self.key.bias]\rLoading weights:  62%|██████▏   | 123/199 [00:00<00:00, 2141.30it/s, Materializing param=encoder.layer.7.attention.self.key.weight]\rLoading weights:  62%|██████▏   | 123/199 [00:00<00:00, 2138.94it/s, Materializing param=encoder.layer.7.attention.self.key.weight]\rLoading weights:  62%|██████▏   | 124/199 [00:00<00:00, 2150.80it/s, Materializing param=encoder.layer.7.attention.self.query.bias]\rLoading weights:  62%|██████▏   | 124/199 [00:00<00:00, 2148.21it/s, Materializing param=encoder.layer.7.attention.self.query.bias]\rLoading weights:  63%|██████▎   | 125/199 [00:00<00:00, 2160.83it/s, Materializing param=encoder.layer.7.attention.self.query.weight]\rLoading weights:  63%|██████▎   | 125/199 [00:00<00:00, 2158.42it/s, Materializing param=encoder.layer.7.attention.self.query.weight]\rLoading weights:  63%|██████▎   | 126/199 [00:00<00:00, 2171.09it/s, Materializing param=encoder.layer.7.attention.self.value.bias]  \rLoading weights:  63%|██████▎   | 126/199 [00:00<00:00, 2168.69it/s, Materializing param=encoder.layer.7.attention.self.value.bias]\rLoading weights:  64%|██████▍   | 127/199 [00:00<00:00, 2181.29it/s, Materializing param=encoder.layer.7.attention.self.value.weight]\rLoading weights:  64%|██████▍   | 127/199 [00:00<00:00, 2178.91it/s, Materializing param=encoder.layer.7.attention.self.value.weight]\rLoading weights:  64%|██████▍   | 128/199 [00:00<00:00, 2190.98it/s, Materializing param=encoder.layer.7.intermediate.dense.bias]    \rLoading weights:  64%|██████▍   | 128/199 [00:00<00:00, 2188.43it/s, Materializing param=encoder.layer.7.intermediate.dense.bias]\rLoading weights:  65%|██████▍   | 129/199 [00:00<00:00, 2200.44it/s, Materializing param=encoder.layer.7.intermediate.dense.weight]\rLoading weights:  65%|██████▍   | 129/199 [00:00<00:00, 2197.59it/s, Materializing param=encoder.layer.7.intermediate.dense.weight]\rLoading weights:  65%|██████▌   | 130/199 [00:00<00:00, 2208.51it/s, Materializing param=encoder.layer.7.output.LayerNorm.bias]    \rLoading weights:  65%|██████▌   | 130/199 [00:00<00:00, 2205.42it/s, Materializing param=encoder.layer.7.output.LayerNorm.bias]\rLoading weights:  66%|██████▌   | 131/199 [00:00<00:00, 2217.34it/s, Materializing param=encoder.layer.7.output.LayerNorm.weight]\rLoading weights:  66%|██████▌   | 131/199 [00:00<00:00, 2215.46it/s, Materializing param=encoder.layer.7.output.LayerNorm.weight]\rLoading weights:  66%|██████▋   | 132/199 [00:00<00:00, 2228.52it/s, Materializing param=encoder.layer.7.output.dense.bias]      \rLoading weights:  66%|██████▋   | 132/199 [00:00<00:00, 2226.63it/s, Materializing param=encoder.layer.7.output.dense.bias]\rLoading weights:  67%|██████▋   | 133/199 [00:00<00:00, 2239.59it/s, Materializing param=encoder.layer.7.output.dense.weight]\rLoading weights:  67%|██████▋   | 133/199 [00:00<00:00, 2237.69it/s, Materializing param=encoder.layer.7.output.dense.weight]\rLoading weights:  67%|██████▋   | 134/199 [00:00<00:00, 2250.60it/s, Materializing param=encoder.layer.8.attention.output.LayerNorm.bias]\rLoading weights:  67%|██████▋   | 134/199 [00:00<00:00, 2248.68it/s, Materializing param=encoder.layer.8.attention.output.LayerNorm.bias]\rLoading weights:  68%|██████▊   | 135/199 [00:00<00:00, 2261.39it/s, Materializing param=encoder.layer.8.attention.output.LayerNorm.weight]\rLoading weights:  68%|██████▊   | 135/199 [00:00<00:00, 2259.37it/s, Materializing param=encoder.layer.8.attention.output.LayerNorm.weight]\rLoading weights:  68%|██████▊   | 136/199 [00:00<00:00, 2272.67it/s, Materializing param=encoder.layer.8.attention.output.dense.bias]      \rLoading weights:  68%|██████▊   | 136/199 [00:00<00:00, 2270.86it/s, Materializing param=encoder.layer.8.attention.output.dense.bias]\rLoading weights:  69%|██████▉   | 137/199 [00:00<00:00, 2284.18it/s, Materializing param=encoder.layer.8.attention.output.dense.weight]\rLoading weights:  69%|██████▉   | 137/199 [00:00<00:00, 2282.34it/s, Materializing param=encoder.layer.8.attention.output.dense.weight]\rLoading weights:  69%|██████▉   | 138/199 [00:00<00:00, 2295.69it/s, Materializing param=encoder.layer.8.attention.self.key.bias]      \rLoading weights:  69%|██████▉   | 138/199 [00:00<00:00, 2293.82it/s, Materializing param=encoder.layer.8.attention.self.key.bias]\rLoading weights:  70%|██████▉   | 139/199 [00:00<00:00, 2307.07it/s, Materializing param=encoder.layer.8.attention.self.key.weight]\rLoading weights:  70%|██████▉   | 139/199 [00:00<00:00, 2305.23it/s, Materializing param=encoder.layer.8.attention.self.key.weight]\rLoading weights:  70%|███████   | 140/199 [00:00<00:00, 2318.58it/s, Materializing param=encoder.layer.8.attention.self.query.bias]\rLoading weights:  70%|███████   | 140/199 [00:00<00:00, 2316.74it/s, Materializing param=encoder.layer.8.attention.self.query.bias]\rLoading weights:  71%|███████   | 141/199 [00:00<00:00, 2329.86it/s, Materializing param=encoder.layer.8.attention.self.query.weight]\rLoading weights:  71%|███████   | 141/199 [00:00<00:00, 2327.98it/s, Materializing param=encoder.layer.8.attention.self.query.weight]\rLoading weights:  71%|███████▏  | 142/199 [00:00<00:00, 2340.54it/s, Materializing param=encoder.layer.8.attention.self.value.bias]  \rLoading weights:  71%|███████▏  | 142/199 [00:00<00:00, 2338.62it/s, Materializing param=encoder.layer.8.attention.self.value.bias]\rLoading weights:  72%|███████▏  | 143/199 [00:00<00:00, 2351.13it/s, Materializing param=encoder.layer.8.attention.self.value.weight]\rLoading weights:  72%|███████▏  | 143/199 [00:00<00:00, 2349.23it/s, Materializing param=encoder.layer.8.attention.self.value.weight]\rLoading weights:  72%|███████▏  | 144/199 [00:00<00:00, 2361.80it/s, Materializing param=encoder.layer.8.intermediate.dense.bias]    \rLoading weights:  72%|███████▏  | 144/199 [00:00<00:00, 2359.90it/s, Materializing param=encoder.layer.8.intermediate.dense.bias]\rLoading weights:  73%|███████▎  | 145/199 [00:00<00:00, 2372.64it/s, Materializing param=encoder.layer.8.intermediate.dense.weight]\rLoading weights:  73%|███████▎  | 145/199 [00:00<00:00, 2370.66it/s, Materializing param=encoder.layer.8.intermediate.dense.weight]\rLoading weights:  73%|███████▎  | 146/199 [00:00<00:00, 2382.97it/s, Materializing param=encoder.layer.8.output.LayerNorm.bias]    \rLoading weights:  73%|███████▎  | 146/199 [00:00<00:00, 2381.01it/s, Materializing param=encoder.layer.8.output.LayerNorm.bias]\rLoading weights:  74%|███████▍  | 147/199 [00:00<00:00, 2393.23it/s, Materializing param=encoder.layer.8.output.LayerNorm.weight]\rLoading weights:  74%|███████▍  | 147/199 [00:00<00:00, 2391.21it/s, Materializing param=encoder.layer.8.output.LayerNorm.weight]\rLoading weights:  74%|███████▍  | 148/199 [00:00<00:00, 2403.49it/s, Materializing param=encoder.layer.8.output.dense.bias]      \rLoading weights:  74%|███████▍  | 148/199 [00:00<00:00, 2400.99it/s, Materializing param=encoder.layer.8.output.dense.bias]\rLoading weights:  75%|███████▍  | 149/199 [00:00<00:00, 2412.90it/s, Materializing param=encoder.layer.8.output.dense.weight]\rLoading weights:  75%|███████▍  | 149/199 [00:00<00:00, 2410.86it/s, Materializing param=encoder.layer.8.output.dense.weight]\rLoading weights:  75%|███████▌  | 150/199 [00:00<00:00, 2423.13it/s, Materializing param=encoder.layer.9.attention.output.LayerNorm.bias]\rLoading weights:  75%|███████▌  | 150/199 [00:00<00:00, 2421.15it/s, Materializing param=encoder.layer.9.attention.output.LayerNorm.bias]\rLoading weights:  76%|███████▌  | 151/199 [00:00<00:00, 2433.26it/s, Materializing param=encoder.layer.9.attention.output.LayerNorm.weight]\rLoading weights:  76%|███████▌  | 151/199 [00:00<00:00, 2431.28it/s, Materializing param=encoder.layer.9.attention.output.LayerNorm.weight]\rLoading weights:  76%|███████▋  | 152/199 [00:00<00:00, 2443.23it/s, Materializing param=encoder.layer.9.attention.output.dense.bias]      \rLoading weights:  76%|███████▋  | 152/199 [00:00<00:00, 2441.22it/s, Materializing param=encoder.layer.9.attention.output.dense.bias]\rLoading weights:  77%|███████▋  | 153/199 [00:00<00:00, 2453.20it/s, Materializing param=encoder.layer.9.attention.output.dense.weight]\rLoading weights:  77%|███████▋  | 153/199 [00:00<00:00, 2451.23it/s, Materializing param=encoder.layer.9.attention.output.dense.weight]\rLoading weights:  77%|███████▋  | 154/199 [00:00<00:00, 2462.72it/s, Materializing param=encoder.layer.9.attention.self.key.bias]      \rLoading weights:  77%|███████▋  | 154/199 [00:00<00:00, 2460.68it/s, Materializing param=encoder.layer.9.attention.self.key.bias]\rLoading weights:  78%|███████▊  | 155/199 [00:00<00:00, 2472.53it/s, Materializing param=encoder.layer.9.attention.self.key.weight]\rLoading weights:  78%|███████▊  | 155/199 [00:00<00:00, 2470.51it/s, Materializing param=encoder.layer.9.attention.self.key.weight]\rLoading weights:  78%|███████▊  | 156/199 [00:00<00:00, 2482.54it/s, Materializing param=encoder.layer.9.attention.self.query.bias]\rLoading weights:  78%|███████▊  | 156/199 [00:00<00:00, 2480.60it/s, Materializing param=encoder.layer.9.attention.self.query.bias]\rLoading weights:  79%|███████▉  | 157/199 [00:00<00:00, 2492.40it/s, Materializing param=encoder.layer.9.attention.self.query.weight]\rLoading weights:  79%|███████▉  | 157/199 [00:00<00:00, 2490.45it/s, Materializing param=encoder.layer.9.attention.self.query.weight]\rLoading weights:  79%|███████▉  | 158/199 [00:00<00:00, 2502.04it/s, Materializing param=encoder.layer.9.attention.self.value.bias]  \rLoading weights:  79%|███████▉  | 158/199 [00:00<00:00, 2500.07it/s, Materializing param=encoder.layer.9.attention.self.value.bias]\rLoading weights:  80%|███████▉  | 159/199 [00:00<00:00, 2512.40it/s, Materializing param=encoder.layer.9.attention.self.value.weight]\rLoading weights:  80%|███████▉  | 159/199 [00:00<00:00, 2510.48it/s, Materializing param=encoder.layer.9.attention.self.value.weight]\rLoading weights:  80%|████████  | 160/199 [00:00<00:00, 2522.75it/s, Materializing param=encoder.layer.9.intermediate.dense.bias]    \rLoading weights:  80%|████████  | 160/199 [00:00<00:00, 2520.76it/s, Materializing param=encoder.layer.9.intermediate.dense.bias]\rLoading weights:  81%|████████  | 161/199 [00:00<00:00, 2532.67it/s, Materializing param=encoder.layer.9.intermediate.dense.weight]\rLoading weights:  81%|████████  | 161/199 [00:00<00:00, 2530.70it/s, Materializing param=encoder.layer.9.intermediate.dense.weight]\rLoading weights:  81%|████████▏ | 162/199 [00:00<00:00, 2542.39it/s, Materializing param=encoder.layer.9.output.LayerNorm.bias]    \rLoading weights:  81%|████████▏ | 162/199 [00:00<00:00, 2540.54it/s, Materializing param=encoder.layer.9.output.LayerNorm.bias]\rLoading weights:  82%|████████▏ | 163/199 [00:00<00:00, 2552.62it/s, Materializing param=encoder.layer.9.output.LayerNorm.weight]\rLoading weights:  82%|████████▏ | 163/199 [00:00<00:00, 2550.76it/s, Materializing param=encoder.layer.9.output.LayerNorm.weight]\rLoading weights:  82%|████████▏ | 164/199 [00:00<00:00, 2562.96it/s, Materializing param=encoder.layer.9.output.dense.bias]      \rLoading weights:  82%|████████▏ | 164/199 [00:00<00:00, 2561.12it/s, Materializing param=encoder.layer.9.output.dense.bias]\rLoading weights:  83%|████████▎ | 165/199 [00:00<00:00, 2573.16it/s, Materializing param=encoder.layer.9.output.dense.weight]\rLoading weights:  83%|████████▎ | 165/199 [00:00<00:00, 2571.27it/s, Materializing param=encoder.layer.9.output.dense.weight]\rLoading weights:  83%|████████▎ | 166/199 [00:00<00:00, 2583.03it/s, Materializing param=encoder.layer.10.attention.output.LayerNorm.bias]\rLoading weights:  83%|████████▎ | 166/199 [00:00<00:00, 2581.02it/s, Materializing param=encoder.layer.10.attention.output.LayerNorm.bias]\rLoading weights:  84%|████████▍ | 167/199 [00:00<00:00, 2592.34it/s, Materializing param=encoder.layer.10.attention.output.LayerNorm.weight]\rLoading weights:  84%|████████▍ | 167/199 [00:00<00:00, 2590.35it/s, Materializing param=encoder.layer.10.attention.output.LayerNorm.weight]\rLoading weights:  84%|████████▍ | 168/199 [00:00<00:00, 2601.96it/s, Materializing param=encoder.layer.10.attention.output.dense.bias]      \rLoading weights:  84%|████████▍ | 168/199 [00:00<00:00, 2600.00it/s, Materializing param=encoder.layer.10.attention.output.dense.bias]\rLoading weights:  85%|████████▍ | 169/199 [00:00<00:00, 2611.20it/s, Materializing param=encoder.layer.10.attention.output.dense.weight]\rLoading weights:  85%|████████▍ | 169/199 [00:00<00:00, 2609.00it/s, Materializing param=encoder.layer.10.attention.output.dense.weight]\rLoading weights:  85%|████████▌ | 170/199 [00:00<00:00, 2620.59it/s, Materializing param=encoder.layer.10.attention.self.key.bias]      \rLoading weights:  85%|████████▌ | 170/199 [00:00<00:00, 2618.60it/s, Materializing param=encoder.layer.10.attention.self.key.bias]\rLoading weights:  86%|████████▌ | 171/199 [00:00<00:00, 2629.77it/s, Materializing param=encoder.layer.10.attention.self.key.weight]\rLoading weights:  86%|████████▌ | 171/199 [00:00<00:00, 2627.82it/s, Materializing param=encoder.layer.10.attention.self.key.weight]\rLoading weights:  86%|████████▋ | 172/199 [00:00<00:00, 2639.36it/s, Materializing param=encoder.layer.10.attention.self.query.bias]\rLoading weights:  86%|████████▋ | 172/199 [00:00<00:00, 2637.41it/s, Materializing param=encoder.layer.10.attention.self.query.bias]\rLoading weights:  87%|████████▋ | 173/199 [00:00<00:00, 2648.72it/s, Materializing param=encoder.layer.10.attention.self.query.weight]\rLoading weights:  87%|████████▋ | 173/199 [00:00<00:00, 2646.73it/s, Materializing param=encoder.layer.10.attention.self.query.weight]\rLoading weights:  87%|████████▋ | 174/199 [00:00<00:00, 2657.46it/s, Materializing param=encoder.layer.10.attention.self.value.bias]  \rLoading weights:  87%|████████▋ | 174/199 [00:00<00:00, 2655.36it/s, Materializing param=encoder.layer.10.attention.self.value.bias]\rLoading weights:  88%|████████▊ | 175/199 [00:00<00:00, 2666.07it/s, Materializing param=encoder.layer.10.attention.self.value.weight]\rLoading weights:  88%|████████▊ | 175/199 [00:00<00:00, 2663.91it/s, Materializing param=encoder.layer.10.attention.self.value.weight]\rLoading weights:  88%|████████▊ | 176/199 [00:00<00:00, 2674.87it/s, Materializing param=encoder.layer.10.intermediate.dense.bias]    \rLoading weights:  88%|████████▊ | 176/199 [00:00<00:00, 2672.81it/s, Materializing param=encoder.layer.10.intermediate.dense.bias]\rLoading weights:  89%|████████▉ | 177/199 [00:00<00:00, 2683.57it/s, Materializing param=encoder.layer.10.intermediate.dense.weight]\rLoading weights:  89%|████████▉ | 177/199 [00:00<00:00, 2681.50it/s, Materializing param=encoder.layer.10.intermediate.dense.weight]\rLoading weights:  89%|████████▉ | 178/199 [00:00<00:00, 2692.63it/s, Materializing param=encoder.layer.10.output.LayerNorm.bias]    \rLoading weights:  89%|████████▉ | 178/199 [00:00<00:00, 2690.57it/s, Materializing param=encoder.layer.10.output.LayerNorm.bias]\rLoading weights:  90%|████████▉ | 179/199 [00:00<00:00, 2701.58it/s, Materializing param=encoder.layer.10.output.LayerNorm.weight]\rLoading weights:  90%|████████▉ | 179/199 [00:00<00:00, 2699.54it/s, Materializing param=encoder.layer.10.output.LayerNorm.weight]\rLoading weights:  90%|█████████ | 180/199 [00:00<00:00, 2711.07it/s, Materializing param=encoder.layer.10.output.dense.bias]      \rLoading weights:  90%|█████████ | 180/199 [00:00<00:00, 2709.12it/s, Materializing param=encoder.layer.10.output.dense.bias]\rLoading weights:  91%|█████████ | 181/199 [00:00<00:00, 2720.14it/s, Materializing param=encoder.layer.10.output.dense.weight]\rLoading weights:  91%|█████████ | 181/199 [00:00<00:00, 2718.19it/s, Materializing param=encoder.layer.10.output.dense.weight]\rLoading weights:  91%|█████████▏| 182/199 [00:00<00:00, 2729.69it/s, Materializing param=encoder.layer.11.attention.output.LayerNorm.bias]\rLoading weights:  91%|█████████▏| 182/199 [00:00<00:00, 2727.70it/s, Materializing param=encoder.layer.11.attention.output.LayerNorm.bias]\rLoading weights:  92%|█████████▏| 183/199 [00:00<00:00, 2738.40it/s, Materializing param=encoder.layer.11.attention.output.LayerNorm.weight]\rLoading weights:  92%|█████████▏| 183/199 [00:00<00:00, 2736.31it/s, Materializing param=encoder.layer.11.attention.output.LayerNorm.weight]\rLoading weights:  92%|█████████▏| 184/199 [00:00<00:00, 2747.33it/s, Materializing param=encoder.layer.11.attention.output.dense.bias]      \rLoading weights:  92%|█████████▏| 184/199 [00:00<00:00, 2745.29it/s, Materializing param=encoder.layer.11.attention.output.dense.bias]\rLoading weights:  93%|█████████▎| 185/199 [00:00<00:00, 2756.09it/s, Materializing param=encoder.layer.11.attention.output.dense.weight]\rLoading weights:  93%|█████████▎| 185/199 [00:00<00:00, 2754.03it/s, Materializing param=encoder.layer.11.attention.output.dense.weight]\rLoading weights:  93%|█████████▎| 186/199 [00:00<00:00, 2764.64it/s, Materializing param=encoder.layer.11.attention.self.key.bias]      \rLoading weights:  93%|█████████▎| 186/199 [00:00<00:00, 2762.54it/s, Materializing param=encoder.layer.11.attention.self.key.bias]\rLoading weights:  94%|█████████▍| 187/199 [00:00<00:00, 2773.43it/s, Materializing param=encoder.layer.11.attention.self.key.weight]\rLoading weights:  94%|█████████▍| 187/199 [00:00<00:00, 2771.38it/s, Materializing param=encoder.layer.11.attention.self.key.weight]\rLoading weights:  94%|█████████▍| 188/199 [00:00<00:00, 2781.89it/s, Materializing param=encoder.layer.11.attention.self.query.bias]\rLoading weights:  94%|█████████▍| 188/199 [00:00<00:00, 2779.84it/s, Materializing param=encoder.layer.11.attention.self.query.bias]\rLoading weights:  95%|█████████▍| 189/199 [00:00<00:00, 2790.19it/s, Materializing param=encoder.layer.11.attention.self.query.weight]\rLoading weights:  95%|█████████▍| 189/199 [00:00<00:00, 2788.09it/s, Materializing param=encoder.layer.11.attention.self.query.weight]\rLoading weights:  95%|█████████▌| 190/199 [00:00<00:00, 2798.75it/s, Materializing param=encoder.layer.11.attention.self.value.bias]  \rLoading weights:  95%|█████████▌| 190/199 [00:00<00:00, 2796.70it/s, Materializing param=encoder.layer.11.attention.self.value.bias]\rLoading weights:  96%|█████████▌| 191/199 [00:00<00:00, 2806.89it/s, Materializing param=encoder.layer.11.attention.self.value.weight]\rLoading weights:  96%|█████████▌| 191/199 [00:00<00:00, 2804.79it/s, Materializing param=encoder.layer.11.attention.self.value.weight]\rLoading weights:  96%|█████████▋| 192/199 [00:00<00:00, 2815.26it/s, Materializing param=encoder.layer.11.intermediate.dense.bias]    \rLoading weights:  96%|█████████▋| 192/199 [00:00<00:00, 2813.26it/s, Materializing param=encoder.layer.11.intermediate.dense.bias]\rLoading weights:  97%|█████████▋| 193/199 [00:00<00:00, 2823.89it/s, Materializing param=encoder.layer.11.intermediate.dense.weight]\rLoading weights:  97%|█████████▋| 193/199 [00:00<00:00, 2821.84it/s, Materializing param=encoder.layer.11.intermediate.dense.weight]\rLoading weights:  97%|█████████▋| 194/199 [00:00<00:00, 2832.51it/s, Materializing param=encoder.layer.11.output.LayerNorm.bias]    \rLoading weights:  97%|█████████▋| 194/199 [00:00<00:00, 2830.39it/s, Materializing param=encoder.layer.11.output.LayerNorm.bias]\rLoading weights:  98%|█████████▊| 195/199 [00:00<00:00, 2840.75it/s, Materializing param=encoder.layer.11.output.LayerNorm.weight]\rLoading weights:  98%|█████████▊| 195/199 [00:00<00:00, 2838.76it/s, Materializing param=encoder.layer.11.output.LayerNorm.weight]\rLoading weights:  98%|█████████▊| 196/199 [00:00<00:00, 2849.20it/s, Materializing param=encoder.layer.11.output.dense.bias]      \rLoading weights:  98%|█████████▊| 196/199 [00:00<00:00, 2847.11it/s, Materializing param=encoder.layer.11.output.dense.bias]\rLoading weights:  99%|█████████▉| 197/199 [00:00<00:00, 2857.82it/s, Materializing param=encoder.layer.11.output.dense.weight]\rLoading weights:  99%|█████████▉| 197/199 [00:00<00:00, 2855.88it/s, Materializing param=encoder.layer.11.output.dense.weight]\rLoading weights:  99%|█████████▉| 198/199 [00:00<00:00, 2866.71it/s, Materializing param=pooler.dense.bias]                   \rLoading weights:  99%|█████████▉| 198/199 [00:00<00:00, 2864.84it/s, Materializing param=pooler.dense.bias]\rLoading weights: 100%|██████████| 199/199 [00:00<00:00, 2875.79it/s, Materializing param=pooler.dense.weight]\rLoading weights: 100%|██████████| 199/199 [00:00<00:00, 2873.95it/s, Materializing param=pooler.dense.weight]\rLoading weights: 100%|██████████| 199/199 [00:00<00:00, 2869.15it/s, Materializing param=pooler.dense.weight]\n\u001b[1mXLMRobertaModel LOAD REPORT\u001b[0m from: xlm-roberta-base\nKey                       | Status     |  | \n--------------------------+------------+--+-\nlm_head.bias              | UNEXPECTED |  | \nlm_head.dense.bias        | UNEXPECTED |  | \nlm_head.layer_norm.bias   | UNEXPECTED |  | \nlm_head.dense.weight      | UNEXPECTED |  | \nlm_head.layer_norm.weight | UNEXPECTED |  | \n\n\u001b[3mNotes:\n- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n2026-02-15 19:43:25,080 | INFO | Polysemy lexicon size: 3726\n\rStatic sim:   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim:  19%|█▉        | 378/2000 [00:00<00:00, 3775.93it/s]\rStatic sim:  40%|███▉      | 791/2000 [00:00<00:00, 3981.33it/s]\rStatic sim:  61%|██████    | 1212/2000 [00:00<00:00, 4083.77it/s]\rStatic sim:  81%|████████  | 1623/2000 [00:00<00:00, 4094.02it/s]\rStatic sim: 100%|██████████| 2000/2000 [00:00<00:00, 4086.87it/s]\n\rStatic sim (mismatch):   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim (mismatch):  22%|██▏       | 439/2000 [00:00<00:00, 4386.71it/s]\rStatic sim (mismatch):  44%|████▍     | 884/2000 [00:00<00:00, 4418.27it/s]\rStatic sim (mismatch):  66%|██████▋   | 1330/2000 [00:00<00:00, 4434.43it/s]\rStatic sim (mismatch):  89%|████████▊ | 1774/2000 [00:00<00:00, 4383.09it/s]\rStatic sim (mismatch): 100%|██████████| 2000/2000 [00:00<00:00, 4383.89it/s]\n\rStatic sim:   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim:  19%|█▉        | 379/2000 [00:00<00:00, 3787.38it/s]\rStatic sim:  40%|████      | 801/2000 [00:00<00:00, 4039.09it/s]\rStatic sim:  61%|██████    | 1223/2000 [00:00<00:00, 4119.27it/s]\rStatic sim:  82%|████████▎ | 1650/2000 [00:00<00:00, 4175.43it/s]\rStatic sim: 100%|██████████| 2000/2000 [00:00<00:00, 4130.15it/s]\n\rStatic sim (mismatch):   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim (mismatch):  22%|██▏       | 439/2000 [00:00<00:00, 4379.46it/s]\rStatic sim (mismatch):  44%|████▍     | 879/2000 [00:00<00:00, 4390.29it/s]\rStatic sim (mismatch):  66%|██████▌   | 1319/2000 [00:00<00:00, 4384.85it/s]\rStatic sim (mismatch):  88%|████████▊ | 1762/2000 [00:00<00:00, 4399.90it/s]\rStatic sim (mismatch): 100%|██████████| 2000/2000 [00:00<00:00, 4381.85it/s]\n\rStatic sim:   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim:  22%|██▏       | 436/2000 [00:00<00:00, 4356.71it/s]\rStatic sim:  44%|████▎     | 872/2000 [00:00<00:00, 4316.81it/s]\rStatic sim:  65%|██████▌   | 1304/2000 [00:00<00:00, 4312.19it/s]\rStatic sim:  87%|████████▋ | 1736/2000 [00:00<00:00, 4210.59it/s]\rStatic sim: 100%|██████████| 2000/2000 [00:00<00:00, 4244.92it/s]\n\rStatic sim (mismatch):   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim (mismatch):  22%|██▏       | 440/2000 [00:00<00:00, 4395.36it/s]\rStatic sim (mismatch):  44%|████▍     | 880/2000 [00:00<00:00, 4394.26it/s]\rStatic sim (mismatch):  66%|██████▌   | 1320/2000 [00:00<00:00, 4362.37it/s]\rStatic sim (mismatch):  88%|████████▊ | 1769/2000 [00:00<00:00, 4411.49it/s]\rStatic sim (mismatch): 100%|██████████| 2000/2000 [00:00<00:00, 4395.61it/s]\n\rStatic sim:   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim:  21%|██        | 419/2000 [00:00<00:00, 4187.51it/s]\rStatic sim:  42%|████▏     | 849/2000 [00:00<00:00, 4251.96it/s]\rStatic sim:  64%|██████▍   | 1284/2000 [00:00<00:00, 4293.69it/s]\rStatic sim:  86%|████████▌ | 1720/2000 [00:00<00:00, 4316.80it/s]\rStatic sim: 100%|██████████| 2000/2000 [00:00<00:00, 4302.83it/s]\n\rStatic sim (mismatch):   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim (mismatch):  23%|██▎       | 455/2000 [00:00<00:00, 4548.20it/s]\rStatic sim (mismatch):  46%|████▌     | 912/2000 [00:00<00:00, 4560.45it/s]\rStatic sim (mismatch):  68%|██████▊   | 1369/2000 [00:00<00:00, 4549.96it/s]\rStatic sim (mismatch):  91%|█████████▏| 1825/2000 [00:00<00:00, 4550.57it/s]\rStatic sim (mismatch): 100%|██████████| 2000/2000 [00:00<00:00, 4551.70it/s]\nTraceback (most recent call last):\n  File \"/data/hypogenicai/workspaces/similar-embeddings-nlp-5ef8-codex/src/run_experiments.py\", line 435, in <module>\n    main()\n  File \"/data/hypogenicai/workspaces/similar-embeddings-nlp-5ef8-codex/src/run_experiments.py\", line 331, in main\n    samples = load_mcl_wic_pair(data_path, gold_path)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/hypogenicai/workspaces/similar-embeddings-nlp-5ef8-codex/src/run_experiments.py\", line 75, in load_mcl_wic_pair\n    start2, end2 = _parse_range(item[\"ranges2\"])\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/hypogenicai/workspaces/similar-embeddings-nlp-5ef8-codex/src/run_experiments.py\", line 56, in _parse_range\n    raise ValueError(f\"Unexpected range format: {range_str}\")\nValueError: Unexpected range format: 104-108,121-128\n","exit_code":1,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_86","type":"reasoning","text":"**Updating range parsing for multi-span handling**\n\nPlanning to update the range parser to split by commas and compute a continuous span covering all segments by taking the minimum start and maximum end across spans, ensuring multi-token or discontinuous ranges are fully captured."}}
{"type":"item.completed","item":{"id":"item_87","type":"file_change","changes":[{"path":"/data/hypogenicai/workspaces/similar-embeddings-nlp-5ef8-codex/src/run_experiments.py","kind":"update"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_88","type":"reasoning","text":"**Re-running script**"}}
{"type":"item.started","item":{"id":"item_89","type":"command_execution","command":"/bin/bash -lc 'source .venv/bin/activate && python src/run_experiments.py'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_90","type":"reasoning","text":"**Waiting before next step**"}}
{"type":"item.completed","item":{"id":"item_91","type":"reasoning","text":"**Waiting for static simulation completion**"}}
{"type":"item.completed","item":{"id":"item_89","type":"command_execution","command":"/bin/bash -lc 'source .venv/bin/activate && python src/run_experiments.py'","aggregated_output":"2026-02-15 19:43:48,480 | INFO | Starting experiments\n2026-02-15 19:43:48,771 | INFO | Device: cuda\n2026-02-15 19:43:48,864 | INFO | HTTP Request: HEAD https://huggingface.co/xlm-roberta-base/resolve/main/config.json \"HTTP/1.1 200 OK\"\n2026-02-15 19:43:48,908 | INFO | HTTP Request: HEAD https://huggingface.co/xlm-roberta-base/resolve/main/tokenizer_config.json \"HTTP/1.1 200 OK\"\n2026-02-15 19:43:48,958 | INFO | HTTP Request: GET https://huggingface.co/api/models/xlm-roberta-base/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 307 Temporary Redirect\"\n2026-02-15 19:43:48,999 | INFO | HTTP Request: GET https://huggingface.co/api/models/FacebookAI/xlm-roberta-base/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n2026-02-15 19:43:49,039 | INFO | HTTP Request: GET https://huggingface.co/api/models/xlm-roberta-base/tree/main?recursive=true&expand=false \"HTTP/1.1 307 Temporary Redirect\"\n2026-02-15 19:43:49,078 | INFO | HTTP Request: GET https://huggingface.co/api/models/FacebookAI/xlm-roberta-base/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n2026-02-15 19:43:51,011 | INFO | HTTP Request: GET https://huggingface.co/api/models/xlm-roberta-base \"HTTP/1.1 307 Temporary Redirect\"\n2026-02-15 19:43:51,050 | INFO | HTTP Request: GET https://huggingface.co/api/models/FacebookAI/xlm-roberta-base \"HTTP/1.1 200 OK\"\n2026-02-15 19:43:51,123 | INFO | HTTP Request: HEAD https://huggingface.co/xlm-roberta-base/resolve/main/config.json \"HTTP/1.1 200 OK\"\n\rLoading weights:   0%|          | 0/199 [00:00<?, ?it/s]\rLoading weights:   1%|          | 1/199 [00:00<00:00, 12446.01it/s, Materializing param=embeddings.LayerNorm.bias]\rLoading weights:   1%|          | 1/199 [00:00<00:00, 5949.37it/s, Materializing param=embeddings.LayerNorm.bias] \rLoading weights:   1%|          | 2/199 [00:00<00:00, 6264.83it/s, Materializing param=embeddings.LayerNorm.weight]\rLoading weights:   1%|          | 2/199 [00:00<00:00, 5181.35it/s, Materializing param=embeddings.LayerNorm.weight]\rLoading weights:   2%|▏         | 3/199 [00:00<00:00, 4627.77it/s, Materializing param=embeddings.position_embeddings.weight]\rLoading weights:   2%|▏         | 3/199 [00:00<00:00, 2939.25it/s, Materializing param=embeddings.position_embeddings.weight]\rLoading weights:   2%|▏         | 4/199 [00:00<00:00, 3253.29it/s, Materializing param=embeddings.token_type_embeddings.weight]\rLoading weights:   2%|▏         | 4/199 [00:00<00:00, 3106.32it/s, Materializing param=embeddings.token_type_embeddings.weight]\rLoading weights:   3%|▎         | 5/199 [00:00<00:00, 3396.20it/s, Materializing param=embeddings.word_embeddings.weight]      \rLoading weights:   3%|▎         | 5/199 [00:00<00:00, 3273.22it/s, Materializing param=embeddings.word_embeddings.weight]\rLoading weights:   3%|▎         | 6/199 [00:00<00:00, 3556.50it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]\rLoading weights:   3%|▎         | 6/199 [00:00<00:00, 3436.55it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]\rLoading weights:   4%|▎         | 7/199 [00:00<00:00, 3690.78it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\rLoading weights:   4%|▎         | 7/199 [00:00<00:00, 3571.79it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\rLoading weights:   4%|▍         | 8/199 [00:00<00:00, 2335.03it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]      \rLoading weights:   4%|▍         | 8/199 [00:00<00:00, 2293.38it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]\rLoading weights:   5%|▍         | 9/199 [00:00<00:00, 2349.31it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\rLoading weights:   5%|▍         | 9/199 [00:00<00:00, 2314.88it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\rLoading weights:   5%|▌         | 10/199 [00:00<00:00, 2252.46it/s, Materializing param=encoder.layer.0.attention.self.key.bias]     \rLoading weights:   5%|▌         | 10/199 [00:00<00:00, 2223.56it/s, Materializing param=encoder.layer.0.attention.self.key.bias]\rLoading weights:   6%|▌         | 11/199 [00:00<00:00, 2378.70it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\rLoading weights:   6%|▌         | 11/199 [00:00<00:00, 2280.30it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\rLoading weights:   6%|▌         | 12/199 [00:00<00:00, 2411.79it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\rLoading weights:   6%|▌         | 12/199 [00:00<00:00, 2384.37it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\rLoading weights:   7%|▋         | 13/199 [00:00<00:00, 2507.17it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\rLoading weights:   7%|▋         | 13/199 [00:00<00:00, 2481.38it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\rLoading weights:   7%|▋         | 14/199 [00:00<00:00, 2609.33it/s, Materializing param=encoder.layer.0.attention.self.value.bias]  \rLoading weights:   7%|▋         | 14/199 [00:00<00:00, 2579.52it/s, Materializing param=encoder.layer.0.attention.self.value.bias]\rLoading weights:   8%|▊         | 15/199 [00:00<00:00, 2691.42it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\rLoading weights:   8%|▊         | 15/199 [00:00<00:00, 2662.60it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\rLoading weights:   8%|▊         | 16/199 [00:00<00:00, 2767.49it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]    \rLoading weights:   8%|▊         | 16/199 [00:00<00:00, 2742.38it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]\rLoading weights:   9%|▊         | 17/199 [00:00<00:00, 2851.90it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\rLoading weights:   9%|▊         | 17/199 [00:00<00:00, 2823.89it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\rLoading weights:   9%|▉         | 18/199 [00:00<00:00, 2931.94it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]    \rLoading weights:   9%|▉         | 18/199 [00:00<00:00, 2903.53it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]\rLoading weights:  10%|▉         | 19/199 [00:00<00:00, 2672.16it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\rLoading weights:  10%|▉         | 19/199 [00:00<00:00, 2650.65it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\rLoading weights:  10%|█         | 20/199 [00:00<00:00, 2728.36it/s, Materializing param=encoder.layer.0.output.dense.bias]      \rLoading weights:  10%|█         | 20/199 [00:00<00:00, 2707.84it/s, Materializing param=encoder.layer.0.output.dense.bias]\rLoading weights:  11%|█         | 21/199 [00:00<00:00, 2774.71it/s, Materializing param=encoder.layer.0.output.dense.weight]\rLoading weights:  11%|█         | 21/199 [00:00<00:00, 2742.31it/s, Materializing param=encoder.layer.0.output.dense.weight]\rLoading weights:  11%|█         | 22/199 [00:00<00:00, 2666.74it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\rLoading weights:  11%|█         | 22/199 [00:00<00:00, 2641.32it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\rLoading weights:  12%|█▏        | 23/199 [00:00<00:00, 2701.91it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]\rLoading weights:  12%|█▏        | 23/199 [00:00<00:00, 2502.63it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]\rLoading weights:  12%|█▏        | 24/199 [00:00<00:00, 2469.42it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]      \rLoading weights:  12%|█▏        | 24/199 [00:00<00:00, 2449.94it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]\rLoading weights:  13%|█▎        | 25/199 [00:00<00:00, 2503.70it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\rLoading weights:  13%|█▎        | 25/199 [00:00<00:00, 2418.25it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\rLoading weights:  13%|█▎        | 26/199 [00:00<00:00, 2382.71it/s, Materializing param=encoder.layer.1.attention.self.key.bias]      \rLoading weights:  13%|█▎        | 26/199 [00:00<00:00, 2365.96it/s, Materializing param=encoder.layer.1.attention.self.key.bias]\rLoading weights:  14%|█▎        | 27/199 [00:00<00:00, 2370.80it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\rLoading weights:  14%|█▎        | 27/199 [00:00<00:00, 2281.49it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\rLoading weights:  14%|█▍        | 28/199 [00:00<00:00, 2264.92it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\rLoading weights:  14%|█▍        | 28/199 [00:00<00:00, 2205.04it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\rLoading weights:  15%|█▍        | 29/199 [00:00<00:00, 2206.01it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\rLoading weights:  15%|█▍        | 29/199 [00:00<00:00, 2183.83it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\rLoading weights:  15%|█▌        | 30/199 [00:00<00:00, 2223.09it/s, Materializing param=encoder.layer.1.attention.self.value.bias]  \rLoading weights:  15%|█▌        | 30/199 [00:00<00:00, 2209.66it/s, Materializing param=encoder.layer.1.attention.self.value.bias]\rLoading weights:  16%|█▌        | 31/199 [00:00<00:00, 2252.03it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\rLoading weights:  16%|█▌        | 31/199 [00:00<00:00, 2194.86it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\rLoading weights:  16%|█▌        | 32/199 [00:00<00:00, 2169.60it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]    \rLoading weights:  16%|█▌        | 32/199 [00:00<00:00, 2139.68it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]\rLoading weights:  17%|█▋        | 33/199 [00:00<00:00, 2173.11it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\rLoading weights:  17%|█▋        | 33/199 [00:00<00:00, 2123.70it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\rLoading weights:  17%|█▋        | 34/199 [00:00<00:00, 2156.36it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]    \rLoading weights:  17%|█▋        | 34/199 [00:00<00:00, 2110.59it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]\rLoading weights:  18%|█▊        | 35/199 [00:00<00:00, 2134.10it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\rLoading weights:  18%|█▊        | 35/199 [00:00<00:00, 2083.90it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\rLoading weights:  18%|█▊        | 36/199 [00:00<00:00, 2084.70it/s, Materializing param=encoder.layer.1.output.dense.bias]      \rLoading weights:  18%|█▊        | 36/199 [00:00<00:00, 2075.50it/s, Materializing param=encoder.layer.1.output.dense.bias]\rLoading weights:  19%|█▊        | 37/199 [00:00<00:00, 2031.57it/s, Materializing param=encoder.layer.1.output.dense.weight]\rLoading weights:  19%|█▊        | 37/199 [00:00<00:00, 1996.98it/s, Materializing param=encoder.layer.1.output.dense.weight]\rLoading weights:  19%|█▉        | 38/199 [00:00<00:00, 2003.41it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\rLoading weights:  19%|█▉        | 38/199 [00:00<00:00, 1965.34it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\rLoading weights:  20%|█▉        | 39/199 [00:00<00:00, 1976.99it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\rLoading weights:  20%|█▉        | 39/199 [00:00<00:00, 1961.84it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\rLoading weights:  20%|██        | 40/199 [00:00<00:00, 1973.47it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]      \rLoading weights:  20%|██        | 40/199 [00:00<00:00, 1957.10it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]\rLoading weights:  21%|██        | 41/199 [00:00<00:00, 1942.82it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\rLoading weights:  21%|██        | 41/199 [00:00<00:00, 1904.69it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\rLoading weights:  21%|██        | 42/199 [00:00<00:00, 1919.88it/s, Materializing param=encoder.layer.2.attention.self.key.bias]      \rLoading weights:  21%|██        | 42/199 [00:00<00:00, 1909.75it/s, Materializing param=encoder.layer.2.attention.self.key.bias]\rLoading weights:  22%|██▏       | 43/199 [00:00<00:00, 1893.31it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\rLoading weights:  22%|██▏       | 43/199 [00:00<00:00, 1868.05it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\rLoading weights:  22%|██▏       | 44/199 [00:00<00:00, 1885.56it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\rLoading weights:  22%|██▏       | 44/199 [00:00<00:00, 1875.58it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\rLoading weights:  23%|██▎       | 45/199 [00:00<00:00, 1875.58it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\rLoading weights:  23%|██▎       | 45/199 [00:00<00:00, 1869.82it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\rLoading weights:  23%|██▎       | 46/199 [00:00<00:00, 1882.30it/s, Materializing param=encoder.layer.2.attention.self.value.bias]  \rLoading weights:  23%|██▎       | 46/199 [00:00<00:00, 1869.68it/s, Materializing param=encoder.layer.2.attention.self.value.bias]\rLoading weights:  24%|██▎       | 47/199 [00:00<00:00, 1869.31it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\rLoading weights:  24%|██▎       | 47/199 [00:00<00:00, 1856.55it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\rLoading weights:  24%|██▍       | 48/199 [00:00<00:00, 1840.62it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]    \rLoading weights:  24%|██▍       | 48/199 [00:00<00:00, 1791.19it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]\rLoading weights:  25%|██▍       | 49/199 [00:00<00:00, 1808.02it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\rLoading weights:  25%|██▍       | 49/199 [00:00<00:00, 1797.47it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\rLoading weights:  25%|██▌       | 50/199 [00:00<00:00, 1754.19it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]    \rLoading weights:  25%|██▌       | 50/199 [00:00<00:00, 1743.27it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]\rLoading weights:  26%|██▌       | 51/199 [00:00<00:00, 1758.07it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\rLoading weights:  26%|██▌       | 51/199 [00:00<00:00, 1751.42it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\rLoading weights:  26%|██▌       | 52/199 [00:00<00:00, 1758.62it/s, Materializing param=encoder.layer.2.output.dense.bias]      \rLoading weights:  26%|██▌       | 52/199 [00:00<00:00, 1752.74it/s, Materializing param=encoder.layer.2.output.dense.bias]\rLoading weights:  27%|██▋       | 53/199 [00:00<00:00, 1766.23it/s, Materializing param=encoder.layer.2.output.dense.weight]\rLoading weights:  27%|██▋       | 53/199 [00:00<00:00, 1752.53it/s, Materializing param=encoder.layer.2.output.dense.weight]\rLoading weights:  27%|██▋       | 54/199 [00:00<00:00, 1749.34it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\rLoading weights:  27%|██▋       | 54/199 [00:00<00:00, 1714.47it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\rLoading weights:  28%|██▊       | 55/199 [00:00<00:00, 1698.96it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\rLoading weights:  28%|██▊       | 55/199 [00:00<00:00, 1679.96it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\rLoading weights:  28%|██▊       | 56/199 [00:00<00:00, 1661.71it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]      \rLoading weights:  28%|██▊       | 56/199 [00:00<00:00, 1652.79it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]\rLoading weights:  29%|██▊       | 57/199 [00:00<00:00, 1637.54it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\rLoading weights:  29%|██▊       | 57/199 [00:00<00:00, 1629.77it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\rLoading weights:  29%|██▉       | 58/199 [00:00<00:00, 1632.52it/s, Materializing param=encoder.layer.3.attention.self.key.bias]      \rLoading weights:  29%|██▉       | 58/199 [00:00<00:00, 1607.53it/s, Materializing param=encoder.layer.3.attention.self.key.bias]\rLoading weights:  30%|██▉       | 59/199 [00:00<00:00, 1600.67it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\rLoading weights:  30%|██▉       | 59/199 [00:00<00:00, 1572.05it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\rLoading weights:  30%|███       | 60/199 [00:00<00:00, 1559.96it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\rLoading weights:  30%|███       | 60/199 [00:00<00:00, 1543.90it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\rLoading weights:  31%|███       | 61/199 [00:00<00:00, 1551.05it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\rLoading weights:  31%|███       | 61/199 [00:00<00:00, 1540.79it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\rLoading weights:  31%|███       | 62/199 [00:00<00:00, 1537.54it/s, Materializing param=encoder.layer.3.attention.self.value.bias]  \rLoading weights:  31%|███       | 62/199 [00:00<00:00, 1525.87it/s, Materializing param=encoder.layer.3.attention.self.value.bias]\rLoading weights:  32%|███▏      | 63/199 [00:00<00:00, 1535.84it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\rLoading weights:  32%|███▏      | 63/199 [00:00<00:00, 1524.30it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\rLoading weights:  32%|███▏      | 64/199 [00:00<00:00, 1518.75it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]    \rLoading weights:  32%|███▏      | 64/199 [00:00<00:00, 1497.14it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]\rLoading weights:  33%|███▎      | 65/199 [00:00<00:00, 1500.76it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\rLoading weights:  33%|███▎      | 65/199 [00:00<00:00, 1492.06it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\rLoading weights:  33%|███▎      | 66/199 [00:00<00:00, 1491.89it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]    \rLoading weights:  33%|███▎      | 66/199 [00:00<00:00, 1489.49it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]\rLoading weights:  34%|███▎      | 67/199 [00:00<00:00, 1503.10it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\rLoading weights:  34%|███▎      | 67/199 [00:00<00:00, 1489.60it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\rLoading weights:  34%|███▍      | 68/199 [00:00<00:00, 1497.26it/s, Materializing param=encoder.layer.3.output.dense.bias]      \rLoading weights:  34%|███▍      | 68/199 [00:00<00:00, 1494.92it/s, Materializing param=encoder.layer.3.output.dense.bias]\rLoading weights:  35%|███▍      | 69/199 [00:00<00:00, 1496.39it/s, Materializing param=encoder.layer.3.output.dense.weight]\rLoading weights:  35%|███▍      | 69/199 [00:00<00:00, 1483.78it/s, Materializing param=encoder.layer.3.output.dense.weight]\rLoading weights:  35%|███▌      | 70/199 [00:00<00:00, 1480.23it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\rLoading weights:  35%|███▌      | 70/199 [00:00<00:00, 1471.61it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\rLoading weights:  36%|███▌      | 71/199 [00:00<00:00, 1486.09it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\rLoading weights:  36%|███▌      | 71/199 [00:00<00:00, 1480.49it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\rLoading weights:  36%|███▌      | 72/199 [00:00<00:00, 1478.99it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]      \rLoading weights:  36%|███▌      | 72/199 [00:00<00:00, 1476.68it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]\rLoading weights:  37%|███▋      | 73/199 [00:00<00:00, 1488.88it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\rLoading weights:  37%|███▋      | 73/199 [00:00<00:00, 1470.59it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\rLoading weights:  37%|███▋      | 74/199 [00:00<00:00, 1485.76it/s, Materializing param=encoder.layer.4.attention.self.key.bias]      \rLoading weights:  37%|███▋      | 74/199 [00:00<00:00, 1483.70it/s, Materializing param=encoder.layer.4.attention.self.key.bias]\rLoading weights:  38%|███▊      | 75/199 [00:00<00:00, 1482.50it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\rLoading weights:  38%|███▊      | 75/199 [00:00<00:00, 1480.21it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\rLoading weights:  38%|███▊      | 76/199 [00:00<00:00, 1494.46it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\rLoading weights:  38%|███▊      | 76/199 [00:00<00:00, 1492.31it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\rLoading weights:  39%|███▊      | 77/199 [00:00<00:00, 1506.43it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\rLoading weights:  39%|███▊      | 77/199 [00:00<00:00, 1504.27it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\rLoading weights:  39%|███▉      | 78/199 [00:00<00:00, 1517.52it/s, Materializing param=encoder.layer.4.attention.self.value.bias]  \rLoading weights:  39%|███▉      | 78/199 [00:00<00:00, 1515.32it/s, Materializing param=encoder.layer.4.attention.self.value.bias]\rLoading weights:  40%|███▉      | 79/199 [00:00<00:00, 1528.58it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\rLoading weights:  40%|███▉      | 79/199 [00:00<00:00, 1521.96it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\rLoading weights:  40%|████      | 80/199 [00:00<00:00, 1534.65it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]    \rLoading weights:  40%|████      | 80/199 [00:00<00:00, 1523.87it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]\rLoading weights:  41%|████      | 81/199 [00:00<00:00, 1538.45it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\rLoading weights:  41%|████      | 81/199 [00:00<00:00, 1536.37it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\rLoading weights:  41%|████      | 82/199 [00:00<00:00, 1551.32it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]    \rLoading weights:  41%|████      | 82/199 [00:00<00:00, 1549.33it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]\rLoading weights:  42%|████▏     | 83/199 [00:00<00:00, 1563.98it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\rLoading weights:  42%|████▏     | 83/199 [00:00<00:00, 1561.94it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\rLoading weights:  42%|████▏     | 84/199 [00:00<00:00, 1576.80it/s, Materializing param=encoder.layer.4.output.dense.bias]      \rLoading weights:  42%|████▏     | 84/199 [00:00<00:00, 1574.83it/s, Materializing param=encoder.layer.4.output.dense.bias]\rLoading weights:  43%|████▎     | 85/199 [00:00<00:00, 1589.35it/s, Materializing param=encoder.layer.4.output.dense.weight]\rLoading weights:  43%|████▎     | 85/199 [00:00<00:00, 1587.29it/s, Materializing param=encoder.layer.4.output.dense.weight]\rLoading weights:  43%|████▎     | 86/199 [00:00<00:00, 1601.82it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\rLoading weights:  43%|████▎     | 86/199 [00:00<00:00, 1599.75it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\rLoading weights:  44%|████▎     | 87/199 [00:00<00:00, 1613.82it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\rLoading weights:  44%|████▎     | 87/199 [00:00<00:00, 1611.70it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\rLoading weights:  44%|████▍     | 88/199 [00:00<00:00, 1626.21it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]      \rLoading weights:  44%|████▍     | 88/199 [00:00<00:00, 1624.18it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]\rLoading weights:  45%|████▍     | 89/199 [00:00<00:00, 1638.16it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\rLoading weights:  45%|████▍     | 89/199 [00:00<00:00, 1636.04it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\rLoading weights:  45%|████▌     | 90/199 [00:00<00:00, 1650.20it/s, Materializing param=encoder.layer.5.attention.self.key.bias]      \rLoading weights:  45%|████▌     | 90/199 [00:00<00:00, 1648.11it/s, Materializing param=encoder.layer.5.attention.self.key.bias]\rLoading weights:  46%|████▌     | 91/199 [00:00<00:00, 1661.83it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\rLoading weights:  46%|████▌     | 91/199 [00:00<00:00, 1659.72it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\rLoading weights:  46%|████▌     | 92/199 [00:00<00:00, 1673.91it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\rLoading weights:  46%|████▌     | 92/199 [00:00<00:00, 1671.88it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\rLoading weights:  47%|████▋     | 93/199 [00:00<00:00, 1685.70it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\rLoading weights:  47%|████▋     | 93/199 [00:00<00:00, 1682.97it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\rLoading weights:  47%|████▋     | 94/199 [00:00<00:00, 1696.79it/s, Materializing param=encoder.layer.5.attention.self.value.bias]  \rLoading weights:  47%|████▋     | 94/199 [00:00<00:00, 1694.67it/s, Materializing param=encoder.layer.5.attention.self.value.bias]\rLoading weights:  48%|████▊     | 95/199 [00:00<00:00, 1708.20it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\rLoading weights:  48%|████▊     | 95/199 [00:00<00:00, 1706.05it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\rLoading weights:  48%|████▊     | 96/199 [00:00<00:00, 1719.87it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]    \rLoading weights:  48%|████▊     | 96/199 [00:00<00:00, 1717.76it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]\rLoading weights:  49%|████▊     | 97/199 [00:00<00:00, 1731.09it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\rLoading weights:  49%|████▊     | 97/199 [00:00<00:00, 1728.92it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\rLoading weights:  49%|████▉     | 98/199 [00:00<00:00, 1742.63it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]    \rLoading weights:  49%|████▉     | 98/199 [00:00<00:00, 1740.52it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]\rLoading weights:  50%|████▉     | 99/199 [00:00<00:00, 1753.84it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\rLoading weights:  50%|████▉     | 99/199 [00:00<00:00, 1751.70it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\rLoading weights:  50%|█████     | 100/199 [00:00<00:00, 1765.32it/s, Materializing param=encoder.layer.5.output.dense.bias]     \rLoading weights:  50%|█████     | 100/199 [00:00<00:00, 1763.23it/s, Materializing param=encoder.layer.5.output.dense.bias]\rLoading weights:  51%|█████     | 101/199 [00:00<00:00, 1776.31it/s, Materializing param=encoder.layer.5.output.dense.weight]\rLoading weights:  51%|█████     | 101/199 [00:00<00:00, 1774.17it/s, Materializing param=encoder.layer.5.output.dense.weight]\rLoading weights:  51%|█████▏    | 102/199 [00:00<00:00, 1787.63it/s, Materializing param=encoder.layer.6.attention.output.LayerNorm.bias]\rLoading weights:  51%|█████▏    | 102/199 [00:00<00:00, 1785.44it/s, Materializing param=encoder.layer.6.attention.output.LayerNorm.bias]\rLoading weights:  52%|█████▏    | 103/199 [00:00<00:00, 1798.37it/s, Materializing param=encoder.layer.6.attention.output.LayerNorm.weight]\rLoading weights:  52%|█████▏    | 103/199 [00:00<00:00, 1796.16it/s, Materializing param=encoder.layer.6.attention.output.LayerNorm.weight]\rLoading weights:  52%|█████▏    | 104/199 [00:00<00:00, 1809.36it/s, Materializing param=encoder.layer.6.attention.output.dense.bias]      \rLoading weights:  52%|█████▏    | 104/199 [00:00<00:00, 1807.24it/s, Materializing param=encoder.layer.6.attention.output.dense.bias]\rLoading weights:  53%|█████▎    | 105/199 [00:00<00:00, 1819.86it/s, Materializing param=encoder.layer.6.attention.output.dense.weight]\rLoading weights:  53%|█████▎    | 105/199 [00:00<00:00, 1817.64it/s, Materializing param=encoder.layer.6.attention.output.dense.weight]\rLoading weights:  53%|█████▎    | 106/199 [00:00<00:00, 1830.74it/s, Materializing param=encoder.layer.6.attention.self.key.bias]      \rLoading weights:  53%|█████▎    | 106/199 [00:00<00:00, 1828.58it/s, Materializing param=encoder.layer.6.attention.self.key.bias]\rLoading weights:  54%|█████▍    | 107/199 [00:00<00:00, 1841.12it/s, Materializing param=encoder.layer.6.attention.self.key.weight]\rLoading weights:  54%|█████▍    | 107/199 [00:00<00:00, 1838.89it/s, Materializing param=encoder.layer.6.attention.self.key.weight]\rLoading weights:  54%|█████▍    | 108/199 [00:00<00:00, 1851.80it/s, Materializing param=encoder.layer.6.attention.self.query.bias]\rLoading weights:  54%|█████▍    | 108/199 [00:00<00:00, 1849.65it/s, Materializing param=encoder.layer.6.attention.self.query.bias]\rLoading weights:  55%|█████▍    | 109/199 [00:00<00:00, 1862.05it/s, Materializing param=encoder.layer.6.attention.self.query.weight]\rLoading weights:  55%|█████▍    | 109/199 [00:00<00:00, 1859.82it/s, Materializing param=encoder.layer.6.attention.self.query.weight]\rLoading weights:  55%|█████▌    | 110/199 [00:00<00:00, 1872.60it/s, Materializing param=encoder.layer.6.attention.self.value.bias]  \rLoading weights:  55%|█████▌    | 110/199 [00:00<00:00, 1870.45it/s, Materializing param=encoder.layer.6.attention.self.value.bias]\rLoading weights:  56%|█████▌    | 111/199 [00:00<00:00, 1882.70it/s, Materializing param=encoder.layer.6.attention.self.value.weight]\rLoading weights:  56%|█████▌    | 111/199 [00:00<00:00, 1880.50it/s, Materializing param=encoder.layer.6.attention.self.value.weight]\rLoading weights:  56%|█████▋    | 112/199 [00:00<00:00, 1893.14it/s, Materializing param=encoder.layer.6.intermediate.dense.bias]    \rLoading weights:  56%|█████▋    | 112/199 [00:00<00:00, 1889.96it/s, Materializing param=encoder.layer.6.intermediate.dense.bias]\rLoading weights:  57%|█████▋    | 113/199 [00:00<00:00, 1902.12it/s, Materializing param=encoder.layer.6.intermediate.dense.weight]\rLoading weights:  57%|█████▋    | 113/199 [00:00<00:00, 1899.88it/s, Materializing param=encoder.layer.6.intermediate.dense.weight]\rLoading weights:  57%|█████▋    | 114/199 [00:00<00:00, 1911.92it/s, Materializing param=encoder.layer.6.output.LayerNorm.bias]    \rLoading weights:  57%|█████▋    | 114/199 [00:00<00:00, 1909.70it/s, Materializing param=encoder.layer.6.output.LayerNorm.bias]\rLoading weights:  58%|█████▊    | 115/199 [00:00<00:00, 1922.60it/s, Materializing param=encoder.layer.6.output.LayerNorm.weight]\rLoading weights:  58%|█████▊    | 115/199 [00:00<00:00, 1920.95it/s, Materializing param=encoder.layer.6.output.LayerNorm.weight]\rLoading weights:  58%|█████▊    | 116/199 [00:00<00:00, 1934.37it/s, Materializing param=encoder.layer.6.output.dense.bias]      \rLoading weights:  58%|█████▊    | 116/199 [00:00<00:00, 1932.76it/s, Materializing param=encoder.layer.6.output.dense.bias]\rLoading weights:  59%|█████▉    | 117/199 [00:00<00:00, 1946.06it/s, Materializing param=encoder.layer.6.output.dense.weight]\rLoading weights:  59%|█████▉    | 117/199 [00:00<00:00, 1944.45it/s, Materializing param=encoder.layer.6.output.dense.weight]\rLoading weights:  59%|█████▉    | 118/199 [00:00<00:00, 1957.68it/s, Materializing param=encoder.layer.7.attention.output.LayerNorm.bias]\rLoading weights:  59%|█████▉    | 118/199 [00:00<00:00, 1956.00it/s, Materializing param=encoder.layer.7.attention.output.LayerNorm.bias]\rLoading weights:  60%|█████▉    | 119/199 [00:00<00:00, 1969.04it/s, Materializing param=encoder.layer.7.attention.output.LayerNorm.weight]\rLoading weights:  60%|█████▉    | 119/199 [00:00<00:00, 1967.37it/s, Materializing param=encoder.layer.7.attention.output.LayerNorm.weight]\rLoading weights:  60%|██████    | 120/199 [00:00<00:00, 1980.41it/s, Materializing param=encoder.layer.7.attention.output.dense.bias]      \rLoading weights:  60%|██████    | 120/199 [00:00<00:00, 1978.76it/s, Materializing param=encoder.layer.7.attention.output.dense.bias]\rLoading weights:  61%|██████    | 121/199 [00:00<00:00, 1991.71it/s, Materializing param=encoder.layer.7.attention.output.dense.weight]\rLoading weights:  61%|██████    | 121/199 [00:00<00:00, 1990.07it/s, Materializing param=encoder.layer.7.attention.output.dense.weight]\rLoading weights:  61%|██████▏   | 122/199 [00:00<00:00, 2003.02it/s, Materializing param=encoder.layer.7.attention.self.key.bias]      \rLoading weights:  61%|██████▏   | 122/199 [00:00<00:00, 2001.36it/s, Materializing param=encoder.layer.7.attention.self.key.bias]\rLoading weights:  62%|██████▏   | 123/199 [00:00<00:00, 2014.21it/s, Materializing param=encoder.layer.7.attention.self.key.weight]\rLoading weights:  62%|██████▏   | 123/199 [00:00<00:00, 2012.52it/s, Materializing param=encoder.layer.7.attention.self.key.weight]\rLoading weights:  62%|██████▏   | 124/199 [00:00<00:00, 2025.39it/s, Materializing param=encoder.layer.7.attention.self.query.bias]\rLoading weights:  62%|██████▏   | 124/199 [00:00<00:00, 2023.60it/s, Materializing param=encoder.layer.7.attention.self.query.bias]\rLoading weights:  63%|██████▎   | 125/199 [00:00<00:00, 2036.39it/s, Materializing param=encoder.layer.7.attention.self.query.weight]\rLoading weights:  63%|██████▎   | 125/199 [00:00<00:00, 2034.73it/s, Materializing param=encoder.layer.7.attention.self.query.weight]\rLoading weights:  63%|██████▎   | 126/199 [00:00<00:00, 2047.51it/s, Materializing param=encoder.layer.7.attention.self.value.bias]  \rLoading weights:  63%|██████▎   | 126/199 [00:00<00:00, 2045.82it/s, Materializing param=encoder.layer.7.attention.self.value.bias]\rLoading weights:  64%|██████▍   | 127/199 [00:00<00:00, 2058.53it/s, Materializing param=encoder.layer.7.attention.self.value.weight]\rLoading weights:  64%|██████▍   | 127/199 [00:00<00:00, 2056.85it/s, Materializing param=encoder.layer.7.attention.self.value.weight]\rLoading weights:  64%|██████▍   | 128/199 [00:00<00:00, 2069.52it/s, Materializing param=encoder.layer.7.intermediate.dense.bias]    \rLoading weights:  64%|██████▍   | 128/199 [00:00<00:00, 2067.81it/s, Materializing param=encoder.layer.7.intermediate.dense.bias]\rLoading weights:  65%|██████▍   | 129/199 [00:00<00:00, 2080.37it/s, Materializing param=encoder.layer.7.intermediate.dense.weight]\rLoading weights:  65%|██████▍   | 129/199 [00:00<00:00, 2078.68it/s, Materializing param=encoder.layer.7.intermediate.dense.weight]\rLoading weights:  65%|██████▌   | 130/199 [00:00<00:00, 2091.34it/s, Materializing param=encoder.layer.7.output.LayerNorm.bias]    \rLoading weights:  65%|██████▌   | 130/199 [00:00<00:00, 2089.66it/s, Materializing param=encoder.layer.7.output.LayerNorm.bias]\rLoading weights:  66%|██████▌   | 131/199 [00:00<00:00, 2102.17it/s, Materializing param=encoder.layer.7.output.LayerNorm.weight]\rLoading weights:  66%|██████▌   | 131/199 [00:00<00:00, 2100.45it/s, Materializing param=encoder.layer.7.output.LayerNorm.weight]\rLoading weights:  66%|██████▋   | 132/199 [00:00<00:00, 2113.06it/s, Materializing param=encoder.layer.7.output.dense.bias]      \rLoading weights:  66%|██████▋   | 132/199 [00:00<00:00, 2111.22it/s, Materializing param=encoder.layer.7.output.dense.bias]\rLoading weights:  67%|██████▋   | 133/199 [00:00<00:00, 2123.75it/s, Materializing param=encoder.layer.7.output.dense.weight]\rLoading weights:  67%|██████▋   | 133/199 [00:00<00:00, 2122.06it/s, Materializing param=encoder.layer.7.output.dense.weight]\rLoading weights:  67%|██████▋   | 134/199 [00:00<00:00, 2134.83it/s, Materializing param=encoder.layer.8.attention.output.LayerNorm.bias]\rLoading weights:  67%|██████▋   | 134/199 [00:00<00:00, 2133.14it/s, Materializing param=encoder.layer.8.attention.output.LayerNorm.bias]\rLoading weights:  68%|██████▊   | 135/199 [00:00<00:00, 2145.59it/s, Materializing param=encoder.layer.8.attention.output.LayerNorm.weight]\rLoading weights:  68%|██████▊   | 135/199 [00:00<00:00, 2143.85it/s, Materializing param=encoder.layer.8.attention.output.LayerNorm.weight]\rLoading weights:  68%|██████▊   | 136/199 [00:00<00:00, 2156.41it/s, Materializing param=encoder.layer.8.attention.output.dense.bias]      \rLoading weights:  68%|██████▊   | 136/199 [00:00<00:00, 2154.72it/s, Materializing param=encoder.layer.8.attention.output.dense.bias]\rLoading weights:  69%|██████▉   | 137/199 [00:00<00:00, 2166.94it/s, Materializing param=encoder.layer.8.attention.output.dense.weight]\rLoading weights:  69%|██████▉   | 137/199 [00:00<00:00, 2165.20it/s, Materializing param=encoder.layer.8.attention.output.dense.weight]\rLoading weights:  69%|██████▉   | 138/199 [00:00<00:00, 2177.56it/s, Materializing param=encoder.layer.8.attention.self.key.bias]      \rLoading weights:  69%|██████▉   | 138/199 [00:00<00:00, 2175.85it/s, Materializing param=encoder.layer.8.attention.self.key.bias]\rLoading weights:  70%|██████▉   | 139/199 [00:00<00:00, 2188.30it/s, Materializing param=encoder.layer.8.attention.self.key.weight]\rLoading weights:  70%|██████▉   | 139/199 [00:00<00:00, 2186.62it/s, Materializing param=encoder.layer.8.attention.self.key.weight]\rLoading weights:  70%|███████   | 140/199 [00:00<00:00, 2198.95it/s, Materializing param=encoder.layer.8.attention.self.query.bias]\rLoading weights:  70%|███████   | 140/199 [00:00<00:00, 2197.20it/s, Materializing param=encoder.layer.8.attention.self.query.bias]\rLoading weights:  71%|███████   | 141/199 [00:00<00:00, 2209.58it/s, Materializing param=encoder.layer.8.attention.self.query.weight]\rLoading weights:  71%|███████   | 141/199 [00:00<00:00, 2207.90it/s, Materializing param=encoder.layer.8.attention.self.query.weight]\rLoading weights:  71%|███████▏  | 142/199 [00:00<00:00, 2220.18it/s, Materializing param=encoder.layer.8.attention.self.value.bias]  \rLoading weights:  71%|███████▏  | 142/199 [00:00<00:00, 2218.41it/s, Materializing param=encoder.layer.8.attention.self.value.bias]\rLoading weights:  72%|███████▏  | 143/199 [00:00<00:00, 2230.62it/s, Materializing param=encoder.layer.8.attention.self.value.weight]\rLoading weights:  72%|███████▏  | 143/199 [00:00<00:00, 2228.90it/s, Materializing param=encoder.layer.8.attention.self.value.weight]\rLoading weights:  72%|███████▏  | 144/199 [00:00<00:00, 2240.85it/s, Materializing param=encoder.layer.8.intermediate.dense.bias]    \rLoading weights:  72%|███████▏  | 144/199 [00:00<00:00, 2239.08it/s, Materializing param=encoder.layer.8.intermediate.dense.bias]\rLoading weights:  73%|███████▎  | 145/199 [00:00<00:00, 2251.03it/s, Materializing param=encoder.layer.8.intermediate.dense.weight]\rLoading weights:  73%|███████▎  | 145/199 [00:00<00:00, 2249.18it/s, Materializing param=encoder.layer.8.intermediate.dense.weight]\rLoading weights:  73%|███████▎  | 146/199 [00:00<00:00, 2260.96it/s, Materializing param=encoder.layer.8.output.LayerNorm.bias]    \rLoading weights:  73%|███████▎  | 146/199 [00:00<00:00, 2259.20it/s, Materializing param=encoder.layer.8.output.LayerNorm.bias]\rLoading weights:  74%|███████▍  | 147/199 [00:00<00:00, 2271.27it/s, Materializing param=encoder.layer.8.output.LayerNorm.weight]\rLoading weights:  74%|███████▍  | 147/199 [00:00<00:00, 2269.54it/s, Materializing param=encoder.layer.8.output.LayerNorm.weight]\rLoading weights:  74%|███████▍  | 148/199 [00:00<00:00, 2281.35it/s, Materializing param=encoder.layer.8.output.dense.bias]      \rLoading weights:  74%|███████▍  | 148/199 [00:00<00:00, 2279.57it/s, Materializing param=encoder.layer.8.output.dense.bias]\rLoading weights:  75%|███████▍  | 149/199 [00:00<00:00, 2291.62it/s, Materializing param=encoder.layer.8.output.dense.weight]\rLoading weights:  75%|███████▍  | 149/199 [00:00<00:00, 2289.92it/s, Materializing param=encoder.layer.8.output.dense.weight]\rLoading weights:  75%|███████▌  | 150/199 [00:00<00:00, 2301.64it/s, Materializing param=encoder.layer.9.attention.output.LayerNorm.bias]\rLoading weights:  75%|███████▌  | 150/199 [00:00<00:00, 2299.85it/s, Materializing param=encoder.layer.9.attention.output.LayerNorm.bias]\rLoading weights:  76%|███████▌  | 151/199 [00:00<00:00, 2311.66it/s, Materializing param=encoder.layer.9.attention.output.LayerNorm.weight]\rLoading weights:  76%|███████▌  | 151/199 [00:00<00:00, 2309.89it/s, Materializing param=encoder.layer.9.attention.output.LayerNorm.weight]\rLoading weights:  76%|███████▋  | 152/199 [00:00<00:00, 2321.42it/s, Materializing param=encoder.layer.9.attention.output.dense.bias]      \rLoading weights:  76%|███████▋  | 152/199 [00:00<00:00, 2319.64it/s, Materializing param=encoder.layer.9.attention.output.dense.bias]\rLoading weights:  77%|███████▋  | 153/199 [00:00<00:00, 2331.42it/s, Materializing param=encoder.layer.9.attention.output.dense.weight]\rLoading weights:  77%|███████▋  | 153/199 [00:00<00:00, 2329.66it/s, Materializing param=encoder.layer.9.attention.output.dense.weight]\rLoading weights:  77%|███████▋  | 154/199 [00:00<00:00, 2341.11it/s, Materializing param=encoder.layer.9.attention.self.key.bias]      \rLoading weights:  77%|███████▋  | 154/199 [00:00<00:00, 2339.32it/s, Materializing param=encoder.layer.9.attention.self.key.bias]\rLoading weights:  78%|███████▊  | 155/199 [00:00<00:00, 2351.01it/s, Materializing param=encoder.layer.9.attention.self.key.weight]\rLoading weights:  78%|███████▊  | 155/199 [00:00<00:00, 2349.22it/s, Materializing param=encoder.layer.9.attention.self.key.weight]\rLoading weights:  78%|███████▊  | 156/199 [00:00<00:00, 2360.60it/s, Materializing param=encoder.layer.9.attention.self.query.bias]\rLoading weights:  78%|███████▊  | 156/199 [00:00<00:00, 2358.85it/s, Materializing param=encoder.layer.9.attention.self.query.bias]\rLoading weights:  79%|███████▉  | 157/199 [00:00<00:00, 2370.40it/s, Materializing param=encoder.layer.9.attention.self.query.weight]\rLoading weights:  79%|███████▉  | 157/199 [00:00<00:00, 2368.64it/s, Materializing param=encoder.layer.9.attention.self.query.weight]\rLoading weights:  79%|███████▉  | 158/199 [00:00<00:00, 2380.13it/s, Materializing param=encoder.layer.9.attention.self.value.bias]  \rLoading weights:  79%|███████▉  | 158/199 [00:00<00:00, 2378.35it/s, Materializing param=encoder.layer.9.attention.self.value.bias]\rLoading weights:  80%|███████▉  | 159/199 [00:00<00:00, 2389.53it/s, Materializing param=encoder.layer.9.attention.self.value.weight]\rLoading weights:  80%|███████▉  | 159/199 [00:00<00:00, 2387.67it/s, Materializing param=encoder.layer.9.attention.self.value.weight]\rLoading weights:  80%|████████  | 160/199 [00:00<00:00, 2399.19it/s, Materializing param=encoder.layer.9.intermediate.dense.bias]    \rLoading weights:  80%|████████  | 160/199 [00:00<00:00, 2397.41it/s, Materializing param=encoder.layer.9.intermediate.dense.bias]\rLoading weights:  81%|████████  | 161/199 [00:00<00:00, 2408.66it/s, Materializing param=encoder.layer.9.intermediate.dense.weight]\rLoading weights:  81%|████████  | 161/199 [00:00<00:00, 2406.84it/s, Materializing param=encoder.layer.9.intermediate.dense.weight]\rLoading weights:  81%|████████▏ | 162/199 [00:00<00:00, 2418.34it/s, Materializing param=encoder.layer.9.output.LayerNorm.bias]    \rLoading weights:  81%|████████▏ | 162/199 [00:00<00:00, 2416.58it/s, Materializing param=encoder.layer.9.output.LayerNorm.bias]\rLoading weights:  82%|████████▏ | 163/199 [00:00<00:00, 2427.70it/s, Materializing param=encoder.layer.9.output.LayerNorm.weight]\rLoading weights:  82%|████████▏ | 163/199 [00:00<00:00, 2425.50it/s, Materializing param=encoder.layer.9.output.LayerNorm.weight]\rLoading weights:  82%|████████▏ | 164/199 [00:00<00:00, 2436.67it/s, Materializing param=encoder.layer.9.output.dense.bias]      \rLoading weights:  82%|████████▏ | 164/199 [00:00<00:00, 2434.90it/s, Materializing param=encoder.layer.9.output.dense.bias]\rLoading weights:  83%|████████▎ | 165/199 [00:00<00:00, 2446.28it/s, Materializing param=encoder.layer.9.output.dense.weight]\rLoading weights:  83%|████████▎ | 165/199 [00:00<00:00, 2444.54it/s, Materializing param=encoder.layer.9.output.dense.weight]\rLoading weights:  83%|████████▎ | 166/199 [00:00<00:00, 2455.63it/s, Materializing param=encoder.layer.10.attention.output.LayerNorm.bias]\rLoading weights:  83%|████████▎ | 166/199 [00:00<00:00, 2453.76it/s, Materializing param=encoder.layer.10.attention.output.LayerNorm.bias]\rLoading weights:  84%|████████▍ | 167/199 [00:00<00:00, 2464.98it/s, Materializing param=encoder.layer.10.attention.output.LayerNorm.weight]\rLoading weights:  84%|████████▍ | 167/199 [00:00<00:00, 2463.14it/s, Materializing param=encoder.layer.10.attention.output.LayerNorm.weight]\rLoading weights:  84%|████████▍ | 168/199 [00:00<00:00, 2473.95it/s, Materializing param=encoder.layer.10.attention.output.dense.bias]      \rLoading weights:  84%|████████▍ | 168/199 [00:00<00:00, 2472.06it/s, Materializing param=encoder.layer.10.attention.output.dense.bias]\rLoading weights:  85%|████████▍ | 169/199 [00:00<00:00, 2483.15it/s, Materializing param=encoder.layer.10.attention.output.dense.weight]\rLoading weights:  85%|████████▍ | 169/199 [00:00<00:00, 2481.32it/s, Materializing param=encoder.layer.10.attention.output.dense.weight]\rLoading weights:  85%|████████▌ | 170/199 [00:00<00:00, 2492.00it/s, Materializing param=encoder.layer.10.attention.self.key.bias]      \rLoading weights:  85%|████████▌ | 170/199 [00:00<00:00, 2490.11it/s, Materializing param=encoder.layer.10.attention.self.key.bias]\rLoading weights:  86%|████████▌ | 171/199 [00:00<00:00, 2500.81it/s, Materializing param=encoder.layer.10.attention.self.key.weight]\rLoading weights:  86%|████████▌ | 171/199 [00:00<00:00, 2498.92it/s, Materializing param=encoder.layer.10.attention.self.key.weight]\rLoading weights:  86%|████████▋ | 172/199 [00:00<00:00, 2509.76it/s, Materializing param=encoder.layer.10.attention.self.query.bias]\rLoading weights:  86%|████████▋ | 172/199 [00:00<00:00, 2507.87it/s, Materializing param=encoder.layer.10.attention.self.query.bias]\rLoading weights:  87%|████████▋ | 173/199 [00:00<00:00, 2518.58it/s, Materializing param=encoder.layer.10.attention.self.query.weight]\rLoading weights:  87%|████████▋ | 173/199 [00:00<00:00, 2516.69it/s, Materializing param=encoder.layer.10.attention.self.query.weight]\rLoading weights:  87%|████████▋ | 174/199 [00:00<00:00, 2527.61it/s, Materializing param=encoder.layer.10.attention.self.value.bias]  \rLoading weights:  87%|████████▋ | 174/199 [00:00<00:00, 2525.81it/s, Materializing param=encoder.layer.10.attention.self.value.bias]\rLoading weights:  88%|████████▊ | 175/199 [00:00<00:00, 2536.40it/s, Materializing param=encoder.layer.10.attention.self.value.weight]\rLoading weights:  88%|████████▊ | 175/199 [00:00<00:00, 2534.50it/s, Materializing param=encoder.layer.10.attention.self.value.weight]\rLoading weights:  88%|████████▊ | 176/199 [00:00<00:00, 2545.33it/s, Materializing param=encoder.layer.10.intermediate.dense.bias]    \rLoading weights:  88%|████████▊ | 176/199 [00:00<00:00, 2543.51it/s, Materializing param=encoder.layer.10.intermediate.dense.bias]\rLoading weights:  89%|████████▉ | 177/199 [00:00<00:00, 2554.10it/s, Materializing param=encoder.layer.10.intermediate.dense.weight]\rLoading weights:  89%|████████▉ | 177/199 [00:00<00:00, 2552.22it/s, Materializing param=encoder.layer.10.intermediate.dense.weight]\rLoading weights:  89%|████████▉ | 178/199 [00:00<00:00, 2563.10it/s, Materializing param=encoder.layer.10.output.LayerNorm.bias]    \rLoading weights:  89%|████████▉ | 178/199 [00:00<00:00, 2561.28it/s, Materializing param=encoder.layer.10.output.LayerNorm.bias]\rLoading weights:  90%|████████▉ | 179/199 [00:00<00:00, 2571.82it/s, Materializing param=encoder.layer.10.output.LayerNorm.weight]\rLoading weights:  90%|████████▉ | 179/199 [00:00<00:00, 2569.96it/s, Materializing param=encoder.layer.10.output.LayerNorm.weight]\rLoading weights:  90%|█████████ | 180/199 [00:00<00:00, 2580.81it/s, Materializing param=encoder.layer.10.output.dense.bias]      \rLoading weights:  90%|█████████ | 180/199 [00:00<00:00, 2578.94it/s, Materializing param=encoder.layer.10.output.dense.bias]\rLoading weights:  91%|█████████ | 181/199 [00:00<00:00, 2589.16it/s, Materializing param=encoder.layer.10.output.dense.weight]\rLoading weights:  91%|█████████ | 181/199 [00:00<00:00, 2587.19it/s, Materializing param=encoder.layer.10.output.dense.weight]\rLoading weights:  91%|█████████▏| 182/199 [00:00<00:00, 2597.76it/s, Materializing param=encoder.layer.11.attention.output.LayerNorm.bias]\rLoading weights:  91%|█████████▏| 182/199 [00:00<00:00, 2595.95it/s, Materializing param=encoder.layer.11.attention.output.LayerNorm.bias]\rLoading weights:  92%|█████████▏| 183/199 [00:00<00:00, 2606.25it/s, Materializing param=encoder.layer.11.attention.output.LayerNorm.weight]\rLoading weights:  92%|█████████▏| 183/199 [00:00<00:00, 2604.41it/s, Materializing param=encoder.layer.11.attention.output.LayerNorm.weight]\rLoading weights:  92%|█████████▏| 184/199 [00:00<00:00, 2614.89it/s, Materializing param=encoder.layer.11.attention.output.dense.bias]      \rLoading weights:  92%|█████████▏| 184/199 [00:00<00:00, 2613.05it/s, Materializing param=encoder.layer.11.attention.output.dense.bias]\rLoading weights:  93%|█████████▎| 185/199 [00:00<00:00, 2623.61it/s, Materializing param=encoder.layer.11.attention.output.dense.weight]\rLoading weights:  93%|█████████▎| 185/199 [00:00<00:00, 2621.84it/s, Materializing param=encoder.layer.11.attention.output.dense.weight]\rLoading weights:  93%|█████████▎| 186/199 [00:00<00:00, 2632.38it/s, Materializing param=encoder.layer.11.attention.self.key.bias]      \rLoading weights:  93%|█████████▎| 186/199 [00:00<00:00, 2630.57it/s, Materializing param=encoder.layer.11.attention.self.key.bias]\rLoading weights:  94%|█████████▍| 187/199 [00:00<00:00, 2641.10it/s, Materializing param=encoder.layer.11.attention.self.key.weight]\rLoading weights:  94%|█████████▍| 187/199 [00:00<00:00, 2639.29it/s, Materializing param=encoder.layer.11.attention.self.key.weight]\rLoading weights:  94%|█████████▍| 188/199 [00:00<00:00, 2649.52it/s, Materializing param=encoder.layer.11.attention.self.query.bias]\rLoading weights:  94%|█████████▍| 188/199 [00:00<00:00, 2647.69it/s, Materializing param=encoder.layer.11.attention.self.query.bias]\rLoading weights:  95%|█████████▍| 189/199 [00:00<00:00, 2658.13it/s, Materializing param=encoder.layer.11.attention.self.query.weight]\rLoading weights:  95%|█████████▍| 189/199 [00:00<00:00, 2656.33it/s, Materializing param=encoder.layer.11.attention.self.query.weight]\rLoading weights:  95%|█████████▌| 190/199 [00:00<00:00, 2665.79it/s, Materializing param=encoder.layer.11.attention.self.value.bias]  \rLoading weights:  95%|█████████▌| 190/199 [00:00<00:00, 2663.89it/s, Materializing param=encoder.layer.11.attention.self.value.bias]\rLoading weights:  96%|█████████▌| 191/199 [00:00<00:00, 2674.31it/s, Materializing param=encoder.layer.11.attention.self.value.weight]\rLoading weights:  96%|█████████▌| 191/199 [00:00<00:00, 2672.53it/s, Materializing param=encoder.layer.11.attention.self.value.weight]\rLoading weights:  96%|█████████▋| 192/199 [00:00<00:00, 2682.93it/s, Materializing param=encoder.layer.11.intermediate.dense.bias]    \rLoading weights:  96%|█████████▋| 192/199 [00:00<00:00, 2681.13it/s, Materializing param=encoder.layer.11.intermediate.dense.bias]\rLoading weights:  97%|█████████▋| 193/199 [00:00<00:00, 2691.40it/s, Materializing param=encoder.layer.11.intermediate.dense.weight]\rLoading weights:  97%|█████████▋| 193/199 [00:00<00:00, 2689.49it/s, Materializing param=encoder.layer.11.intermediate.dense.weight]\rLoading weights:  97%|█████████▋| 194/199 [00:00<00:00, 2699.70it/s, Materializing param=encoder.layer.11.output.LayerNorm.bias]    \rLoading weights:  97%|█████████▋| 194/199 [00:00<00:00, 2697.87it/s, Materializing param=encoder.layer.11.output.LayerNorm.bias]\rLoading weights:  98%|█████████▊| 195/199 [00:00<00:00, 2707.83it/s, Materializing param=encoder.layer.11.output.LayerNorm.weight]\rLoading weights:  98%|█████████▊| 195/199 [00:00<00:00, 2705.94it/s, Materializing param=encoder.layer.11.output.LayerNorm.weight]\rLoading weights:  98%|█████████▊| 196/199 [00:00<00:00, 2716.20it/s, Materializing param=encoder.layer.11.output.dense.bias]      \rLoading weights:  98%|█████████▊| 196/199 [00:00<00:00, 2714.37it/s, Materializing param=encoder.layer.11.output.dense.bias]\rLoading weights:  99%|█████████▉| 197/199 [00:00<00:00, 2724.02it/s, Materializing param=encoder.layer.11.output.dense.weight]\rLoading weights:  99%|█████████▉| 197/199 [00:00<00:00, 2722.04it/s, Materializing param=encoder.layer.11.output.dense.weight]\rLoading weights:  99%|█████████▉| 198/199 [00:00<00:00, 2731.83it/s, Materializing param=pooler.dense.bias]                   \rLoading weights:  99%|█████████▉| 198/199 [00:00<00:00, 2729.74it/s, Materializing param=pooler.dense.bias]\rLoading weights: 100%|██████████| 199/199 [00:00<00:00, 2740.04it/s, Materializing param=pooler.dense.weight]\rLoading weights: 100%|██████████| 199/199 [00:00<00:00, 2738.26it/s, Materializing param=pooler.dense.weight]\rLoading weights: 100%|██████████| 199/199 [00:00<00:00, 2733.67it/s, Materializing param=pooler.dense.weight]\n\u001b[1mXLMRobertaModel LOAD REPORT\u001b[0m from: xlm-roberta-base\nKey                       | Status     |  | \n--------------------------+------------+--+-\nlm_head.dense.bias        | UNEXPECTED |  | \nlm_head.dense.weight      | UNEXPECTED |  | \nlm_head.bias              | UNEXPECTED |  | \nlm_head.layer_norm.weight | UNEXPECTED |  | \nlm_head.layer_norm.bias   | UNEXPECTED |  | \n\n\u001b[3mNotes:\n- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n2026-02-15 19:43:52,081 | INFO | Polysemy lexicon size: 3726\n\rStatic sim:   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim:  20%|█▉        | 398/2000 [00:00<00:00, 3973.91it/s]\rStatic sim:  40%|███▉      | 798/2000 [00:00<00:00, 3989.17it/s]\rStatic sim:  60%|█████▉    | 1197/2000 [00:00<00:00, 3978.10it/s]\rStatic sim:  80%|████████  | 1600/2000 [00:00<00:00, 3996.45it/s]\rStatic sim: 100%|██████████| 2000/2000 [00:00<00:00, 4010.01it/s]\n\rStatic sim (mismatch):   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim (mismatch):  22%|██▏       | 435/2000 [00:00<00:00, 4345.51it/s]\rStatic sim (mismatch):  44%|████▎     | 874/2000 [00:00<00:00, 4367.68it/s]\rStatic sim (mismatch):  66%|██████▌   | 1315/2000 [00:00<00:00, 4384.46it/s]\rStatic sim (mismatch):  88%|████████▊ | 1754/2000 [00:00<00:00, 4384.85it/s]\rStatic sim (mismatch): 100%|██████████| 2000/2000 [00:00<00:00, 4390.79it/s]\n\rStatic sim:   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim:  21%|██        | 413/2000 [00:00<00:00, 4125.64it/s]\rStatic sim:  42%|████▏     | 839/2000 [00:00<00:00, 4199.46it/s]\rStatic sim:  63%|██████▎   | 1259/2000 [00:00<00:00, 4091.83it/s]\rStatic sim:  83%|████████▎ | 1669/2000 [00:00<00:00, 4076.40it/s]\rStatic sim: 100%|██████████| 2000/2000 [00:00<00:00, 4078.30it/s]\n\rStatic sim (mismatch):   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim (mismatch):  21%|██        | 416/2000 [00:00<00:00, 4151.60it/s]\rStatic sim (mismatch):  42%|████▏     | 832/2000 [00:00<00:00, 4134.56it/s]\rStatic sim (mismatch):  62%|██████▏   | 1247/2000 [00:00<00:00, 4137.61it/s]\rStatic sim (mismatch):  83%|████████▎ | 1665/2000 [00:00<00:00, 4153.45it/s]\rStatic sim (mismatch): 100%|██████████| 2000/2000 [00:00<00:00, 4140.64it/s]\n\rStatic sim:   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim:  22%|██▏       | 437/2000 [00:00<00:00, 4360.90it/s]\rStatic sim:  44%|████▎     | 874/2000 [00:00<00:00, 4281.11it/s]\rStatic sim:  65%|██████▌   | 1303/2000 [00:00<00:00, 4259.08it/s]\rStatic sim:  86%|████████▋ | 1729/2000 [00:00<00:00, 4158.88it/s]\rStatic sim: 100%|██████████| 2000/2000 [00:00<00:00, 4195.30it/s]\n\rStatic sim (mismatch):   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim (mismatch):  22%|██▏       | 432/2000 [00:00<00:00, 4311.96it/s]\rStatic sim (mismatch):  43%|████▎     | 864/2000 [00:00<00:00, 4161.96it/s]\rStatic sim (mismatch):  64%|██████▍   | 1281/2000 [00:00<00:00, 4157.00it/s]\rStatic sim (mismatch):  85%|████████▍ | 1697/2000 [00:00<00:00, 4138.36it/s]\rStatic sim (mismatch): 100%|██████████| 2000/2000 [00:00<00:00, 4127.45it/s]\n\rStatic sim:   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim:  21%|██        | 413/2000 [00:00<00:00, 4128.57it/s]\rStatic sim:  42%|████▏     | 844/2000 [00:00<00:00, 4235.15it/s]\rStatic sim:  64%|██████▎   | 1271/2000 [00:00<00:00, 4248.59it/s]\rStatic sim:  85%|████████▍ | 1696/2000 [00:00<00:00, 4208.81it/s]\rStatic sim: 100%|██████████| 2000/2000 [00:00<00:00, 4204.56it/s]\n\rStatic sim (mismatch):   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim (mismatch):  21%|██▏       | 427/2000 [00:00<00:00, 4267.53it/s]\rStatic sim (mismatch):  43%|████▎     | 857/2000 [00:00<00:00, 4280.94it/s]\rStatic sim (mismatch):  65%|██████▌   | 1306/2000 [00:00<00:00, 4372.17it/s]\rStatic sim (mismatch):  88%|████████▊ | 1752/2000 [00:00<00:00, 4406.10it/s]\rStatic sim (mismatch): 100%|██████████| 2000/2000 [00:00<00:00, 4369.66it/s]\n\rContextual batches:   0%|          | 0/16 [00:00<?, ?it/s]\rContextual batches:   6%|▋         | 1/16 [00:00<00:04,  3.20it/s]\rContextual batches:  19%|█▉        | 3/16 [00:00<00:01,  6.84it/s]\rContextual batches:  31%|███▏      | 5/16 [00:00<00:01,  8.85it/s]\rContextual batches:  44%|████▍     | 7/16 [00:00<00:00, 11.21it/s]\rContextual batches:  56%|█████▋    | 9/16 [00:00<00:00, 12.36it/s]\rContextual batches:  69%|██████▉   | 11/16 [00:01<00:00, 12.94it/s]\rContextual batches:  81%|████████▏ | 13/16 [00:01<00:00, 13.71it/s]\rContextual batches:  94%|█████████▍| 15/16 [00:01<00:00, 14.43it/s]\rContextual batches: 100%|██████████| 16/16 [00:01<00:00, 11.81it/s]\n\rContextual batches:   0%|          | 0/16 [00:00<?, ?it/s]\rContextual batches:   6%|▋         | 1/16 [00:00<00:01,  7.74it/s]\rContextual batches:  12%|█▎        | 2/16 [00:00<00:01,  8.88it/s]\rContextual batches:  19%|█▉        | 3/16 [00:00<00:01,  9.26it/s]\rContextual batches:  31%|███▏      | 5/16 [00:00<00:01,  9.56it/s]\rContextual batches:  44%|████▍     | 7/16 [00:00<00:00,  9.56it/s]\rContextual batches:  56%|█████▋    | 9/16 [00:00<00:00, 10.74it/s]\rContextual batches:  69%|██████▉   | 11/16 [00:01<00:00, 10.36it/s]\rContextual batches:  81%|████████▏ | 13/16 [00:01<00:00, 10.65it/s]\rContextual batches:  94%|█████████▍| 15/16 [00:01<00:00, 10.58it/s]\rContextual batches: 100%|██████████| 16/16 [00:01<00:00, 10.52it/s]\n\rContextual batches:   0%|          | 0/16 [00:00<?, ?it/s]\rContextual batches:  12%|█▎        | 2/16 [00:00<00:01, 12.27it/s]\rContextual batches:  25%|██▌       | 4/16 [00:00<00:00, 12.45it/s]\rContextual batches:  38%|███▊      | 6/16 [00:00<00:00, 12.72it/s]\rContextual batches:  50%|█████     | 8/16 [00:00<00:00, 13.52it/s]\rContextual batches:  62%|██████▎   | 10/16 [00:00<00:00, 13.98it/s]\rContextual batches:  75%|███████▌  | 12/16 [00:00<00:00, 14.34it/s]\rContextual batches:  88%|████████▊ | 14/16 [00:01<00:00, 14.40it/s]\rContextual batches: 100%|██████████| 16/16 [00:01<00:00, 14.50it/s]\n\rContextual batches:   0%|          | 0/16 [00:00<?, ?it/s]\rContextual batches:  12%|█▎        | 2/16 [00:00<00:01, 10.07it/s]\rContextual batches:  25%|██▌       | 4/16 [00:00<00:01, 10.72it/s]\rContextual batches:  38%|███▊      | 6/16 [00:00<00:00, 11.10it/s]\rContextual batches:  50%|█████     | 8/16 [00:00<00:00, 10.47it/s]\rContextual batches:  62%|██████▎   | 10/16 [00:00<00:00, 10.44it/s]\rContextual batches:  75%|███████▌  | 12/16 [00:01<00:00, 10.84it/s]\rContextual batches:  88%|████████▊ | 14/16 [00:01<00:00, 11.55it/s]\rContextual batches: 100%|██████████| 16/16 [00:01<00:00, 12.31it/s]\rContextual batches: 100%|██████████| 16/16 [00:01<00:00, 11.35it/s]\n\rContextual batches:   0%|          | 0/16 [00:00<?, ?it/s]\rContextual batches:  12%|█▎        | 2/16 [00:00<00:01, 12.55it/s]\rContextual batches:  25%|██▌       | 4/16 [00:00<00:00, 12.47it/s]\rContextual batches:  38%|███▊      | 6/16 [00:00<00:00, 12.56it/s]\rContextual batches:  50%|█████     | 8/16 [00:00<00:00, 12.83it/s]\rContextual batches:  62%|██████▎   | 10/16 [00:00<00:00, 13.38it/s]\rContextual batches:  75%|███████▌  | 12/16 [00:00<00:00, 14.24it/s]\rContextual batches:  88%|████████▊ | 14/16 [00:01<00:00, 14.56it/s]\rContextual batches: 100%|██████████| 16/16 [00:01<00:00, 15.69it/s]\rContextual batches: 100%|██████████| 16/16 [00:01<00:00, 14.19it/s]\n\rContextual batches:   0%|          | 0/16 [00:00<?, ?it/s]\rContextual batches:  12%|█▎        | 2/16 [00:00<00:00, 16.33it/s]\rContextual batches:  25%|██▌       | 4/16 [00:00<00:00, 17.25it/s]\rContextual batches:  38%|███▊      | 6/16 [00:00<00:00, 16.82it/s]\rContextual batches:  50%|█████     | 8/16 [00:00<00:00, 16.70it/s]\rContextual batches:  62%|██████▎   | 10/16 [00:00<00:00, 16.49it/s]\rContextual batches:  75%|███████▌  | 12/16 [00:00<00:00, 16.00it/s]\rContextual batches:  88%|████████▊ | 14/16 [00:00<00:00, 16.51it/s]\rContextual batches: 100%|██████████| 16/16 [00:00<00:00, 17.47it/s]\rContextual batches: 100%|██████████| 16/16 [00:00<00:00, 16.89it/s]\n\rContextual batches:   0%|          | 0/16 [00:00<?, ?it/s]\rContextual batches:  12%|█▎        | 2/16 [00:00<00:01, 12.69it/s]\rContextual batches:  25%|██▌       | 4/16 [00:00<00:00, 12.73it/s]\rContextual batches:  38%|███▊      | 6/16 [00:00<00:00, 13.18it/s]\rContextual batches:  50%|█████     | 8/16 [00:00<00:00, 13.89it/s]\rContextual batches:  62%|██████▎   | 10/16 [00:00<00:00, 14.19it/s]\rContextual batches:  75%|███████▌  | 12/16 [00:00<00:00, 14.85it/s]\rContextual batches:  88%|████████▊ | 14/16 [00:00<00:00, 14.92it/s]\rContextual batches: 100%|██████████| 16/16 [00:01<00:00, 15.68it/s]\rContextual batches: 100%|██████████| 16/16 [00:01<00:00, 14.59it/s]\n\rContextual batches:   0%|          | 0/16 [00:00<?, ?it/s]\rContextual batches:  12%|█▎        | 2/16 [00:00<00:01,  9.41it/s]\rContextual batches:  25%|██▌       | 4/16 [00:00<00:01, 10.43it/s]\rContextual batches:  38%|███▊      | 6/16 [00:00<00:01,  9.95it/s]\rContextual batches:  50%|█████     | 8/16 [00:00<00:00, 10.19it/s]\rContextual batches:  62%|██████▎   | 10/16 [00:00<00:00, 10.97it/s]\rContextual batches:  75%|███████▌  | 12/16 [00:01<00:00, 11.09it/s]\rContextual batches:  88%|████████▊ | 14/16 [00:01<00:00, 11.41it/s]\rContextual batches: 100%|██████████| 16/16 [00:01<00:00, 11.68it/s]\rContextual batches: 100%|██████████| 16/16 [00:01<00:00, 11.02it/s]\n\rContextual batches:   0%|          | 0/16 [00:00<?, ?it/s]\rContextual batches:  12%|█▎        | 2/16 [00:00<00:00, 14.31it/s]\rContextual batches:  25%|██▌       | 4/16 [00:00<00:00, 14.20it/s]\rContextual batches:  38%|███▊      | 6/16 [00:00<00:00, 14.92it/s]\rContextual batches:  50%|█████     | 8/16 [00:00<00:00, 14.98it/s]\rContextual batches:  62%|██████▎   | 10/16 [00:00<00:00, 15.76it/s]\rContextual batches:  75%|███████▌  | 12/16 [00:00<00:00, 16.20it/s]\rContextual batches:  88%|████████▊ | 14/16 [00:00<00:00, 16.46it/s]\rContextual batches: 100%|██████████| 16/16 [00:00<00:00, 16.32it/s]\n\rContextual batches:   0%|          | 0/16 [00:00<?, ?it/s]\rContextual batches:  12%|█▎        | 2/16 [00:00<00:01, 13.66it/s]\rContextual batches:  25%|██▌       | 4/16 [00:00<00:00, 13.74it/s]\rContextual batches:  38%|███▊      | 6/16 [00:00<00:00, 14.49it/s]\rContextual batches:  50%|█████     | 8/16 [00:00<00:00, 14.90it/s]\rContextual batches:  62%|██████▎   | 10/16 [00:00<00:00, 14.92it/s]\rContextual batches:  75%|███████▌  | 12/16 [00:00<00:00, 15.44it/s]\rContextual batches:  88%|████████▊ | 14/16 [00:00<00:00, 15.28it/s]\rContextual batches: 100%|██████████| 16/16 [00:01<00:00, 16.17it/s]\rContextual batches: 100%|██████████| 16/16 [00:01<00:00, 15.30it/s]\n2026-02-15 19:44:12,399 | INFO | Experiments completed\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_92","type":"reasoning","text":"**Loading and inspecting metrics data**"}}
{"type":"item.started","item":{"id":"item_93","type":"command_execution","command":"/bin/bash -lc \"python - << 'PY'\nimport json\nfrom pprint import pprint\nwith open('results/metrics.json') as f:\n    data=json.load(f)\nprint('model', data['model'])\nprint('device', data['device'])\nprint('batch_size', data['batch_size'])\nprint('dev_threshold', data['dev_threshold'])\nprint('dev_accuracy', data['dev_accuracy'])\nprint('crosslingual_accuracy', data['crosslingual_accuracy'])\nprint('stats keys', data['stats'].keys())\nprint('contextual_ttest', data['stats']['contextual_ttest'])\nprint('contextual_mwu', data['stats']['contextual_mwu'])\nPY\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_93","type":"command_execution","command":"/bin/bash -lc \"python - << 'PY'\nimport json\nfrom pprint import pprint\nwith open('results/metrics.json') as f:\n    data=json.load(f)\nprint('model', data['model'])\nprint('device', data['device'])\nprint('batch_size', data['batch_size'])\nprint('dev_threshold', data['dev_threshold'])\nprint('dev_accuracy', data['dev_accuracy'])\nprint('crosslingual_accuracy', data['crosslingual_accuracy'])\nprint('stats keys', data['stats'].keys())\nprint('contextual_ttest', data['stats']['contextual_ttest'])\nprint('contextual_mwu', data['stats']['contextual_mwu'])\nPY\"","aggregated_output":"model xlm-roberta-base\ndevice cuda\nbatch_size 64\ndev_threshold 0.9750000000000001\ndev_accuracy 0.503\ncrosslingual_accuracy 0.53\nstats keys dict_keys(['static_similarity', 'contextual_similarity', 'polysemy_contextual', 'contextual_ttest', 'contextual_mwu', 'static_polysemy_ttest'])\ncontextual_ttest {'t': 14.56593457925549, 'p': 7.56382243383649e-47}\ncontextual_mwu {'u': 2541088.5, 'p': 1.146819131428751e-49}\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_94","type":"reasoning","text":"**Planning similarity summary**\n\nI'll compute mean similarity scores for true vs false pairs, compare static translation cases against mismatches, and group results by polysemy for a detailed report."}}
{"type":"item.started","item":{"id":"item_95","type":"command_execution","command":"/bin/bash -lc \"python - << 'PY'\nimport pandas as pd, json\nstatic_df = pd.read_csv('results/static_similarity.csv')\ncontext_df = pd.read_csv('results/contextual_similarity.csv')\n\nprint('Static by pair_type:')\nprint(static_df.groupby('pair_type')['cosine'].agg(['count','mean','std']).round(4))\nprint('\\\\nStatic by polysemy:')\nprint(static_df.groupby('polysemy')['cosine'].agg(['count','mean','std']).round(4))\n\nprint('\\\\nContextual by label:')\nprint(context_df.groupby('label')['cosine'].agg(['count','mean','std']).round(4))\nprint('\\\\nContextual by polysemy:')\nprint(context_df.groupby('polysemy')['cosine'].agg(['count','mean','std']).round(4))\n\nprint('\\\\nContextual by lang pair + label:')\nprint(context_df.groupby(['lang_pair','label'])['cosine'].agg(['count','mean']).round(4))\nPY\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_95","type":"command_execution","command":"/bin/bash -lc \"python - << 'PY'\nimport pandas as pd, json\nstatic_df = pd.read_csv('results/static_similarity.csv')\ncontext_df = pd.read_csv('results/contextual_similarity.csv')\n\nprint('Static by pair_type:')\nprint(static_df.groupby('pair_type')['cosine'].agg(['count','mean','std']).round(4))\nprint('\\\\nStatic by polysemy:')\nprint(static_df.groupby('polysemy')['cosine'].agg(['count','mean','std']).round(4))\n\nprint('\\\\nContextual by label:')\nprint(context_df.groupby('label')['cosine'].agg(['count','mean','std']).round(4))\nprint('\\\\nContextual by polysemy:')\nprint(context_df.groupby('polysemy')['cosine'].agg(['count','mean','std']).round(4))\n\nprint('\\\\nContextual by lang pair + label:')\nprint(context_df.groupby(['lang_pair','label'])['cosine'].agg(['count','mean']).round(4))\nPY\"","aggregated_output":"Static by pair_type:\n             count    mean     std\npair_type                         \nmismatch      8000  0.3747  0.0937\ntranslation   8000  0.5131  0.1646\n\nStatic by polysemy:\n            count    mean     std\npolysemy                         \nmonosemous   4338  0.4357  0.1453\npolysemous   2560  0.4318  0.1425\nunknown      9102  0.4512  0.1551\n\nContextual by label:\n       count    mean     std\nlabel                       \nF       2000  0.9822  0.0059\nT       2000  0.9847  0.0051\n\nContextual by polysemy:\nTraceback (most recent call last):\n  File \"<stdin>\", line 13, in <module>\n  File \"/data/haokunliu/idea-explorer/.venv/lib/python3.12/site-packages/pandas/core/frame.py\", line 9210, in groupby\n    return DataFrameGroupBy(\n           ^^^^^^^^^^^^^^^^^\n  File \"/data/haokunliu/idea-explorer/.venv/lib/python3.12/site-packages/pandas/core/groupby/groupby.py\", line 1331, in __init__\n    grouper, exclusions, obj = get_grouper(\n                               ^^^^^^^^^^^^\n  File \"/data/haokunliu/idea-explorer/.venv/lib/python3.12/site-packages/pandas/core/groupby/grouper.py\", line 1043, in get_grouper\n    raise KeyError(gpr)\nKeyError: 'polysemy'\n","exit_code":1,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_96","type":"reasoning","text":"**Planning analysis script and polysemy update**\n\nDiscovered the polysemy counts weren't saved to the contextual similarity CSV, so I’ll update the analysis to compute polysemy during report generation and save updated results. Also noting very high contextual similarity values likely from mean pooling the same model, raising cross-lingual quality questions and a modest accuracy around 0.53. I’ll create an analysis script to generate a reproducible summary JSON with key metrics, tables, and data quality checks, possibly integrating data stats there."}}
{"type":"item.completed","item":{"id":"item_97","type":"reasoning","text":"**Creating data quality script**\n\nI'm implementing a script to compute missing values and counts for the crosslingual dataset and MUSE dictionaries, outputting results to a JSON file for data quality checks."}}
{"type":"item.started","item":{"id":"item_98","type":"command_execution","command":"/bin/bash -lc \"cat > src/data_quality.py << 'PY'\nimport json\nfrom pathlib import Path\nimport pandas as pd\n\n\ndef count_missing(fields):\n    return {k: int(v) for k, v in fields.items()}\n\n\ndef main():\n    out = {}\n\n    # MCL-WiC crosslingual\n    base = Path(\\\"datasets/mcl_wic/data/MCL-WiC/test/crosslingual\\\")\n    gold_base = Path(\\\"datasets/mcl_wic/data_gold\\\")\n    for path in sorted(base.glob(\\\"*.data\\\")):\n        data = json.loads(path.read_text())\n        gold_path = gold_base / path.name.replace(\\\".data\\\", \\\".gold\\\")\n        gold = json.loads(gold_path.read_text()) if gold_path.exists() else []\n        missing_counts = {\n            \\\"lemma\\\": sum(1 for x in data if not x.get(\\\"lemma\\\")),\n            \\\"sentence1\\\": sum(1 for x in data if not x.get(\\\"sentence1\\\")),\n            \\\"sentence2\\\": sum(1 for x in data if not x.get(\\\"sentence2\\\")),\n            \\\"ranges1\\\": sum(1 for x in data if not x.get(\\\"ranges1\\\")),\n            \\\"ranges2\\\": sum(1 for x in data if not x.get(\\\"ranges2\\\")),\n        }\n        out[path.name] = {\n            \\\"num_examples\\\": len(data),\n            \\\"num_gold\\\": len(gold),\n            \\\"missing\\\": count_missing(missing_counts),\n        }\n\n    # MCL-WiC training (for polysemy lexicon)\n    train_data = Path(\\\"datasets/mcl_wic/data/MCL-WiC/training/training.en-en.data\\\")\n    train_gold = Path(\\\"datasets/mcl_wic/data/MCL-WiC/training/training.en-en.gold\\\")\n    if train_data.exists():\n        data = json.loads(train_data.read_text())\n        gold = json.loads(train_gold.read_text()) if train_gold.exists() else []\n        out[\\\"training.en-en.data\\\"] = {\n            \\\"num_examples\\\": len(data),\n            \\\"num_gold\\\": len(gold),\n        }\n\n    # MUSE dictionary sizes (subset used by experiment)\n    dict_dir = Path(\\\"datasets/muse_dictionaries/dictionaries\\\")\n    muse_stats = {}\n    for fname in [\\\"en-fr.0-5000.txt\\\", \\\"en-ru.0-5000.txt\\\", \\\"en-zh.0-5000.txt\\\", \\\"en-ar.0-5000.txt\\\"]:\n        path = dict_dir / fname\n        if path.exists():\n            with path.open(\\\"r\\\", encoding=\\\"utf-8\\\") as f:\n                count = sum(1 for _ in f)\n            muse_stats[fname] = count\n    out[\\\"muse_dictionaries\\\"] = muse_stats\n\n    Path(\\\"results\\\").mkdir(exist_ok=True)\n    with open(\\\"results/data_quality.json\\\", \\\"w\\\") as f:\n        json.dump(out, f, indent=2)\n\n\nif __name__ == \\\"__main__\\\":\n    main()\nPY\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_98","type":"command_execution","command":"/bin/bash -lc \"cat > src/data_quality.py << 'PY'\nimport json\nfrom pathlib import Path\nimport pandas as pd\n\n\ndef count_missing(fields):\n    return {k: int(v) for k, v in fields.items()}\n\n\ndef main():\n    out = {}\n\n    # MCL-WiC crosslingual\n    base = Path(\\\"datasets/mcl_wic/data/MCL-WiC/test/crosslingual\\\")\n    gold_base = Path(\\\"datasets/mcl_wic/data_gold\\\")\n    for path in sorted(base.glob(\\\"*.data\\\")):\n        data = json.loads(path.read_text())\n        gold_path = gold_base / path.name.replace(\\\".data\\\", \\\".gold\\\")\n        gold = json.loads(gold_path.read_text()) if gold_path.exists() else []\n        missing_counts = {\n            \\\"lemma\\\": sum(1 for x in data if not x.get(\\\"lemma\\\")),\n            \\\"sentence1\\\": sum(1 for x in data if not x.get(\\\"sentence1\\\")),\n            \\\"sentence2\\\": sum(1 for x in data if not x.get(\\\"sentence2\\\")),\n            \\\"ranges1\\\": sum(1 for x in data if not x.get(\\\"ranges1\\\")),\n            \\\"ranges2\\\": sum(1 for x in data if not x.get(\\\"ranges2\\\")),\n        }\n        out[path.name] = {\n            \\\"num_examples\\\": len(data),\n            \\\"num_gold\\\": len(gold),\n            \\\"missing\\\": count_missing(missing_counts),\n        }\n\n    # MCL-WiC training (for polysemy lexicon)\n    train_data = Path(\\\"datasets/mcl_wic/data/MCL-WiC/training/training.en-en.data\\\")\n    train_gold = Path(\\\"datasets/mcl_wic/data/MCL-WiC/training/training.en-en.gold\\\")\n    if train_data.exists():\n        data = json.loads(train_data.read_text())\n        gold = json.loads(train_gold.read_text()) if train_gold.exists() else []\n        out[\\\"training.en-en.data\\\"] = {\n            \\\"num_examples\\\": len(data),\n            \\\"num_gold\\\": len(gold),\n        }\n\n    # MUSE dictionary sizes (subset used by experiment)\n    dict_dir = Path(\\\"datasets/muse_dictionaries/dictionaries\\\")\n    muse_stats = {}\n    for fname in [\\\"en-fr.0-5000.txt\\\", \\\"en-ru.0-5000.txt\\\", \\\"en-zh.0-5000.txt\\\", \\\"en-ar.0-5000.txt\\\"]:\n        path = dict_dir / fname\n        if path.exists():\n            with path.open(\\\"r\\\", encoding=\\\"utf-8\\\") as f:\n                count = sum(1 for _ in f)\n            muse_stats[fname] = count\n    out[\\\"muse_dictionaries\\\"] = muse_stats\n\n    Path(\\\"results\\\").mkdir(exist_ok=True)\n    with open(\\\"results/data_quality.json\\\", \\\"w\\\") as f:\n        json.dump(out, f, indent=2)\n\n\nif __name__ == \\\"__main__\\\":\n    main()\nPY\"","aggregated_output":"","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_99","type":"reasoning","text":"**Running script**"}}
{"type":"item.started","item":{"id":"item_100","type":"command_execution","command":"/bin/bash -lc 'source .venv/bin/activate && python src/data_quality.py'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_100","type":"command_execution","command":"/bin/bash -lc 'source .venv/bin/activate && python src/data_quality.py'","aggregated_output":"","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_101","type":"reasoning","text":"**Planning results aggregation module**\n\nI'm preparing to create a new module that will compute aggregated statistics from analysis outputs and save the results as CSV and JSON tables."}}
{"type":"item.started","item":{"id":"item_102","type":"command_execution","command":"/bin/bash -lc \"cat > src/analyze_results.py << 'PY'\nimport json\nfrom pathlib import Path\nimport pandas as pd\nfrom scipy.stats import ttest_ind, mannwhitneyu\n\n\ndef main():\n    static_df = pd.read_csv(\\\"results/static_similarity.csv\\\")\n    context_df = pd.read_csv(\\\"results/contextual_similarity.csv\\\")\n\n    # Load polysemy map from training data\n    import json as _json\n    train_data = Path(\\\"datasets/mcl_wic/data/MCL-WiC/training/training.en-en.data\\\")\n    train_gold = Path(\\\"datasets/mcl_wic/data/MCL-WiC/training/training.en-en.gold\\\")\n    data = _json.loads(train_data.read_text())\n    gold = {item[\\\"id\\\"]: item[\\\"tag\\\"] for item in _json.loads(train_gold.read_text())}\n    lemma_labels = {}\n    for item in data:\n        tag = gold.get(item[\\\"id\\\"])\n        if tag is None:\n            continue\n        lemma_labels.setdefault(item[\\\"lemma\\\"], set()).add(tag)\n    poly_map = {lemma: (\\\"polysemous\\\" if len(labels) > 1 else \\\"monosemous\\\") for lemma, labels in lemma_labels.items()}\n\n    context_df[\\\"polysemy\\\"] = context_df[\\\"lemma\\\"].map(poly_map).fillna(\\\"unknown\\\")\n\n    # Summary tables\n    summary = {\n        \\\"static_pair_type\\\": static_df.groupby(\\\"pair_type\\\")[\\\"cosine\\\"].agg([\\\"count\\\", \\\"mean\\\", \\\"std\\\"]).reset_index(),\n        \\\"static_polysemy\\\": static_df.groupby(\\\"polysemy\\\")[\\\"cosine\\\"].agg([\\\"count\\\", \\\"mean\\\", \\\"std\\\"]).reset_index(),\n        \\\"context_label\\\": context_df.groupby(\\\"label\\\")[\\\"cosine\\\"].agg([\\\"count\\\", \\\"mean\\\", \\\"std\\\"]).reset_index(),\n        \\\"context_polysemy\\\": context_df.groupby(\\\"polysemy\\\")[\\\"cosine\\\"].agg([\\\"count\\\", \\\"mean\\\", \\\"std\\\"]).reset_index(),\n        \\\"context_lang_label\\\": context_df.groupby([\\\"lang_pair\\\", \\\"label\\\"])[\\\"cosine\\\"].agg([\\\"count\\\", \\\"mean\\\"]).reset_index(),\n    }\n\n    # Statistical tests\n    t_vals = context_df[context_df[\\\"label\\\"] == \\\"T\\\"][\\\"cosine\\\"]\n    f_vals = context_df[context_df[\\\"label\\\"] == \\\"F\\\"][\\\"cosine\\\"]\n    ttest = ttest_ind(t_vals, f_vals, equal_var=False)\n    mwu = mannwhitneyu(t_vals, f_vals, alternative=\\\"two-sided\\\")\n\n    stats = {\n        \\\"context_ttest\\\": {\\\"t\\\": float(ttest.statistic), \\\"p\\\": float(ttest.pvalue)},\n        \\\"context_mwu\\\": {\\\"u\\\": float(mwu.statistic), \\\"p\\\": float(mwu.pvalue)},\n    }\n\n    # Save tables\n    Path(\\\"results\\\").mkdir(exist_ok=True)\n    for name, df in summary.items():\n        df.to_csv(f\\\"results/{name}.csv\\\", index=False)\n\n    with open(\\\"results/analysis_summary.json\\\", \\\"w\\\") as f:\n        json.dump(stats, f, indent=2)\n\n    # Update contextual with polysemy for convenience\n    context_df.to_csv(\\\"results/contextual_similarity_with_polysemy.csv\\\", index=False)\n\n\nif __name__ == \\\"__main__\\\":\n    main()\nPY\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_102","type":"command_execution","command":"/bin/bash -lc \"cat > src/analyze_results.py << 'PY'\nimport json\nfrom pathlib import Path\nimport pandas as pd\nfrom scipy.stats import ttest_ind, mannwhitneyu\n\n\ndef main():\n    static_df = pd.read_csv(\\\"results/static_similarity.csv\\\")\n    context_df = pd.read_csv(\\\"results/contextual_similarity.csv\\\")\n\n    # Load polysemy map from training data\n    import json as _json\n    train_data = Path(\\\"datasets/mcl_wic/data/MCL-WiC/training/training.en-en.data\\\")\n    train_gold = Path(\\\"datasets/mcl_wic/data/MCL-WiC/training/training.en-en.gold\\\")\n    data = _json.loads(train_data.read_text())\n    gold = {item[\\\"id\\\"]: item[\\\"tag\\\"] for item in _json.loads(train_gold.read_text())}\n    lemma_labels = {}\n    for item in data:\n        tag = gold.get(item[\\\"id\\\"])\n        if tag is None:\n            continue\n        lemma_labels.setdefault(item[\\\"lemma\\\"], set()).add(tag)\n    poly_map = {lemma: (\\\"polysemous\\\" if len(labels) > 1 else \\\"monosemous\\\") for lemma, labels in lemma_labels.items()}\n\n    context_df[\\\"polysemy\\\"] = context_df[\\\"lemma\\\"].map(poly_map).fillna(\\\"unknown\\\")\n\n    # Summary tables\n    summary = {\n        \\\"static_pair_type\\\": static_df.groupby(\\\"pair_type\\\")[\\\"cosine\\\"].agg([\\\"count\\\", \\\"mean\\\", \\\"std\\\"]).reset_index(),\n        \\\"static_polysemy\\\": static_df.groupby(\\\"polysemy\\\")[\\\"cosine\\\"].agg([\\\"count\\\", \\\"mean\\\", \\\"std\\\"]).reset_index(),\n        \\\"context_label\\\": context_df.groupby(\\\"label\\\")[\\\"cosine\\\"].agg([\\\"count\\\", \\\"mean\\\", \\\"std\\\"]).reset_index(),\n        \\\"context_polysemy\\\": context_df.groupby(\\\"polysemy\\\")[\\\"cosine\\\"].agg([\\\"count\\\", \\\"mean\\\", \\\"std\\\"]).reset_index(),\n        \\\"context_lang_label\\\": context_df.groupby([\\\"lang_pair\\\", \\\"label\\\"])[\\\"cosine\\\"].agg([\\\"count\\\", \\\"mean\\\"]).reset_index(),\n    }\n\n    # Statistical tests\n    t_vals = context_df[context_df[\\\"label\\\"] == \\\"T\\\"][\\\"cosine\\\"]\n    f_vals = context_df[context_df[\\\"label\\\"] == \\\"F\\\"][\\\"cosine\\\"]\n    ttest = ttest_ind(t_vals, f_vals, equal_var=False)\n    mwu = mannwhitneyu(t_vals, f_vals, alternative=\\\"two-sided\\\")\n\n    stats = {\n        \\\"context_ttest\\\": {\\\"t\\\": float(ttest.statistic), \\\"p\\\": float(ttest.pvalue)},\n        \\\"context_mwu\\\": {\\\"u\\\": float(mwu.statistic), \\\"p\\\": float(mwu.pvalue)},\n    }\n\n    # Save tables\n    Path(\\\"results\\\").mkdir(exist_ok=True)\n    for name, df in summary.items():\n        df.to_csv(f\\\"results/{name}.csv\\\", index=False)\n\n    with open(\\\"results/analysis_summary.json\\\", \\\"w\\\") as f:\n        json.dump(stats, f, indent=2)\n\n    # Update contextual with polysemy for convenience\n    context_df.to_csv(\\\"results/contextual_similarity_with_polysemy.csv\\\", index=False)\n\n\nif __name__ == \\\"__main__\\\":\n    main()\nPY\"","aggregated_output":"","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_103","type":"command_execution","command":"/bin/bash -lc 'source .venv/bin/activate && python src/analyze_results.py'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_103","type":"command_execution","command":"/bin/bash -lc 'source .venv/bin/activate && python src/analyze_results.py'","aggregated_output":"","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_104","type":"reasoning","text":"**Planning environment capture**\n\nI'll record the Python version and environment details using a Python script to include in the report for context."}}
{"type":"item.started","item":{"id":"item_105","type":"command_execution","command":"/bin/bash -lc \"source .venv/bin/activate && python - << 'PY'\nimport sys, torch, transformers, datasets, numpy, pandas\nprint('Python', sys.version)\nprint('Torch', torch.__version__)\nprint('Transformers', transformers.__version__)\nprint('Datasets', datasets.__version__)\nprint('NumPy', numpy.__version__)\nprint('Pandas', pandas.__version__)\nprint('CUDA available', torch.cuda.is_available())\nif torch.cuda.is_available():\n    print('CUDA device', torch.cuda.get_device_name(0))\nPY\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_105","type":"command_execution","command":"/bin/bash -lc \"source .venv/bin/activate && python - << 'PY'\nimport sys, torch, transformers, datasets, numpy, pandas\nprint('Python', sys.version)\nprint('Torch', torch.__version__)\nprint('Transformers', transformers.__version__)\nprint('Datasets', datasets.__version__)\nprint('NumPy', numpy.__version__)\nprint('Pandas', pandas.__version__)\nprint('CUDA available', torch.cuda.is_available())\nif torch.cuda.is_available():\n    print('CUDA device', torch.cuda.get_device_name(0))\nPY\"","aggregated_output":"Python 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 17:35:02) [GCC 11.2.0]\nTorch 2.10.0+cu128\nTransformers 5.1.0\nDatasets 4.5.0\nNumPy 2.4.2\nPandas 3.0.0\nCUDA available True\nCUDA device NVIDIA GeForce RTX 3090\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_106","type":"reasoning","text":"**Preparing GPU info and report data**\n\nI'll include GPU details from nvidia-smi earlier in the process and gather data from data_quality.json, metrics JSON, and summary tables to document results and plots; next, I’ll review the summary CSV for a quick overview."}}
{"type":"item.started","item":{"id":"item_107","type":"command_execution","command":"/bin/bash -lc \"python - << 'PY'\nimport pandas as pd\nprint('static_pair_type')\nprint(pd.read_csv('results/static_pair_type.csv'))\nprint('\\\\nstatic_polysemy')\nprint(pd.read_csv('results/static_polysemy.csv'))\nprint('\\\\ncontext_label')\nprint(pd.read_csv('results/context_label.csv'))\nprint('\\\\ncontext_polysemy')\nprint(pd.read_csv('results/context_polysemy.csv'))\nprint('\\\\ncontext_lang_label')\nprint(pd.read_csv('results/context_lang_label.csv'))\nPY\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_107","type":"command_execution","command":"/bin/bash -lc \"python - << 'PY'\nimport pandas as pd\nprint('static_pair_type')\nprint(pd.read_csv('results/static_pair_type.csv'))\nprint('\\\\nstatic_polysemy')\nprint(pd.read_csv('results/static_polysemy.csv'))\nprint('\\\\ncontext_label')\nprint(pd.read_csv('results/context_label.csv'))\nprint('\\\\ncontext_polysemy')\nprint(pd.read_csv('results/context_polysemy.csv'))\nprint('\\\\ncontext_lang_label')\nprint(pd.read_csv('results/context_lang_label.csv'))\nPY\"","aggregated_output":"static_pair_type\n     pair_type  count      mean       std\n0     mismatch   8000  0.374687  0.093737\n1  translation   8000  0.513094  0.164588\n\nstatic_polysemy\n     polysemy  count      mean       std\n0  monosemous   4338  0.435664  0.145287\n1  polysemous   2560  0.431815  0.142469\n2     unknown   9102  0.451207  0.155107\n\ncontext_label\n  label  count      mean       std\n0     F   2000  0.982195  0.005857\n1     T   2000  0.984725  0.005105\n\ncontext_polysemy\n     polysemy  count      mean       std\n0  monosemous    568  0.982056  0.005809\n1  polysemous    248  0.983421  0.005451\n2     unknown   3184  0.983714  0.005585\n\ncontext_lang_label\n  lang_pair label  count      mean\n0     en-ar     F    500  0.982104\n1     en-ar     T    500  0.983908\n2     en-fr     F    500  0.983866\n3     en-fr     T    500  0.986516\n4     en-ru     F    500  0.983257\n5     en-ru     T    500  0.985908\n6     en-zh     F    500  0.979551\n7     en-zh     T    500  0.982568\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_108","type":"reasoning","text":"**Reviewing data quality for distributions**\n\nNoticing very high contextual similarity likely due to XLM-R embeddings across languages; planning to check static polysemy differences and perform exploratory data analysis on distributions using data_quality.json."}}
{"type":"item.started","item":{"id":"item_109","type":"command_execution","command":"/bin/bash -lc 'cat results/data_quality.json'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_109","type":"command_execution","command":"/bin/bash -lc 'cat results/data_quality.json'","aggregated_output":"{\n  \"test.en-ar.data\": {\n    \"num_examples\": 1000,\n    \"num_gold\": 1000,\n    \"missing\": {\n      \"lemma\": 0,\n      \"sentence1\": 0,\n      \"sentence2\": 0,\n      \"ranges1\": 0,\n      \"ranges2\": 0\n    }\n  },\n  \"test.en-fr.data\": {\n    \"num_examples\": 1000,\n    \"num_gold\": 1000,\n    \"missing\": {\n      \"lemma\": 0,\n      \"sentence1\": 0,\n      \"sentence2\": 0,\n      \"ranges1\": 0,\n      \"ranges2\": 0\n    }\n  },\n  \"test.en-ru.data\": {\n    \"num_examples\": 1000,\n    \"num_gold\": 1000,\n    \"missing\": {\n      \"lemma\": 0,\n      \"sentence1\": 0,\n      \"sentence2\": 0,\n      \"ranges1\": 0,\n      \"ranges2\": 0\n    }\n  },\n  \"test.en-zh.data\": {\n    \"num_examples\": 1000,\n    \"num_gold\": 1000,\n    \"missing\": {\n      \"lemma\": 0,\n      \"sentence1\": 0,\n      \"sentence2\": 0,\n      \"ranges1\": 0,\n      \"ranges2\": 0\n    }\n  },\n  \"training.en-en.data\": {\n    \"num_examples\": 8000,\n    \"num_gold\": 8000\n  },\n  \"muse_dictionaries\": {\n    \"en-fr.0-5000.txt\": 10872,\n    \"en-ru.0-5000.txt\": 10887,\n    \"en-zh.0-5000.txt\": 8728,\n    \"en-ar.0-5000.txt\": 11571\n  }\n}","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_110","type":"reasoning","text":"**Planning report and docs updates**\n\nI'm preparing to create REPORT.md with analysis including effect sizes like Cohen’s d, and considering adding a research log section to resources.md to document the research process per requirements."}}
{"type":"item.started","item":{"id":"item_111","type":"command_execution","command":"/bin/bash -lc \"python - << 'PY'\nimport pandas as pd\nimport numpy as np\n\ndef cohens_d(a,b):\n    a=np.array(a); b=np.array(b)\n    na, nb = len(a), len(b)\n    sa, sb = a.std(ddof=1), b.std(ddof=1)\n    s = np.sqrt(((na-1)*sa**2 + (nb-1)*sb**2)/(na+nb-2))\n    return (a.mean()-b.mean())/s\n\ncontext = pd.read_csv('results/contextual_similarity.csv')\nstatic = pd.read_csv('results/static_similarity.csv')\n\n# context T vs F\nT = context[context['label']=='T']['cosine']\nF = context[context['label']=='F']['cosine']\nprint('Context d', cohens_d(T,F))\n\n# static translation vs mismatch\ntr = static[static['pair_type']=='translation']['cosine']\nmm = static[static['pair_type']=='mismatch']['cosine']\nprint('Static d', cohens_d(tr, mm))\n\nPY\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_111","type":"command_execution","command":"/bin/bash -lc \"python - << 'PY'\nimport pandas as pd\nimport numpy as np\n\ndef cohens_d(a,b):\n    a=np.array(a); b=np.array(b)\n    na, nb = len(a), len(b)\n    sa, sb = a.std(ddof=1), b.std(ddof=1)\n    s = np.sqrt(((na-1)*sa**2 + (nb-1)*sb**2)/(na+nb-2))\n    return (a.mean()-b.mean())/s\n\ncontext = pd.read_csv('results/contextual_similarity.csv')\nstatic = pd.read_csv('results/static_similarity.csv')\n\n# context T vs F\nT = context[context['label']=='T']['cosine']\nF = context[context['label']=='F']['cosine']\nprint('Context d', cohens_d(T,F))\n\n# static translation vs mismatch\ntr = static[static['pair_type']=='translation']['cosine']\nmm = static[static['pair_type']=='mismatch']['cosine']\nprint('Static d', cohens_d(tr, mm))\n\nPY\"","aggregated_output":"Context d 0.4606152951945373\nStatic d 1.0334067872525434\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_112","type":"reasoning","text":"**Planning polysemy effect computation**"}}
{"type":"item.started","item":{"id":"item_113","type":"command_execution","command":"/bin/bash -lc \"python - << 'PY'\nimport pandas as pd\nimport numpy as np\n\ndef cohens_d(a,b):\n    a=np.array(a); b=np.array(b)\n    na, nb = len(a), len(b)\n    sa, sb = a.std(ddof=1), b.std(ddof=1)\n    s = np.sqrt(((na-1)*sa**2 + (nb-1)*sb**2)/(na+nb-2))\n    return (a.mean()-b.mean())/s\n\nstatic = pd.read_csv('results/static_similarity.csv')\npoly = static[static['polysemy']=='polysemous']['cosine']\nmono = static[static['polysemy']=='monosemous']['cosine']\nprint('Static polysemy d', cohens_d(poly, mono))\nPY\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_113","type":"command_execution","command":"/bin/bash -lc \"python - << 'PY'\nimport pandas as pd\nimport numpy as np\n\ndef cohens_d(a,b):\n    a=np.array(a); b=np.array(b)\n    na, nb = len(a), len(b)\n    sa, sb = a.std(ddof=1), b.std(ddof=1)\n    s = np.sqrt(((na-1)*sa**2 + (nb-1)*sb**2)/(na+nb-2))\n    return (a.mean()-b.mean())/s\n\nstatic = pd.read_csv('results/static_similarity.csv')\npoly = static[static['polysemy']=='polysemous']['cosine']\nmono = static[static['polysemy']=='monosemous']['cosine']\nprint('Static polysemy d', cohens_d(poly, mono))\nPY\"","aggregated_output":"Static polysemy d -0.026682919551175212\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_114","type":"reasoning","text":"**Outlining final report contents**\n\nPlanning to create REPORT.md and README.md with detailed sections including exec summary, goals, data construction, and experiment notes. Will note evaluation thresholds, data splits, methods limitations, results with tables, significance mentions, and GPU info, plus include plots and contextual/static embedding notes."}}
{"type":"item.completed","item":{"id":"item_115","type":"reasoning","text":"**Detailing data and implementation notes**\n\nPlanning to document dataset sizes, translation pair counts, missing values, and merge limitations alongside implementation specifics like transformer config and pooling method. Will add environment and GPU info, results tables, plots references, and append research execution notes to resources.md."}}
{"type":"item.started","item":{"id":"item_116","type":"command_execution","command":"/bin/bash -lc \"cat > REPORT.md << 'EOF'\n## 1. Executive Summary\nWe evaluated whether multilingual embeddings align meanings across languages and whether polysemy weakens that alignment using MCL-WiC cross-lingual data and MUSE dictionaries with XLM-R embeddings. Translation pairs showed much higher static similarity than mismatched pairs, and contextual similarity was slightly higher for same-sense (T) than different-sense (F) pairs across languages, though the effect was small. Practically, multilingual contextual embeddings appear to preserve shared senses, but polysemy only weakly modulates similarity in this setup.\n\n## 2. Goal\nWe tested the hypothesis that words with similar meanings across languages have similar embeddings in multilingual models, and that polysemy reduces similarity when only one sense aligns. This matters for cross-lingual retrieval, bilingual lexicon induction, and semantic search. The expected impact is clearer guidance on when multilingual embeddings can be trusted for sense-level matching.\n\n## 3. Data Construction\n\n### Dataset Description\n- MCL-WiC (SemEval-2021 Task 2): cross-lingual word-in-context disambiguation data for en-ar, en-fr, en-ru, en-zh. Each example provides two sentences in different languages with target word spans and a gold label (T/F) for same sense.\n- MUSE Dictionaries: bilingual word pairs for en-fr, en-ru, en-zh, en-ar used for static similarity baselines.\n\n### Example Samples\nMCL-WiC (cross-lingual) example format:\n\"'```text\nid: test.en-fr.0\nlemma: gently\nsentence1: ... treated more gently in the 2008 Chairman'\"'s working paper.\nsentence2: Pendant cette décennie, ... augmenté modérément ...\nranges1: 116-122\nranges2: 73-83\nlabel: T/F\n\"'```\n\n### Data Quality\nFrom `results/data_quality.json`:\n- Cross-lingual test sets: 1000 examples each for en-ar, en-fr, en-ru, en-zh; 0 missing spans or sentences.\n- Training en-en set: 8000 examples (used for polysemy lexicon).\n- MUSE dictionary files sizes: en-fr 10872, en-ru 10887, en-zh 8728, en-ar 11571.\n\n### Preprocessing Steps\n1. Parsed MCL-WiC JSON files and joined gold labels.\n2. Converted `ranges1/ranges2` (multi-span possible) to a single span by taking min start / max end.\n3. For embeddings, tokenized sentences and pooled target-span tokens via offset mappings.\n4. For static embeddings, averaged XLM-R input embeddings for the wordpiece tokens.\n\n### Train/Val/Test Splits\n- Polysemy lexicon derived from MCL-WiC training `en-en` set.\n- Threshold selection on MCL-WiC dev `en-en` (multilingual) set.\n- Main evaluation on cross-lingual test sets (en-ar, en-fr, en-ru, en-zh).\n\n## 4. Experiment Description\n\n### Methodology\n#### High-Level Approach\nWe compared static vs contextual similarities in a multilingual encoder (XLM-R). Static similarity used input embedding averages for MUSE translation pairs. Contextual similarity used target-span embeddings from MCL-WiC and compared T vs F labels.\n\n#### Why This Method?\nIt directly aligns with the hypothesis: if embeddings capture shared meaning, translation pairs and same-sense pairs should be more similar than mismatched or different-sense pairs. XLM-R is a widely used multilingual model with strong cross-lingual alignment.\n\n### Implementation Details\n#### Tools and Libraries\n- torch 2.10.0+cu128\n- transformers 5.1.0\n- datasets 4.5.0\n- numpy 2.4.2, pandas 3.0.0, scipy 1.17.0, seaborn 0.13.2\n\n#### Algorithms/Models\n- Model: `xlm-roberta-base`\n- Contextual embeddings: last hidden state, mean pooled over target-span tokens\n- Static embeddings: mean of input embedding vectors for wordpiece tokens\n\n#### Hyperparameters\n| Parameter | Value | Selection Method |\n|---|---|---|\n| max_length | 128 | default (covers WiC sentence lengths) |\n| batch_size | 64 | GPU memory-based (24GB) |\n| similarity | cosine | standard metric |\n| threshold grid | [-1..1], step 0.025 | dev set search |\n\n#### Training Procedure or Analysis Pipeline\n1. Load datasets and gold labels.\n2. Build polysemy lexicon from training (lemmas with both T and F labels).\n3. Compute static similarities for translation and mismatched pairs.\n4. Compute contextual similarities for cross-lingual WiC pairs.\n5. Fit threshold on dev en-en and evaluate on cross-lingual test.\n6. Run statistical tests and generate plots.\n\n### Experimental Protocol\n#### Reproducibility Information\n- Runs: 1 (deterministic inference)\n- Seed: 42\n- Hardware: NVIDIA GeForce RTX 3090 (24GB)\n- Batch size: 64\n- Mixed precision: not used (inference-only)\n\n#### Evaluation Metrics\n- Cosine similarity: measures embedding alignment\n- WiC accuracy (thresholded similarity): interpretable baseline for sense matching\n- Statistical tests: Welch t-test and Mann–Whitney U on T vs F similarities\n\n### Raw Results\n#### Tables\nStatic similarity (MUSE dictionaries, 4 languages, 2k pairs each):\n| Pair Type | Count | Mean | Std |\n|---|---:|---:|---:|\n| translation | 8000 | 0.5131 | 0.1646 |\n| mismatch | 8000 | 0.3747 | 0.0937 |\n\nContextual similarity (MCL-WiC cross-lingual test):\n| Label | Count | Mean | Std |\n|---|---:|---:|---:|\n| T (same sense) | 2000 | 0.9847 | 0.0051 |\n| F (different sense) | 2000 | 0.9822 | 0.0059 |\n\n#### Visualizations\n- `figures/contextual_similarity_hist.png`\n- `figures/contextual_similarity_box.png`\n- `figures/contextual_similarity_polysemy.png`\n- `figures/static_similarity_box.png`\n\n#### Output Locations\n- Results JSON: `results/metrics.json`\n- Plots: `figures/`\n- Tables: `results/*.csv`\n\n## 5. Result Analysis\n\n### Key Findings\n1. Translation pairs are substantially more similar than mismatched pairs in static embeddings (mean 0.513 vs 0.375; Cohen’s d ≈ 1.03).\n2. Contextual similarity is higher for same-sense (T) than different-sense (F) pairs, but the effect is small (mean 0.9847 vs 0.9822; Cohen’s d ≈ 0.46; p < 1e-46).\n3. Polysemy classification from MCL-WiC training shows minimal effect on static similarity (d ≈ -0.03), and a small effect on contextual similarity (polysemous slightly higher than monosemous).\n\n### Hypothesis Testing Results\n- H1 (translation pairs higher similarity): Supported.\n- H2 (same-sense contexts higher similarity): Supported with small effect size.\n- H3 (polysemy reduces similarity in static embeddings): Not supported in this setup.\n\nStatistical tests (contextual T vs F):\n- Welch t-test: t = 14.57, p = 7.56e-47\n- Mann–Whitney U: U = 2,541,088.5, p = 1.15e-49\n\n### Comparison to Baselines\n- Static baseline clearly separates translation vs mismatched pairs.\n- Thresholded WiC accuracy (dev-trained threshold) on cross-lingual test: 0.53 (slightly above chance).\n\n### Surprises and Insights\n- Contextual similarity values are extremely high for both T and F, suggesting that raw cosine similarity may be too coarse for sense discrimination without additional normalization.\n\n### Error Analysis\n- Many F examples still have high cosine similarity, indicating overlap in contextual representations even when senses differ.\n- This may be due to averaging over wordpiece spans and the overall sentence context dominating the target token representation.\n\n### Limitations\n- Static embeddings derived from XLM-R input embeddings, not standalone monolingual vectors (e.g., fastText).\n- Polysemy is approximated by presence of both T and F labels in MCL-WiC training, which is incomplete.\n- Span handling merges multiple ranges into a single contiguous span, which may blur multiword targets.\n- No fine-tuning or alignment-specific training was performed.\n\n## 6. Conclusions\nMultilingual embeddings in XLM-R show strong alignment for translation pairs and slightly higher similarity for cross-lingual same-sense pairs, indicating that shared meaning is reflected in embeddings. However, polysemy does not strongly reduce similarity in static embeddings and the contextual effect size is modest. This suggests that raw cosine similarity is informative but insufficient for robust sense discrimination without additional modeling.\n\n### Implications\n- Cross-lingual semantic retrieval can rely on multilingual embeddings for broad meaning alignment.\n- Sense-level distinction likely requires more than simple cosine similarity (e.g., probing, alignment, or contrastive objectives).\n\n### Confidence in Findings\nModerate. The experiments are consistent across four language pairs, but the polysemy proxy and static baseline are limited. Stronger evidence would come from sense-annotated lexicons and multi-model comparisons.\n\n## 7. Next Steps\n### Immediate Follow-ups\n1. Replace static baseline with fastText or aligned MUSE vectors to separate model effects from token-embedding artifacts.\n2. Evaluate with XL-WiC to test consistency across a different benchmark.\n\n### Alternative Approaches\n- Use contrastive probing on contextual embeddings to improve sense separability.\n\n### Broader Extensions\n- Extend to more language families and scripts.\n\n### Open Questions\n- How do alignment-aware fine-tuned models (e.g., multilingual sentence encoders) change sense-level similarity?\n\n## References\n- MCL-WiC (SemEval-2021 Task 2)\n- XL-WiC\n- MUSE dictionaries\n- XLM-R (Conneau et al., 2019)\nEOF'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_116","type":"command_execution","command":"/bin/bash -lc \"cat > REPORT.md << 'EOF'\n## 1. Executive Summary\nWe evaluated whether multilingual embeddings align meanings across languages and whether polysemy weakens that alignment using MCL-WiC cross-lingual data and MUSE dictionaries with XLM-R embeddings. Translation pairs showed much higher static similarity than mismatched pairs, and contextual similarity was slightly higher for same-sense (T) than different-sense (F) pairs across languages, though the effect was small. Practically, multilingual contextual embeddings appear to preserve shared senses, but polysemy only weakly modulates similarity in this setup.\n\n## 2. Goal\nWe tested the hypothesis that words with similar meanings across languages have similar embeddings in multilingual models, and that polysemy reduces similarity when only one sense aligns. This matters for cross-lingual retrieval, bilingual lexicon induction, and semantic search. The expected impact is clearer guidance on when multilingual embeddings can be trusted for sense-level matching.\n\n## 3. Data Construction\n\n### Dataset Description\n- MCL-WiC (SemEval-2021 Task 2): cross-lingual word-in-context disambiguation data for en-ar, en-fr, en-ru, en-zh. Each example provides two sentences in different languages with target word spans and a gold label (T/F) for same sense.\n- MUSE Dictionaries: bilingual word pairs for en-fr, en-ru, en-zh, en-ar used for static similarity baselines.\n\n### Example Samples\nMCL-WiC (cross-lingual) example format:\n\"'```text\nid: test.en-fr.0\nlemma: gently\nsentence1: ... treated more gently in the 2008 Chairman'\"'s working paper.\nsentence2: Pendant cette décennie, ... augmenté modérément ...\nranges1: 116-122\nranges2: 73-83\nlabel: T/F\n\"'```\n\n### Data Quality\nFrom `results/data_quality.json`:\n- Cross-lingual test sets: 1000 examples each for en-ar, en-fr, en-ru, en-zh; 0 missing spans or sentences.\n- Training en-en set: 8000 examples (used for polysemy lexicon).\n- MUSE dictionary files sizes: en-fr 10872, en-ru 10887, en-zh 8728, en-ar 11571.\n\n### Preprocessing Steps\n1. Parsed MCL-WiC JSON files and joined gold labels.\n2. Converted `ranges1/ranges2` (multi-span possible) to a single span by taking min start / max end.\n3. For embeddings, tokenized sentences and pooled target-span tokens via offset mappings.\n4. For static embeddings, averaged XLM-R input embeddings for the wordpiece tokens.\n\n### Train/Val/Test Splits\n- Polysemy lexicon derived from MCL-WiC training `en-en` set.\n- Threshold selection on MCL-WiC dev `en-en` (multilingual) set.\n- Main evaluation on cross-lingual test sets (en-ar, en-fr, en-ru, en-zh).\n\n## 4. Experiment Description\n\n### Methodology\n#### High-Level Approach\nWe compared static vs contextual similarities in a multilingual encoder (XLM-R). Static similarity used input embedding averages for MUSE translation pairs. Contextual similarity used target-span embeddings from MCL-WiC and compared T vs F labels.\n\n#### Why This Method?\nIt directly aligns with the hypothesis: if embeddings capture shared meaning, translation pairs and same-sense pairs should be more similar than mismatched or different-sense pairs. XLM-R is a widely used multilingual model with strong cross-lingual alignment.\n\n### Implementation Details\n#### Tools and Libraries\n- torch 2.10.0+cu128\n- transformers 5.1.0\n- datasets 4.5.0\n- numpy 2.4.2, pandas 3.0.0, scipy 1.17.0, seaborn 0.13.2\n\n#### Algorithms/Models\n- Model: `xlm-roberta-base`\n- Contextual embeddings: last hidden state, mean pooled over target-span tokens\n- Static embeddings: mean of input embedding vectors for wordpiece tokens\n\n#### Hyperparameters\n| Parameter | Value | Selection Method |\n|---|---|---|\n| max_length | 128 | default (covers WiC sentence lengths) |\n| batch_size | 64 | GPU memory-based (24GB) |\n| similarity | cosine | standard metric |\n| threshold grid | [-1..1], step 0.025 | dev set search |\n\n#### Training Procedure or Analysis Pipeline\n1. Load datasets and gold labels.\n2. Build polysemy lexicon from training (lemmas with both T and F labels).\n3. Compute static similarities for translation and mismatched pairs.\n4. Compute contextual similarities for cross-lingual WiC pairs.\n5. Fit threshold on dev en-en and evaluate on cross-lingual test.\n6. Run statistical tests and generate plots.\n\n### Experimental Protocol\n#### Reproducibility Information\n- Runs: 1 (deterministic inference)\n- Seed: 42\n- Hardware: NVIDIA GeForce RTX 3090 (24GB)\n- Batch size: 64\n- Mixed precision: not used (inference-only)\n\n#### Evaluation Metrics\n- Cosine similarity: measures embedding alignment\n- WiC accuracy (thresholded similarity): interpretable baseline for sense matching\n- Statistical tests: Welch t-test and Mann–Whitney U on T vs F similarities\n\n### Raw Results\n#### Tables\nStatic similarity (MUSE dictionaries, 4 languages, 2k pairs each):\n| Pair Type | Count | Mean | Std |\n|---|---:|---:|---:|\n| translation | 8000 | 0.5131 | 0.1646 |\n| mismatch | 8000 | 0.3747 | 0.0937 |\n\nContextual similarity (MCL-WiC cross-lingual test):\n| Label | Count | Mean | Std |\n|---|---:|---:|---:|\n| T (same sense) | 2000 | 0.9847 | 0.0051 |\n| F (different sense) | 2000 | 0.9822 | 0.0059 |\n\n#### Visualizations\n- `figures/contextual_similarity_hist.png`\n- `figures/contextual_similarity_box.png`\n- `figures/contextual_similarity_polysemy.png`\n- `figures/static_similarity_box.png`\n\n#### Output Locations\n- Results JSON: `results/metrics.json`\n- Plots: `figures/`\n- Tables: `results/*.csv`\n\n## 5. Result Analysis\n\n### Key Findings\n1. Translation pairs are substantially more similar than mismatched pairs in static embeddings (mean 0.513 vs 0.375; Cohen’s d ≈ 1.03).\n2. Contextual similarity is higher for same-sense (T) than different-sense (F) pairs, but the effect is small (mean 0.9847 vs 0.9822; Cohen’s d ≈ 0.46; p < 1e-46).\n3. Polysemy classification from MCL-WiC training shows minimal effect on static similarity (d ≈ -0.03), and a small effect on contextual similarity (polysemous slightly higher than monosemous).\n\n### Hypothesis Testing Results\n- H1 (translation pairs higher similarity): Supported.\n- H2 (same-sense contexts higher similarity): Supported with small effect size.\n- H3 (polysemy reduces similarity in static embeddings): Not supported in this setup.\n\nStatistical tests (contextual T vs F):\n- Welch t-test: t = 14.57, p = 7.56e-47\n- Mann–Whitney U: U = 2,541,088.5, p = 1.15e-49\n\n### Comparison to Baselines\n- Static baseline clearly separates translation vs mismatched pairs.\n- Thresholded WiC accuracy (dev-trained threshold) on cross-lingual test: 0.53 (slightly above chance).\n\n### Surprises and Insights\n- Contextual similarity values are extremely high for both T and F, suggesting that raw cosine similarity may be too coarse for sense discrimination without additional normalization.\n\n### Error Analysis\n- Many F examples still have high cosine similarity, indicating overlap in contextual representations even when senses differ.\n- This may be due to averaging over wordpiece spans and the overall sentence context dominating the target token representation.\n\n### Limitations\n- Static embeddings derived from XLM-R input embeddings, not standalone monolingual vectors (e.g., fastText).\n- Polysemy is approximated by presence of both T and F labels in MCL-WiC training, which is incomplete.\n- Span handling merges multiple ranges into a single contiguous span, which may blur multiword targets.\n- No fine-tuning or alignment-specific training was performed.\n\n## 6. Conclusions\nMultilingual embeddings in XLM-R show strong alignment for translation pairs and slightly higher similarity for cross-lingual same-sense pairs, indicating that shared meaning is reflected in embeddings. However, polysemy does not strongly reduce similarity in static embeddings and the contextual effect size is modest. This suggests that raw cosine similarity is informative but insufficient for robust sense discrimination without additional modeling.\n\n### Implications\n- Cross-lingual semantic retrieval can rely on multilingual embeddings for broad meaning alignment.\n- Sense-level distinction likely requires more than simple cosine similarity (e.g., probing, alignment, or contrastive objectives).\n\n### Confidence in Findings\nModerate. The experiments are consistent across four language pairs, but the polysemy proxy and static baseline are limited. Stronger evidence would come from sense-annotated lexicons and multi-model comparisons.\n\n## 7. Next Steps\n### Immediate Follow-ups\n1. Replace static baseline with fastText or aligned MUSE vectors to separate model effects from token-embedding artifacts.\n2. Evaluate with XL-WiC to test consistency across a different benchmark.\n\n### Alternative Approaches\n- Use contrastive probing on contextual embeddings to improve sense separability.\n\n### Broader Extensions\n- Extend to more language families and scripts.\n\n### Open Questions\n- How do alignment-aware fine-tuned models (e.g., multilingual sentence encoders) change sense-level similarity?\n\n## References\n- MCL-WiC (SemEval-2021 Task 2)\n- XL-WiC\n- MUSE dictionaries\n- XLM-R (Conneau et al., 2019)\nEOF'","aggregated_output":"","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_117","type":"reasoning","text":"**Noting missing README.md**"}}
{"type":"item.started","item":{"id":"item_118","type":"command_execution","command":"/bin/bash -lc \"cat > README.md << 'EOF'\n# Multilingual Embedding Similarity and Polysemy\n\nThis project evaluates whether words with similar meanings across languages have similar embeddings, and how polysemy affects that similarity using MCL-WiC and MUSE datasets with XLM-R embeddings.\n\n## Key Findings\n- Translation pairs show much higher static similarity than mismatched pairs.\n- Same-sense cross-lingual contexts have slightly higher similarity than different-sense contexts.\n- Polysemy shows minimal effect on static similarity in this setup.\n\n## How to Reproduce\n1. Create and activate environment:\n\"'```bash\nuv venv\nsource .venv/bin/activate\nuv pip install -r requirements.txt\n```\n2. Run experiments:\n```bash\npython src/run_experiments.py\npython src/data_quality.py\npython src/analyze_results.py\n```\n\n## File Structure\n- `src/run_experiments.py`: main experiments and plots\n- `src/data_quality.py`: data quality checks\n- `src/analyze_results.py`: summary tables and stats\n- `results/`: metrics and tables\n- `figures/`: plots\n- `REPORT.md`: full report\n\nSee `REPORT.md` for full methodology and analysis.\nEOF'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_118","type":"command_execution","command":"/bin/bash -lc \"cat > README.md << 'EOF'\n# Multilingual Embedding Similarity and Polysemy\n\nThis project evaluates whether words with similar meanings across languages have similar embeddings, and how polysemy affects that similarity using MCL-WiC and MUSE datasets with XLM-R embeddings.\n\n## Key Findings\n- Translation pairs show much higher static similarity than mismatched pairs.\n- Same-sense cross-lingual contexts have slightly higher similarity than different-sense contexts.\n- Polysemy shows minimal effect on static similarity in this setup.\n\n## How to Reproduce\n1. Create and activate environment:\n\"'```bash\nuv venv\nsource .venv/bin/activate\nuv pip install -r requirements.txt\n```\n2. Run experiments:\n```bash\npython src/run_experiments.py\npython src/data_quality.py\npython src/analyze_results.py\n```\n\n## File Structure\n- `src/run_experiments.py`: main experiments and plots\n- `src/data_quality.py`: data quality checks\n- `src/analyze_results.py`: summary tables and stats\n- `results/`: metrics and tables\n- `figures/`: plots\n- `REPORT.md`: full report\n\nSee `REPORT.md` for full methodology and analysis.\nEOF'","aggregated_output":"","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_119","type":"reasoning","text":"**Adding research process to resources**"}}
{"type":"item.started","item":{"id":"item_120","type":"command_execution","command":"/bin/bash -lc \"cat >> resources.md << 'EOF'\n\n## Research Execution Notes (2026-02-15)\n- Implemented experiments in \"'`src/run_experiments.py` using XLM-R embeddings.\n- Data quality checks: `src/data_quality.py` (outputs in `results/data_quality.json`).\n- Analysis summaries: `src/analyze_results.py` (tables in `results/*.csv`).\n- Plots saved in `figures/` and metrics in `results/metrics.json`.\n- Full report: `REPORT.md`.\nEOF'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_120","type":"command_execution","command":"/bin/bash -lc \"cat >> resources.md << 'EOF'\n\n## Research Execution Notes (2026-02-15)\n- Implemented experiments in \"'`src/run_experiments.py` using XLM-R embeddings.\n- Data quality checks: `src/data_quality.py` (outputs in `results/data_quality.json`).\n- Analysis summaries: `src/analyze_results.py` (tables in `results/*.csv`).\n- Plots saved in `figures/` and metrics in `results/metrics.json`.\n- Full report: `REPORT.md`.\nEOF'","aggregated_output":"","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_121","type":"reasoning","text":"**Considering validation completeness**\n\nPlanning to mention environment details and GPU detection in the report and possibly add statistical p-values for static polysemy analysis. To fully comply with reproducibility checks, deciding to re-run the experiments script despite the compute cost, as it ensures results are reproducible per instructions."}}
{"type":"item.completed","item":{"id":"item_122","type":"reasoning","text":"**Planning lightweight reproducibility check**\n\nDeciding to implement reproducibility by copying existing metrics, re-running experiments to regenerate metrics, and then comparing files to confirm outputs match, balancing correctness with runtime cost."}}
{"type":"item.started","item":{"id":"item_123","type":"command_execution","command":"/bin/bash -lc 'cp results/metrics.json results/metrics_run1.json'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_123","type":"command_execution","command":"/bin/bash -lc 'cp results/metrics.json results/metrics_run1.json'","aggregated_output":"","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_124","type":"reasoning","text":"**Re-running experiments**"}}
{"type":"item.started","item":{"id":"item_125","type":"command_execution","command":"/bin/bash -lc 'source .venv/bin/activate && python src/run_experiments.py'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_125","type":"command_execution","command":"/bin/bash -lc 'source .venv/bin/activate && python src/run_experiments.py'","aggregated_output":"2026-02-15 19:46:45,054 | INFO | Starting experiments\n2026-02-15 19:46:45,321 | INFO | Device: cuda\n2026-02-15 19:46:45,418 | INFO | HTTP Request: HEAD https://huggingface.co/xlm-roberta-base/resolve/main/config.json \"HTTP/1.1 200 OK\"\n2026-02-15 19:46:45,461 | INFO | HTTP Request: HEAD https://huggingface.co/xlm-roberta-base/resolve/main/tokenizer_config.json \"HTTP/1.1 200 OK\"\n2026-02-15 19:46:45,501 | INFO | HTTP Request: GET https://huggingface.co/api/models/xlm-roberta-base/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 307 Temporary Redirect\"\n2026-02-15 19:46:45,546 | INFO | HTTP Request: GET https://huggingface.co/api/models/FacebookAI/xlm-roberta-base/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n2026-02-15 19:46:45,583 | INFO | HTTP Request: GET https://huggingface.co/api/models/xlm-roberta-base/tree/main?recursive=true&expand=false \"HTTP/1.1 307 Temporary Redirect\"\n2026-02-15 19:46:45,619 | INFO | HTTP Request: GET https://huggingface.co/api/models/FacebookAI/xlm-roberta-base/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n2026-02-15 19:46:47,510 | INFO | HTTP Request: GET https://huggingface.co/api/models/xlm-roberta-base \"HTTP/1.1 307 Temporary Redirect\"\n2026-02-15 19:46:47,545 | INFO | HTTP Request: GET https://huggingface.co/api/models/FacebookAI/xlm-roberta-base \"HTTP/1.1 200 OK\"\n2026-02-15 19:46:47,625 | INFO | HTTP Request: HEAD https://huggingface.co/xlm-roberta-base/resolve/main/config.json \"HTTP/1.1 200 OK\"\n\rLoading weights:   0%|          | 0/199 [00:00<?, ?it/s]\rLoading weights:   1%|          | 1/199 [00:00<00:00, 17189.77it/s, Materializing param=embeddings.LayerNorm.bias]\rLoading weights:   1%|          | 1/199 [00:00<00:00, 3816.47it/s, Materializing param=embeddings.LayerNorm.bias] \rLoading weights:   1%|          | 2/199 [00:00<00:00, 4793.49it/s, Materializing param=embeddings.LayerNorm.weight]\rLoading weights:   1%|          | 2/199 [00:00<00:00, 4198.50it/s, Materializing param=embeddings.LayerNorm.weight]\rLoading weights:   2%|▏         | 3/199 [00:00<00:00, 4789.84it/s, Materializing param=embeddings.position_embeddings.weight]\rLoading weights:   2%|▏         | 3/199 [00:00<00:00, 4325.51it/s, Materializing param=embeddings.position_embeddings.weight]\rLoading weights:   2%|▏         | 4/199 [00:00<00:00, 4696.87it/s, Materializing param=embeddings.token_type_embeddings.weight]\rLoading weights:   2%|▏         | 4/199 [00:00<00:00, 4404.62it/s, Materializing param=embeddings.token_type_embeddings.weight]\rLoading weights:   3%|▎         | 5/199 [00:00<00:00, 4704.24it/s, Materializing param=embeddings.word_embeddings.weight]      \rLoading weights:   3%|▎         | 5/199 [00:00<00:00, 4480.14it/s, Materializing param=embeddings.word_embeddings.weight]\rLoading weights:   3%|▎         | 6/199 [00:00<00:00, 3980.67it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]\rLoading weights:   3%|▎         | 6/199 [00:00<00:00, 3827.50it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]\rLoading weights:   4%|▎         | 7/199 [00:00<00:00, 4032.43it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\rLoading weights:   4%|▎         | 7/199 [00:00<00:00, 3907.91it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\rLoading weights:   4%|▍         | 8/199 [00:00<00:00, 3331.13it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]      \rLoading weights:   4%|▍         | 8/199 [00:00<00:00, 3253.61it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]\rLoading weights:   5%|▍         | 9/199 [00:00<00:00, 3440.77it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\rLoading weights:   5%|▍         | 9/199 [00:00<00:00, 3369.22it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\rLoading weights:   5%|▌         | 10/199 [00:00<00:00, 3092.23it/s, Materializing param=encoder.layer.0.attention.self.key.bias]     \rLoading weights:   5%|▌         | 10/199 [00:00<00:00, 3036.93it/s, Materializing param=encoder.layer.0.attention.self.key.bias]\rLoading weights:   6%|▌         | 11/199 [00:00<00:00, 3181.23it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\rLoading weights:   6%|▌         | 11/199 [00:00<00:00, 3128.59it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\rLoading weights:   6%|▌         | 12/199 [00:00<00:00, 2438.79it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\rLoading weights:   6%|▌         | 12/199 [00:00<00:00, 2411.10it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\rLoading weights:   7%|▋         | 13/199 [00:00<00:00, 2543.78it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\rLoading weights:   7%|▋         | 13/199 [00:00<00:00, 2515.85it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\rLoading weights:   7%|▋         | 14/199 [00:00<00:00, 2634.02it/s, Materializing param=encoder.layer.0.attention.self.value.bias]  \rLoading weights:   7%|▋         | 14/199 [00:00<00:00, 2607.70it/s, Materializing param=encoder.layer.0.attention.self.value.bias]\rLoading weights:   8%|▊         | 15/199 [00:00<00:00, 2710.90it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\rLoading weights:   8%|▊         | 15/199 [00:00<00:00, 2683.84it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\rLoading weights:   8%|▊         | 16/199 [00:00<00:00, 2787.72it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]    \rLoading weights:   8%|▊         | 16/199 [00:00<00:00, 2762.14it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]\rLoading weights:   9%|▊         | 17/199 [00:00<00:00, 2868.88it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\rLoading weights:   9%|▊         | 17/199 [00:00<00:00, 2842.69it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\rLoading weights:   9%|▉         | 18/199 [00:00<00:00, 2935.36it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]    \rLoading weights:   9%|▉         | 18/199 [00:00<00:00, 2909.12it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]\rLoading weights:  10%|▉         | 19/199 [00:00<00:00, 2739.30it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\rLoading weights:  10%|▉         | 19/199 [00:00<00:00, 2717.54it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\rLoading weights:  10%|█         | 20/199 [00:00<00:00, 2808.56it/s, Materializing param=encoder.layer.0.output.dense.bias]      \rLoading weights:  10%|█         | 20/199 [00:00<00:00, 2788.40it/s, Materializing param=encoder.layer.0.output.dense.bias]\rLoading weights:  11%|█         | 21/199 [00:00<00:00, 2790.80it/s, Materializing param=encoder.layer.0.output.dense.weight]\rLoading weights:  11%|█         | 21/199 [00:00<00:00, 2771.04it/s, Materializing param=encoder.layer.0.output.dense.weight]\rLoading weights:  11%|█         | 22/199 [00:00<00:00, 2849.74it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\rLoading weights:  11%|█         | 22/199 [00:00<00:00, 2830.16it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\rLoading weights:  12%|█▏        | 23/199 [00:00<00:00, 2787.88it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]\rLoading weights:  12%|█▏        | 23/199 [00:00<00:00, 2768.28it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]\rLoading weights:  12%|█▏        | 24/199 [00:00<00:00, 2826.83it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]      \rLoading weights:  12%|█▏        | 24/199 [00:00<00:00, 2808.22it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]\rLoading weights:  13%|█▎        | 25/199 [00:00<00:00, 2556.82it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\rLoading weights:  13%|█▎        | 25/199 [00:00<00:00, 2540.71it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\rLoading weights:  13%|█▎        | 26/199 [00:00<00:00, 2592.03it/s, Materializing param=encoder.layer.1.attention.self.key.bias]      \rLoading weights:  13%|█▎        | 26/199 [00:00<00:00, 2577.15it/s, Materializing param=encoder.layer.1.attention.self.key.bias]\rLoading weights:  14%|█▎        | 27/199 [00:00<00:00, 2543.37it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\rLoading weights:  14%|█▎        | 27/199 [00:00<00:00, 2480.31it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\rLoading weights:  14%|█▍        | 28/199 [00:00<00:00, 2412.35it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\rLoading weights:  14%|█▍        | 28/199 [00:00<00:00, 2345.90it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\rLoading weights:  15%|█▍        | 29/199 [00:00<00:00, 2377.77it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\rLoading weights:  15%|█▍        | 29/199 [00:00<00:00, 2339.22it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\rLoading weights:  15%|█▌        | 30/199 [00:00<00:00, 2140.61it/s, Materializing param=encoder.layer.1.attention.self.value.bias]  \rLoading weights:  15%|█▌        | 30/199 [00:00<00:00, 2115.56it/s, Materializing param=encoder.layer.1.attention.self.value.bias]\rLoading weights:  16%|█▌        | 31/199 [00:00<00:00, 2079.88it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\rLoading weights:  16%|█▌        | 31/199 [00:00<00:00, 2058.34it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\rLoading weights:  16%|█▌        | 32/199 [00:00<00:00, 2092.09it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]    \rLoading weights:  16%|█▌        | 32/199 [00:00<00:00, 2081.96it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]\rLoading weights:  17%|█▋        | 33/199 [00:00<00:00, 2103.14it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\rLoading weights:  17%|█▋        | 33/199 [00:00<00:00, 2009.50it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\rLoading weights:  17%|█▋        | 34/199 [00:00<00:00, 1948.20it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]    \rLoading weights:  17%|█▋        | 34/199 [00:00<00:00, 1925.79it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]\rLoading weights:  18%|█▊        | 35/199 [00:00<00:00, 1924.93it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\rLoading weights:  18%|█▊        | 35/199 [00:00<00:00, 1916.43it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\rLoading weights:  18%|█▊        | 36/199 [00:00<00:00, 1926.99it/s, Materializing param=encoder.layer.1.output.dense.bias]      \rLoading weights:  18%|█▊        | 36/199 [00:00<00:00, 1916.03it/s, Materializing param=encoder.layer.1.output.dense.bias]\rLoading weights:  19%|█▊        | 37/199 [00:00<00:00, 1921.30it/s, Materializing param=encoder.layer.1.output.dense.weight]\rLoading weights:  19%|█▊        | 37/199 [00:00<00:00, 1892.23it/s, Materializing param=encoder.layer.1.output.dense.weight]\rLoading weights:  19%|█▉        | 38/199 [00:00<00:00, 1898.19it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\rLoading weights:  19%|█▉        | 38/199 [00:00<00:00, 1881.99it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\rLoading weights:  20%|█▉        | 39/199 [00:00<00:00, 1845.25it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\rLoading weights:  20%|█▉        | 39/199 [00:00<00:00, 1828.89it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\rLoading weights:  20%|██        | 40/199 [00:00<00:00, 1836.91it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]      \rLoading weights:  20%|██        | 40/199 [00:00<00:00, 1820.60it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]\rLoading weights:  21%|██        | 41/199 [00:00<00:00, 1813.07it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\rLoading weights:  21%|██        | 41/199 [00:00<00:00, 1790.83it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\rLoading weights:  21%|██        | 42/199 [00:00<00:00, 1808.63it/s, Materializing param=encoder.layer.2.attention.self.key.bias]      \rLoading weights:  21%|██        | 42/199 [00:00<00:00, 1775.89it/s, Materializing param=encoder.layer.2.attention.self.key.bias]\rLoading weights:  22%|██▏       | 43/199 [00:00<00:00, 1779.33it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\rLoading weights:  22%|██▏       | 43/199 [00:00<00:00, 1765.82it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\rLoading weights:  22%|██▏       | 44/199 [00:00<00:00, 1774.33it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\rLoading weights:  22%|██▏       | 44/199 [00:00<00:00, 1732.79it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\rLoading weights:  23%|██▎       | 45/199 [00:00<00:00, 1724.14it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\rLoading weights:  23%|██▎       | 45/199 [00:00<00:00, 1702.86it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\rLoading weights:  23%|██▎       | 46/199 [00:00<00:00, 1727.81it/s, Materializing param=encoder.layer.2.attention.self.value.bias]  \rLoading weights:  23%|██▎       | 46/199 [00:00<00:00, 1703.99it/s, Materializing param=encoder.layer.2.attention.self.value.bias]\rLoading weights:  24%|██▎       | 47/199 [00:00<00:00, 1712.33it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\rLoading weights:  24%|██▎       | 47/199 [00:00<00:00, 1684.96it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\rLoading weights:  24%|██▍       | 48/199 [00:00<00:00, 1690.74it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]    \rLoading weights:  24%|██▍       | 48/199 [00:00<00:00, 1631.06it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]\rLoading weights:  25%|██▍       | 49/199 [00:00<00:00, 1634.09it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\rLoading weights:  25%|██▍       | 49/199 [00:00<00:00, 1621.82it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\rLoading weights:  25%|██▌       | 50/199 [00:00<00:00, 1619.84it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]    \rLoading weights:  25%|██▌       | 50/199 [00:00<00:00, 1576.15it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]\rLoading weights:  26%|██▌       | 51/199 [00:00<00:00, 1586.61it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\rLoading weights:  26%|██▌       | 51/199 [00:00<00:00, 1559.79it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\rLoading weights:  26%|██▌       | 52/199 [00:00<00:00, 1571.84it/s, Materializing param=encoder.layer.2.output.dense.bias]      \rLoading weights:  26%|██▌       | 52/199 [00:00<00:00, 1552.21it/s, Materializing param=encoder.layer.2.output.dense.bias]\rLoading weights:  27%|██▋       | 53/199 [00:00<00:00, 1545.92it/s, Materializing param=encoder.layer.2.output.dense.weight]\rLoading weights:  27%|██▋       | 53/199 [00:00<00:00, 1538.85it/s, Materializing param=encoder.layer.2.output.dense.weight]\rLoading weights:  27%|██▋       | 54/199 [00:00<00:00, 1544.65it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\rLoading weights:  27%|██▋       | 54/199 [00:00<00:00, 1536.69it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\rLoading weights:  28%|██▊       | 55/199 [00:00<00:00, 1532.58it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\rLoading weights:  28%|██▊       | 55/199 [00:00<00:00, 1521.37it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\rLoading weights:  28%|██▊       | 56/199 [00:00<00:00, 1531.49it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]      \rLoading weights:  28%|██▊       | 56/199 [00:00<00:00, 1521.76it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]\rLoading weights:  29%|██▊       | 57/199 [00:00<00:00, 1526.77it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\rLoading weights:  29%|██▊       | 57/199 [00:00<00:00, 1507.92it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\rLoading weights:  29%|██▉       | 58/199 [00:00<00:00, 1523.91it/s, Materializing param=encoder.layer.3.attention.self.key.bias]      \rLoading weights:  29%|██▉       | 58/199 [00:00<00:00, 1498.18it/s, Materializing param=encoder.layer.3.attention.self.key.bias]\rLoading weights:  30%|██▉       | 59/199 [00:00<00:00, 1496.16it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\rLoading weights:  30%|██▉       | 59/199 [00:00<00:00, 1490.70it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\rLoading weights:  30%|███       | 60/199 [00:00<00:00, 1504.45it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\rLoading weights:  30%|███       | 60/199 [00:00<00:00, 1493.49it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\rLoading weights:  31%|███       | 61/199 [00:00<00:00, 1501.59it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\rLoading weights:  31%|███       | 61/199 [00:00<00:00, 1487.84it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\rLoading weights:  31%|███       | 62/199 [00:00<00:00, 1470.40it/s, Materializing param=encoder.layer.3.attention.self.value.bias]  \rLoading weights:  31%|███       | 62/199 [00:00<00:00, 1466.04it/s, Materializing param=encoder.layer.3.attention.self.value.bias]\rLoading weights:  32%|███▏      | 63/199 [00:00<00:00, 1465.34it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\rLoading weights:  32%|███▏      | 63/199 [00:00<00:00, 1458.99it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\rLoading weights:  32%|███▏      | 64/199 [00:00<00:00, 1464.23it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]    \rLoading weights:  32%|███▏      | 64/199 [00:00<00:00, 1454.43it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]\rLoading weights:  33%|███▎      | 65/199 [00:00<00:00, 1471.84it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\rLoading weights:  33%|███▎      | 65/199 [00:00<00:00, 1469.44it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\rLoading weights:  33%|███▎      | 66/199 [00:00<00:00, 1487.06it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]    \rLoading weights:  33%|███▎      | 66/199 [00:00<00:00, 1484.60it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]\rLoading weights:  34%|███▎      | 67/199 [00:00<00:00, 1502.67it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\rLoading weights:  34%|███▎      | 67/199 [00:00<00:00, 1500.12it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\rLoading weights:  34%|███▍      | 68/199 [00:00<00:00, 1518.16it/s, Materializing param=encoder.layer.3.output.dense.bias]      \rLoading weights:  34%|███▍      | 68/199 [00:00<00:00, 1515.63it/s, Materializing param=encoder.layer.3.output.dense.bias]\rLoading weights:  35%|███▍      | 69/199 [00:00<00:00, 1533.34it/s, Materializing param=encoder.layer.3.output.dense.weight]\rLoading weights:  35%|███▍      | 69/199 [00:00<00:00, 1531.07it/s, Materializing param=encoder.layer.3.output.dense.weight]\rLoading weights:  35%|███▌      | 70/199 [00:00<00:00, 1548.86it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\rLoading weights:  35%|███▌      | 70/199 [00:00<00:00, 1546.62it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\rLoading weights:  36%|███▌      | 71/199 [00:00<00:00, 1564.15it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\rLoading weights:  36%|███▌      | 71/199 [00:00<00:00, 1560.62it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\rLoading weights:  36%|███▌      | 72/199 [00:00<00:00, 1578.00it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]      \rLoading weights:  36%|███▌      | 72/199 [00:00<00:00, 1575.32it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]\rLoading weights:  37%|███▋      | 73/199 [00:00<00:00, 1591.87it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\rLoading weights:  37%|███▋      | 73/199 [00:00<00:00, 1589.54it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\rLoading weights:  37%|███▋      | 74/199 [00:00<00:00, 1606.82it/s, Materializing param=encoder.layer.4.attention.self.key.bias]      \rLoading weights:  37%|███▋      | 74/199 [00:00<00:00, 1604.34it/s, Materializing param=encoder.layer.4.attention.self.key.bias]\rLoading weights:  38%|███▊      | 75/199 [00:00<00:00, 1621.98it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\rLoading weights:  38%|███▊      | 75/199 [00:00<00:00, 1619.66it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\rLoading weights:  38%|███▊      | 76/199 [00:00<00:00, 1636.90it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\rLoading weights:  38%|███▊      | 76/199 [00:00<00:00, 1634.53it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\rLoading weights:  39%|███▊      | 77/199 [00:00<00:00, 1651.40it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\rLoading weights:  39%|███▊      | 77/199 [00:00<00:00, 1648.79it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\rLoading weights:  39%|███▉      | 78/199 [00:00<00:00, 1666.17it/s, Materializing param=encoder.layer.4.attention.self.value.bias]  \rLoading weights:  39%|███▉      | 78/199 [00:00<00:00, 1663.97it/s, Materializing param=encoder.layer.4.attention.self.value.bias]\rLoading weights:  40%|███▉      | 79/199 [00:00<00:00, 1680.48it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\rLoading weights:  40%|███▉      | 79/199 [00:00<00:00, 1677.97it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\rLoading weights:  40%|████      | 80/199 [00:00<00:00, 1693.86it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]    \rLoading weights:  40%|████      | 80/199 [00:00<00:00, 1691.25it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]\rLoading weights:  41%|████      | 81/199 [00:00<00:00, 1708.34it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\rLoading weights:  41%|████      | 81/199 [00:00<00:00, 1705.94it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\rLoading weights:  41%|████      | 82/199 [00:00<00:00, 1722.69it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]    \rLoading weights:  41%|████      | 82/199 [00:00<00:00, 1720.06it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]\rLoading weights:  42%|████▏     | 83/199 [00:00<00:00, 1736.37it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\rLoading weights:  42%|████▏     | 83/199 [00:00<00:00, 1733.85it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\rLoading weights:  42%|████▏     | 84/199 [00:00<00:00, 1750.67it/s, Materializing param=encoder.layer.4.output.dense.bias]      \rLoading weights:  42%|████▏     | 84/199 [00:00<00:00, 1748.23it/s, Materializing param=encoder.layer.4.output.dense.bias]\rLoading weights:  43%|████▎     | 85/199 [00:00<00:00, 1764.80it/s, Materializing param=encoder.layer.4.output.dense.weight]\rLoading weights:  43%|████▎     | 85/199 [00:00<00:00, 1762.39it/s, Materializing param=encoder.layer.4.output.dense.weight]\rLoading weights:  43%|████▎     | 86/199 [00:00<00:00, 1778.24it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\rLoading weights:  43%|████▎     | 86/199 [00:00<00:00, 1775.68it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\rLoading weights:  44%|████▎     | 87/199 [00:00<00:00, 1791.55it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\rLoading weights:  44%|████▎     | 87/199 [00:00<00:00, 1789.09it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\rLoading weights:  44%|████▍     | 88/199 [00:00<00:00, 1805.09it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]      \rLoading weights:  44%|████▍     | 88/199 [00:00<00:00, 1802.63it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]\rLoading weights:  45%|████▍     | 89/199 [00:00<00:00, 1818.39it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\rLoading weights:  45%|████▍     | 89/199 [00:00<00:00, 1815.87it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\rLoading weights:  45%|████▌     | 90/199 [00:00<00:00, 1831.05it/s, Materializing param=encoder.layer.5.attention.self.key.bias]      \rLoading weights:  45%|████▌     | 90/199 [00:00<00:00, 1828.50it/s, Materializing param=encoder.layer.5.attention.self.key.bias]\rLoading weights:  46%|████▌     | 91/199 [00:00<00:00, 1843.63it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\rLoading weights:  46%|████▌     | 91/199 [00:00<00:00, 1840.55it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\rLoading weights:  46%|████▌     | 92/199 [00:00<00:00, 1854.84it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\rLoading weights:  46%|████▌     | 92/199 [00:00<00:00, 1852.26it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\rLoading weights:  47%|████▋     | 93/199 [00:00<00:00, 1867.03it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\rLoading weights:  47%|████▋     | 93/199 [00:00<00:00, 1864.43it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\rLoading weights:  47%|████▋     | 94/199 [00:00<00:00, 1879.38it/s, Materializing param=encoder.layer.5.attention.self.value.bias]  \rLoading weights:  47%|████▋     | 94/199 [00:00<00:00, 1876.60it/s, Materializing param=encoder.layer.5.attention.self.value.bias]\rLoading weights:  48%|████▊     | 95/199 [00:00<00:00, 1891.26it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\rLoading weights:  48%|████▊     | 95/199 [00:00<00:00, 1888.38it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\rLoading weights:  48%|████▊     | 96/199 [00:00<00:00, 1902.52it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]    \rLoading weights:  48%|████▊     | 96/199 [00:00<00:00, 1899.61it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]\rLoading weights:  49%|████▊     | 97/199 [00:00<00:00, 1913.91it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\rLoading weights:  49%|████▊     | 97/199 [00:00<00:00, 1911.14it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\rLoading weights:  49%|████▉     | 98/199 [00:00<00:00, 1926.30it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]    \rLoading weights:  49%|████▉     | 98/199 [00:00<00:00, 1923.43it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]\rLoading weights:  50%|████▉     | 99/199 [00:00<00:00, 1937.48it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\rLoading weights:  50%|████▉     | 99/199 [00:00<00:00, 1934.89it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\rLoading weights:  50%|█████     | 100/199 [00:00<00:00, 1948.91it/s, Materializing param=encoder.layer.5.output.dense.bias]     \rLoading weights:  50%|█████     | 100/199 [00:00<00:00, 1946.31it/s, Materializing param=encoder.layer.5.output.dense.bias]\rLoading weights:  51%|█████     | 101/199 [00:00<00:00, 1960.43it/s, Materializing param=encoder.layer.5.output.dense.weight]\rLoading weights:  51%|█████     | 101/199 [00:00<00:00, 1957.88it/s, Materializing param=encoder.layer.5.output.dense.weight]\rLoading weights:  51%|█████▏    | 102/199 [00:00<00:00, 1972.83it/s, Materializing param=encoder.layer.6.attention.output.LayerNorm.bias]\rLoading weights:  51%|█████▏    | 102/199 [00:00<00:00, 1970.33it/s, Materializing param=encoder.layer.6.attention.output.LayerNorm.bias]\rLoading weights:  52%|█████▏    | 103/199 [00:00<00:00, 1984.23it/s, Materializing param=encoder.layer.6.attention.output.LayerNorm.weight]\rLoading weights:  52%|█████▏    | 103/199 [00:00<00:00, 1981.69it/s, Materializing param=encoder.layer.6.attention.output.LayerNorm.weight]\rLoading weights:  52%|█████▏    | 104/199 [00:00<00:00, 1996.25it/s, Materializing param=encoder.layer.6.attention.output.dense.bias]      \rLoading weights:  52%|█████▏    | 104/199 [00:00<00:00, 1993.56it/s, Materializing param=encoder.layer.6.attention.output.dense.bias]\rLoading weights:  53%|█████▎    | 105/199 [00:00<00:00, 2007.30it/s, Materializing param=encoder.layer.6.attention.output.dense.weight]\rLoading weights:  53%|█████▎    | 105/199 [00:00<00:00, 2004.63it/s, Materializing param=encoder.layer.6.attention.output.dense.weight]\rLoading weights:  53%|█████▎    | 106/199 [00:00<00:00, 2018.77it/s, Materializing param=encoder.layer.6.attention.self.key.bias]      \rLoading weights:  53%|█████▎    | 106/199 [00:00<00:00, 2015.82it/s, Materializing param=encoder.layer.6.attention.self.key.bias]\rLoading weights:  54%|█████▍    | 107/199 [00:00<00:00, 2029.23it/s, Materializing param=encoder.layer.6.attention.self.key.weight]\rLoading weights:  54%|█████▍    | 107/199 [00:00<00:00, 2026.54it/s, Materializing param=encoder.layer.6.attention.self.key.weight]\rLoading weights:  54%|█████▍    | 108/199 [00:00<00:00, 2039.94it/s, Materializing param=encoder.layer.6.attention.self.query.bias]\rLoading weights:  54%|█████▍    | 108/199 [00:00<00:00, 2037.31it/s, Materializing param=encoder.layer.6.attention.self.query.bias]\rLoading weights:  55%|█████▍    | 109/199 [00:00<00:00, 2050.63it/s, Materializing param=encoder.layer.6.attention.self.query.weight]\rLoading weights:  55%|█████▍    | 109/199 [00:00<00:00, 2047.92it/s, Materializing param=encoder.layer.6.attention.self.query.weight]\rLoading weights:  55%|█████▌    | 110/199 [00:00<00:00, 2062.00it/s, Materializing param=encoder.layer.6.attention.self.value.bias]  \rLoading weights:  55%|█████▌    | 110/199 [00:00<00:00, 2058.38it/s, Materializing param=encoder.layer.6.attention.self.value.bias]\rLoading weights:  56%|█████▌    | 111/199 [00:00<00:00, 2071.66it/s, Materializing param=encoder.layer.6.attention.self.value.weight]\rLoading weights:  56%|█████▌    | 111/199 [00:00<00:00, 2069.21it/s, Materializing param=encoder.layer.6.attention.self.value.weight]\rLoading weights:  56%|█████▋    | 112/199 [00:00<00:00, 2083.02it/s, Materializing param=encoder.layer.6.intermediate.dense.bias]    \rLoading weights:  56%|█████▋    | 112/199 [00:00<00:00, 2080.58it/s, Materializing param=encoder.layer.6.intermediate.dense.bias]\rLoading weights:  57%|█████▋    | 113/199 [00:00<00:00, 2094.44it/s, Materializing param=encoder.layer.6.intermediate.dense.weight]\rLoading weights:  57%|█████▋    | 113/199 [00:00<00:00, 2091.99it/s, Materializing param=encoder.layer.6.intermediate.dense.weight]\rLoading weights:  57%|█████▋    | 114/199 [00:00<00:00, 2104.98it/s, Materializing param=encoder.layer.6.output.LayerNorm.bias]    \rLoading weights:  57%|█████▋    | 114/199 [00:00<00:00, 2101.50it/s, Materializing param=encoder.layer.6.output.LayerNorm.bias]\rLoading weights:  58%|█████▊    | 115/199 [00:00<00:00, 2113.33it/s, Materializing param=encoder.layer.6.output.LayerNorm.weight]\rLoading weights:  58%|█████▊    | 115/199 [00:00<00:00, 2111.06it/s, Materializing param=encoder.layer.6.output.LayerNorm.weight]\rLoading weights:  58%|█████▊    | 116/199 [00:00<00:00, 2125.48it/s, Materializing param=encoder.layer.6.output.dense.bias]      \rLoading weights:  58%|█████▊    | 116/199 [00:00<00:00, 2123.69it/s, Materializing param=encoder.layer.6.output.dense.bias]\rLoading weights:  59%|█████▉    | 117/199 [00:00<00:00, 2138.34it/s, Materializing param=encoder.layer.6.output.dense.weight]\rLoading weights:  59%|█████▉    | 117/199 [00:00<00:00, 2136.41it/s, Materializing param=encoder.layer.6.output.dense.weight]\rLoading weights:  59%|█████▉    | 118/199 [00:00<00:00, 2151.24it/s, Materializing param=encoder.layer.7.attention.output.LayerNorm.bias]\rLoading weights:  59%|█████▉    | 118/199 [00:00<00:00, 2149.38it/s, Materializing param=encoder.layer.7.attention.output.LayerNorm.bias]\rLoading weights:  60%|█████▉    | 119/199 [00:00<00:00, 2163.60it/s, Materializing param=encoder.layer.7.attention.output.LayerNorm.weight]\rLoading weights:  60%|█████▉    | 119/199 [00:00<00:00, 2161.68it/s, Materializing param=encoder.layer.7.attention.output.LayerNorm.weight]\rLoading weights:  60%|██████    | 120/199 [00:00<00:00, 2176.05it/s, Materializing param=encoder.layer.7.attention.output.dense.bias]      \rLoading weights:  60%|██████    | 120/199 [00:00<00:00, 2174.09it/s, Materializing param=encoder.layer.7.attention.output.dense.bias]\rLoading weights:  61%|██████    | 121/199 [00:00<00:00, 2188.68it/s, Materializing param=encoder.layer.7.attention.output.dense.weight]\rLoading weights:  61%|██████    | 121/199 [00:00<00:00, 2186.75it/s, Materializing param=encoder.layer.7.attention.output.dense.weight]\rLoading weights:  61%|██████▏   | 122/199 [00:00<00:00, 2201.25it/s, Materializing param=encoder.layer.7.attention.self.key.bias]      \rLoading weights:  61%|██████▏   | 122/199 [00:00<00:00, 2199.36it/s, Materializing param=encoder.layer.7.attention.self.key.bias]\rLoading weights:  62%|██████▏   | 123/199 [00:00<00:00, 2213.73it/s, Materializing param=encoder.layer.7.attention.self.key.weight]\rLoading weights:  62%|██████▏   | 123/199 [00:00<00:00, 2211.81it/s, Materializing param=encoder.layer.7.attention.self.key.weight]\rLoading weights:  62%|██████▏   | 124/199 [00:00<00:00, 2226.26it/s, Materializing param=encoder.layer.7.attention.self.query.bias]\rLoading weights:  62%|██████▏   | 124/199 [00:00<00:00, 2224.22it/s, Materializing param=encoder.layer.7.attention.self.query.bias]\rLoading weights:  63%|██████▎   | 125/199 [00:00<00:00, 2238.60it/s, Materializing param=encoder.layer.7.attention.self.query.weight]\rLoading weights:  63%|██████▎   | 125/199 [00:00<00:00, 2236.67it/s, Materializing param=encoder.layer.7.attention.self.query.weight]\rLoading weights:  63%|██████▎   | 126/199 [00:00<00:00, 2251.04it/s, Materializing param=encoder.layer.7.attention.self.value.bias]  \rLoading weights:  63%|██████▎   | 126/199 [00:00<00:00, 2249.08it/s, Materializing param=encoder.layer.7.attention.self.value.bias]\rLoading weights:  64%|██████▍   | 127/199 [00:00<00:00, 2263.39it/s, Materializing param=encoder.layer.7.attention.self.value.weight]\rLoading weights:  64%|██████▍   | 127/199 [00:00<00:00, 2261.44it/s, Materializing param=encoder.layer.7.attention.self.value.weight]\rLoading weights:  64%|██████▍   | 128/199 [00:00<00:00, 2275.79it/s, Materializing param=encoder.layer.7.intermediate.dense.bias]    \rLoading weights:  64%|██████▍   | 128/199 [00:00<00:00, 2273.73it/s, Materializing param=encoder.layer.7.intermediate.dense.bias]\rLoading weights:  65%|██████▍   | 129/199 [00:00<00:00, 2287.92it/s, Materializing param=encoder.layer.7.intermediate.dense.weight]\rLoading weights:  65%|██████▍   | 129/199 [00:00<00:00, 2285.96it/s, Materializing param=encoder.layer.7.intermediate.dense.weight]\rLoading weights:  65%|██████▌   | 130/199 [00:00<00:00, 2300.17it/s, Materializing param=encoder.layer.7.output.LayerNorm.bias]    \rLoading weights:  65%|██████▌   | 130/199 [00:00<00:00, 2298.22it/s, Materializing param=encoder.layer.7.output.LayerNorm.bias]\rLoading weights:  66%|██████▌   | 131/199 [00:00<00:00, 2312.28it/s, Materializing param=encoder.layer.7.output.LayerNorm.weight]\rLoading weights:  66%|██████▌   | 131/199 [00:00<00:00, 2310.32it/s, Materializing param=encoder.layer.7.output.LayerNorm.weight]\rLoading weights:  66%|██████▋   | 132/199 [00:00<00:00, 2324.40it/s, Materializing param=encoder.layer.7.output.dense.bias]      \rLoading weights:  66%|██████▋   | 132/199 [00:00<00:00, 2322.47it/s, Materializing param=encoder.layer.7.output.dense.bias]\rLoading weights:  67%|██████▋   | 133/199 [00:00<00:00, 2336.50it/s, Materializing param=encoder.layer.7.output.dense.weight]\rLoading weights:  67%|██████▋   | 133/199 [00:00<00:00, 2334.51it/s, Materializing param=encoder.layer.7.output.dense.weight]\rLoading weights:  67%|██████▋   | 134/199 [00:00<00:00, 2348.15it/s, Materializing param=encoder.layer.8.attention.output.LayerNorm.bias]\rLoading weights:  67%|██████▋   | 134/199 [00:00<00:00, 2346.11it/s, Materializing param=encoder.layer.8.attention.output.LayerNorm.bias]\rLoading weights:  68%|██████▊   | 135/199 [00:00<00:00, 2359.76it/s, Materializing param=encoder.layer.8.attention.output.LayerNorm.weight]\rLoading weights:  68%|██████▊   | 135/199 [00:00<00:00, 2357.80it/s, Materializing param=encoder.layer.8.attention.output.LayerNorm.weight]\rLoading weights:  68%|██████▊   | 136/199 [00:00<00:00, 2371.05it/s, Materializing param=encoder.layer.8.attention.output.dense.bias]      \rLoading weights:  68%|██████▊   | 136/199 [00:00<00:00, 2369.03it/s, Materializing param=encoder.layer.8.attention.output.dense.bias]\rLoading weights:  69%|██████▉   | 137/199 [00:00<00:00, 2202.65it/s, Materializing param=encoder.layer.8.attention.output.dense.weight]\rLoading weights:  69%|██████▉   | 137/199 [00:00<00:00, 2200.80it/s, Materializing param=encoder.layer.8.attention.output.dense.weight]\rLoading weights:  69%|██████▉   | 138/199 [00:00<00:00, 2213.11it/s, Materializing param=encoder.layer.8.attention.self.key.bias]      \rLoading weights:  69%|██████▉   | 138/199 [00:00<00:00, 2211.38it/s, Materializing param=encoder.layer.8.attention.self.key.bias]\rLoading weights:  70%|██████▉   | 139/199 [00:00<00:00, 2223.75it/s, Materializing param=encoder.layer.8.attention.self.key.weight]\rLoading weights:  70%|██████▉   | 139/199 [00:00<00:00, 2222.08it/s, Materializing param=encoder.layer.8.attention.self.key.weight]\rLoading weights:  70%|███████   | 140/199 [00:00<00:00, 2234.71it/s, Materializing param=encoder.layer.8.attention.self.query.bias]\rLoading weights:  70%|███████   | 140/199 [00:00<00:00, 2233.09it/s, Materializing param=encoder.layer.8.attention.self.query.bias]\rLoading weights:  71%|███████   | 141/199 [00:00<00:00, 2245.71it/s, Materializing param=encoder.layer.8.attention.self.query.weight]\rLoading weights:  71%|███████   | 141/199 [00:00<00:00, 2244.07it/s, Materializing param=encoder.layer.8.attention.self.query.weight]\rLoading weights:  71%|███████▏  | 142/199 [00:00<00:00, 2256.47it/s, Materializing param=encoder.layer.8.attention.self.value.bias]  \rLoading weights:  71%|███████▏  | 142/199 [00:00<00:00, 2254.70it/s, Materializing param=encoder.layer.8.attention.self.value.bias]\rLoading weights:  72%|███████▏  | 143/199 [00:00<00:00, 2266.83it/s, Materializing param=encoder.layer.8.attention.self.value.weight]\rLoading weights:  72%|███████▏  | 143/199 [00:00<00:00, 2265.09it/s, Materializing param=encoder.layer.8.attention.self.value.weight]\rLoading weights:  72%|███████▏  | 144/199 [00:00<00:00, 2277.54it/s, Materializing param=encoder.layer.8.intermediate.dense.bias]    \rLoading weights:  72%|███████▏  | 144/199 [00:00<00:00, 2275.82it/s, Materializing param=encoder.layer.8.intermediate.dense.bias]\rLoading weights:  73%|███████▎  | 145/199 [00:00<00:00, 2288.04it/s, Materializing param=encoder.layer.8.intermediate.dense.weight]\rLoading weights:  73%|███████▎  | 145/199 [00:00<00:00, 2286.29it/s, Materializing param=encoder.layer.8.intermediate.dense.weight]\rLoading weights:  73%|███████▎  | 146/199 [00:00<00:00, 2298.76it/s, Materializing param=encoder.layer.8.output.LayerNorm.bias]    \rLoading weights:  73%|███████▎  | 146/199 [00:00<00:00, 2297.07it/s, Materializing param=encoder.layer.8.output.LayerNorm.bias]\rLoading weights:  74%|███████▍  | 147/199 [00:00<00:00, 2309.44it/s, Materializing param=encoder.layer.8.output.LayerNorm.weight]\rLoading weights:  74%|███████▍  | 147/199 [00:00<00:00, 2307.79it/s, Materializing param=encoder.layer.8.output.LayerNorm.weight]\rLoading weights:  74%|███████▍  | 148/199 [00:00<00:00, 2320.21it/s, Materializing param=encoder.layer.8.output.dense.bias]      \rLoading weights:  74%|███████▍  | 148/199 [00:00<00:00, 2318.50it/s, Materializing param=encoder.layer.8.output.dense.bias]\rLoading weights:  75%|███████▍  | 149/199 [00:00<00:00, 2330.67it/s, Materializing param=encoder.layer.8.output.dense.weight]\rLoading weights:  75%|███████▍  | 149/199 [00:00<00:00, 2328.91it/s, Materializing param=encoder.layer.8.output.dense.weight]\rLoading weights:  75%|███████▌  | 150/199 [00:00<00:00, 2340.77it/s, Materializing param=encoder.layer.9.attention.output.LayerNorm.bias]\rLoading weights:  75%|███████▌  | 150/199 [00:00<00:00, 2338.93it/s, Materializing param=encoder.layer.9.attention.output.LayerNorm.bias]\rLoading weights:  76%|███████▌  | 151/199 [00:00<00:00, 2350.51it/s, Materializing param=encoder.layer.9.attention.output.LayerNorm.weight]\rLoading weights:  76%|███████▌  | 151/199 [00:00<00:00, 2348.59it/s, Materializing param=encoder.layer.9.attention.output.LayerNorm.weight]\rLoading weights:  76%|███████▋  | 152/199 [00:00<00:00, 2360.11it/s, Materializing param=encoder.layer.9.attention.output.dense.bias]      \rLoading weights:  76%|███████▋  | 152/199 [00:00<00:00, 2358.26it/s, Materializing param=encoder.layer.9.attention.output.dense.bias]\rLoading weights:  77%|███████▋  | 153/199 [00:00<00:00, 2369.84it/s, Materializing param=encoder.layer.9.attention.output.dense.weight]\rLoading weights:  77%|███████▋  | 153/199 [00:00<00:00, 2367.98it/s, Materializing param=encoder.layer.9.attention.output.dense.weight]\rLoading weights:  77%|███████▋  | 154/199 [00:00<00:00, 2379.55it/s, Materializing param=encoder.layer.9.attention.self.key.bias]      \rLoading weights:  77%|███████▋  | 154/199 [00:00<00:00, 2377.64it/s, Materializing param=encoder.layer.9.attention.self.key.bias]\rLoading weights:  78%|███████▊  | 155/199 [00:00<00:00, 2388.95it/s, Materializing param=encoder.layer.9.attention.self.key.weight]\rLoading weights:  78%|███████▊  | 155/199 [00:00<00:00, 2387.06it/s, Materializing param=encoder.layer.9.attention.self.key.weight]\rLoading weights:  78%|███████▊  | 156/199 [00:00<00:00, 2398.46it/s, Materializing param=encoder.layer.9.attention.self.query.bias]\rLoading weights:  78%|███████▊  | 156/199 [00:00<00:00, 2396.60it/s, Materializing param=encoder.layer.9.attention.self.query.bias]\rLoading weights:  79%|███████▉  | 157/199 [00:00<00:00, 2407.89it/s, Materializing param=encoder.layer.9.attention.self.query.weight]\rLoading weights:  79%|███████▉  | 157/199 [00:00<00:00, 2406.03it/s, Materializing param=encoder.layer.9.attention.self.query.weight]\rLoading weights:  79%|███████▉  | 158/199 [00:00<00:00, 2417.42it/s, Materializing param=encoder.layer.9.attention.self.value.bias]  \rLoading weights:  79%|███████▉  | 158/199 [00:00<00:00, 2415.60it/s, Materializing param=encoder.layer.9.attention.self.value.bias]\rLoading weights:  80%|███████▉  | 159/199 [00:00<00:00, 2426.06it/s, Materializing param=encoder.layer.9.attention.self.value.weight]\rLoading weights:  80%|███████▉  | 159/199 [00:00<00:00, 2424.16it/s, Materializing param=encoder.layer.9.attention.self.value.weight]\rLoading weights:  80%|████████  | 160/199 [00:00<00:00, 2435.43it/s, Materializing param=encoder.layer.9.intermediate.dense.bias]    \rLoading weights:  80%|████████  | 160/199 [00:00<00:00, 2433.55it/s, Materializing param=encoder.layer.9.intermediate.dense.bias]\rLoading weights:  81%|████████  | 161/199 [00:00<00:00, 2444.86it/s, Materializing param=encoder.layer.9.intermediate.dense.weight]\rLoading weights:  81%|████████  | 161/199 [00:00<00:00, 2443.00it/s, Materializing param=encoder.layer.9.intermediate.dense.weight]\rLoading weights:  81%|████████▏ | 162/199 [00:00<00:00, 2454.29it/s, Materializing param=encoder.layer.9.output.LayerNorm.bias]    \rLoading weights:  81%|████████▏ | 162/199 [00:00<00:00, 2452.44it/s, Materializing param=encoder.layer.9.output.LayerNorm.bias]\rLoading weights:  82%|████████▏ | 163/199 [00:00<00:00, 2463.57it/s, Materializing param=encoder.layer.9.output.LayerNorm.weight]\rLoading weights:  82%|████████▏ | 163/199 [00:00<00:00, 2461.67it/s, Materializing param=encoder.layer.9.output.LayerNorm.weight]\rLoading weights:  82%|████████▏ | 164/199 [00:00<00:00, 2472.71it/s, Materializing param=encoder.layer.9.output.dense.bias]      \rLoading weights:  82%|████████▏ | 164/199 [00:00<00:00, 2470.85it/s, Materializing param=encoder.layer.9.output.dense.bias]\rLoading weights:  83%|████████▎ | 165/199 [00:00<00:00, 2481.92it/s, Materializing param=encoder.layer.9.output.dense.weight]\rLoading weights:  83%|████████▎ | 165/199 [00:00<00:00, 2480.07it/s, Materializing param=encoder.layer.9.output.dense.weight]\rLoading weights:  83%|████████▎ | 166/199 [00:00<00:00, 2490.98it/s, Materializing param=encoder.layer.10.attention.output.LayerNorm.bias]\rLoading weights:  83%|████████▎ | 166/199 [00:00<00:00, 2489.09it/s, Materializing param=encoder.layer.10.attention.output.LayerNorm.bias]\rLoading weights:  84%|████████▍ | 167/199 [00:00<00:00, 2500.05it/s, Materializing param=encoder.layer.10.attention.output.LayerNorm.weight]\rLoading weights:  84%|████████▍ | 167/199 [00:00<00:00, 2498.14it/s, Materializing param=encoder.layer.10.attention.output.LayerNorm.weight]\rLoading weights:  84%|████████▍ | 168/199 [00:00<00:00, 2509.08it/s, Materializing param=encoder.layer.10.attention.output.dense.bias]      \rLoading weights:  84%|████████▍ | 168/199 [00:00<00:00, 2507.18it/s, Materializing param=encoder.layer.10.attention.output.dense.bias]\rLoading weights:  85%|████████▍ | 169/199 [00:00<00:00, 2518.15it/s, Materializing param=encoder.layer.10.attention.output.dense.weight]\rLoading weights:  85%|████████▍ | 169/199 [00:00<00:00, 2516.28it/s, Materializing param=encoder.layer.10.attention.output.dense.weight]\rLoading weights:  85%|████████▌ | 170/199 [00:00<00:00, 2527.20it/s, Materializing param=encoder.layer.10.attention.self.key.bias]      \rLoading weights:  85%|████████▌ | 170/199 [00:00<00:00, 2525.34it/s, Materializing param=encoder.layer.10.attention.self.key.bias]\rLoading weights:  86%|████████▌ | 171/199 [00:00<00:00, 2536.21it/s, Materializing param=encoder.layer.10.attention.self.key.weight]\rLoading weights:  86%|████████▌ | 171/199 [00:00<00:00, 2534.31it/s, Materializing param=encoder.layer.10.attention.self.key.weight]\rLoading weights:  86%|████████▋ | 172/199 [00:00<00:00, 2545.11it/s, Materializing param=encoder.layer.10.attention.self.query.bias]\rLoading weights:  86%|████████▋ | 172/199 [00:00<00:00, 2543.20it/s, Materializing param=encoder.layer.10.attention.self.query.bias]\rLoading weights:  87%|████████▋ | 173/199 [00:00<00:00, 2553.98it/s, Materializing param=encoder.layer.10.attention.self.query.weight]\rLoading weights:  87%|████████▋ | 173/199 [00:00<00:00, 2552.10it/s, Materializing param=encoder.layer.10.attention.self.query.weight]\rLoading weights:  87%|████████▋ | 174/199 [00:00<00:00, 2562.83it/s, Materializing param=encoder.layer.10.attention.self.value.bias]  \rLoading weights:  87%|████████▋ | 174/199 [00:00<00:00, 2560.92it/s, Materializing param=encoder.layer.10.attention.self.value.bias]\rLoading weights:  88%|████████▊ | 175/199 [00:00<00:00, 2571.53it/s, Materializing param=encoder.layer.10.attention.self.value.weight]\rLoading weights:  88%|████████▊ | 175/199 [00:00<00:00, 2569.52it/s, Materializing param=encoder.layer.10.attention.self.value.weight]\rLoading weights:  88%|████████▊ | 176/199 [00:00<00:00, 2580.08it/s, Materializing param=encoder.layer.10.intermediate.dense.bias]    \rLoading weights:  88%|████████▊ | 176/199 [00:00<00:00, 2578.14it/s, Materializing param=encoder.layer.10.intermediate.dense.bias]\rLoading weights:  89%|████████▉ | 177/199 [00:00<00:00, 2588.82it/s, Materializing param=encoder.layer.10.intermediate.dense.weight]\rLoading weights:  89%|████████▉ | 177/199 [00:00<00:00, 2586.90it/s, Materializing param=encoder.layer.10.intermediate.dense.weight]\rLoading weights:  89%|████████▉ | 178/199 [00:00<00:00, 2597.59it/s, Materializing param=encoder.layer.10.output.LayerNorm.bias]    \rLoading weights:  89%|████████▉ | 178/199 [00:00<00:00, 2595.67it/s, Materializing param=encoder.layer.10.output.LayerNorm.bias]\rLoading weights:  90%|████████▉ | 179/199 [00:00<00:00, 2606.33it/s, Materializing param=encoder.layer.10.output.LayerNorm.weight]\rLoading weights:  90%|████████▉ | 179/199 [00:00<00:00, 2604.48it/s, Materializing param=encoder.layer.10.output.LayerNorm.weight]\rLoading weights:  90%|█████████ | 180/199 [00:00<00:00, 2615.19it/s, Materializing param=encoder.layer.10.output.dense.bias]      \rLoading weights:  90%|█████████ | 180/199 [00:00<00:00, 2613.25it/s, Materializing param=encoder.layer.10.output.dense.bias]\rLoading weights:  91%|█████████ | 181/199 [00:00<00:00, 2623.84it/s, Materializing param=encoder.layer.10.output.dense.weight]\rLoading weights:  91%|█████████ | 181/199 [00:00<00:00, 2621.95it/s, Materializing param=encoder.layer.10.output.dense.weight]\rLoading weights:  91%|█████████▏| 182/199 [00:00<00:00, 2632.51it/s, Materializing param=encoder.layer.11.attention.output.LayerNorm.bias]\rLoading weights:  91%|█████████▏| 182/199 [00:00<00:00, 2630.59it/s, Materializing param=encoder.layer.11.attention.output.LayerNorm.bias]\rLoading weights:  92%|█████████▏| 183/199 [00:00<00:00, 2640.83it/s, Materializing param=encoder.layer.11.attention.output.LayerNorm.weight]\rLoading weights:  92%|█████████▏| 183/199 [00:00<00:00, 2638.89it/s, Materializing param=encoder.layer.11.attention.output.LayerNorm.weight]\rLoading weights:  92%|█████████▏| 184/199 [00:00<00:00, 2648.76it/s, Materializing param=encoder.layer.11.attention.output.dense.bias]      \rLoading weights:  92%|█████████▏| 184/199 [00:00<00:00, 2646.70it/s, Materializing param=encoder.layer.11.attention.output.dense.bias]\rLoading weights:  93%|█████████▎| 185/199 [00:00<00:00, 2656.90it/s, Materializing param=encoder.layer.11.attention.output.dense.weight]\rLoading weights:  93%|█████████▎| 185/199 [00:00<00:00, 2655.00it/s, Materializing param=encoder.layer.11.attention.output.dense.weight]\rLoading weights:  93%|█████████▎| 186/199 [00:00<00:00, 2665.59it/s, Materializing param=encoder.layer.11.attention.self.key.bias]      \rLoading weights:  93%|█████████▎| 186/199 [00:00<00:00, 2663.70it/s, Materializing param=encoder.layer.11.attention.self.key.bias]\rLoading weights:  94%|█████████▍| 187/199 [00:00<00:00, 2674.05it/s, Materializing param=encoder.layer.11.attention.self.key.weight]\rLoading weights:  94%|█████████▍| 187/199 [00:00<00:00, 2672.11it/s, Materializing param=encoder.layer.11.attention.self.key.weight]\rLoading weights:  94%|█████████▍| 188/199 [00:00<00:00, 2682.37it/s, Materializing param=encoder.layer.11.attention.self.query.bias]\rLoading weights:  94%|█████████▍| 188/199 [00:00<00:00, 2680.47it/s, Materializing param=encoder.layer.11.attention.self.query.bias]\rLoading weights:  95%|█████████▍| 189/199 [00:00<00:00, 2690.62it/s, Materializing param=encoder.layer.11.attention.self.query.weight]\rLoading weights:  95%|█████████▍| 189/199 [00:00<00:00, 2688.66it/s, Materializing param=encoder.layer.11.attention.self.query.weight]\rLoading weights:  95%|█████████▌| 190/199 [00:00<00:00, 2698.83it/s, Materializing param=encoder.layer.11.attention.self.value.bias]  \rLoading weights:  95%|█████████▌| 190/199 [00:00<00:00, 2696.88it/s, Materializing param=encoder.layer.11.attention.self.value.bias]\rLoading weights:  96%|█████████▌| 191/199 [00:00<00:00, 2706.94it/s, Materializing param=encoder.layer.11.attention.self.value.weight]\rLoading weights:  96%|█████████▌| 191/199 [00:00<00:00, 2705.04it/s, Materializing param=encoder.layer.11.attention.self.value.weight]\rLoading weights:  96%|█████████▋| 192/199 [00:00<00:00, 2715.47it/s, Materializing param=encoder.layer.11.intermediate.dense.bias]    \rLoading weights:  96%|█████████▋| 192/199 [00:00<00:00, 2713.61it/s, Materializing param=encoder.layer.11.intermediate.dense.bias]\rLoading weights:  97%|█████████▋| 193/199 [00:00<00:00, 2724.04it/s, Materializing param=encoder.layer.11.intermediate.dense.weight]\rLoading weights:  97%|█████████▋| 193/199 [00:00<00:00, 2722.14it/s, Materializing param=encoder.layer.11.intermediate.dense.weight]\rLoading weights:  97%|█████████▋| 194/199 [00:00<00:00, 2732.28it/s, Materializing param=encoder.layer.11.output.LayerNorm.bias]    \rLoading weights:  97%|█████████▋| 194/199 [00:00<00:00, 2730.36it/s, Materializing param=encoder.layer.11.output.LayerNorm.bias]\rLoading weights:  98%|█████████▊| 195/199 [00:00<00:00, 2740.63it/s, Materializing param=encoder.layer.11.output.LayerNorm.weight]\rLoading weights:  98%|█████████▊| 195/199 [00:00<00:00, 2738.75it/s, Materializing param=encoder.layer.11.output.LayerNorm.weight]\rLoading weights:  98%|█████████▊| 196/199 [00:00<00:00, 2748.87it/s, Materializing param=encoder.layer.11.output.dense.bias]      \rLoading weights:  98%|█████████▊| 196/199 [00:00<00:00, 2746.98it/s, Materializing param=encoder.layer.11.output.dense.bias]\rLoading weights:  99%|█████████▉| 197/199 [00:00<00:00, 2757.08it/s, Materializing param=encoder.layer.11.output.dense.weight]\rLoading weights:  99%|█████████▉| 197/199 [00:00<00:00, 2755.19it/s, Materializing param=encoder.layer.11.output.dense.weight]\rLoading weights:  99%|█████████▉| 198/199 [00:00<00:00, 2765.26it/s, Materializing param=pooler.dense.bias]                   \rLoading weights:  99%|█████████▉| 198/199 [00:00<00:00, 2763.40it/s, Materializing param=pooler.dense.bias]\rLoading weights: 100%|██████████| 199/199 [00:00<00:00, 2773.32it/s, Materializing param=pooler.dense.weight]\rLoading weights: 100%|██████████| 199/199 [00:00<00:00, 2771.46it/s, Materializing param=pooler.dense.weight]\rLoading weights: 100%|██████████| 199/199 [00:00<00:00, 2766.50it/s, Materializing param=pooler.dense.weight]\n\u001b[1mXLMRobertaModel LOAD REPORT\u001b[0m from: xlm-roberta-base\nKey                       | Status     |  | \n--------------------------+------------+--+-\nlm_head.layer_norm.weight | UNEXPECTED |  | \nlm_head.bias              | UNEXPECTED |  | \nlm_head.layer_norm.bias   | UNEXPECTED |  | \nlm_head.dense.bias        | UNEXPECTED |  | \nlm_head.dense.weight      | UNEXPECTED |  | \n\n\u001b[3mNotes:\n- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n2026-02-15 19:46:48,541 | INFO | Polysemy lexicon size: 3726\n\rStatic sim:   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim:  19%|█▉        | 385/2000 [00:00<00:00, 3841.70it/s]\rStatic sim:  39%|███▉      | 780/2000 [00:00<00:00, 3901.97it/s]\rStatic sim:  59%|█████▉    | 1185/2000 [00:00<00:00, 3965.22it/s]\rStatic sim:  79%|███████▉  | 1582/2000 [00:00<00:00, 3952.86it/s]\rStatic sim:  99%|█████████▉| 1978/2000 [00:00<00:00, 3892.45it/s]\rStatic sim: 100%|██████████| 2000/2000 [00:00<00:00, 3908.49it/s]\n\rStatic sim (mismatch):   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim (mismatch):  21%|██        | 420/2000 [00:00<00:00, 4198.93it/s]\rStatic sim (mismatch):  42%|████▏     | 845/2000 [00:00<00:00, 4227.39it/s]\rStatic sim (mismatch):  63%|██████▎   | 1268/2000 [00:00<00:00, 4197.32it/s]\rStatic sim (mismatch):  85%|████████▍ | 1698/2000 [00:00<00:00, 4236.98it/s]\rStatic sim (mismatch): 100%|██████████| 2000/2000 [00:00<00:00, 4247.65it/s]\n\rStatic sim:   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim:  20%|█▉        | 397/2000 [00:00<00:00, 3961.94it/s]\rStatic sim:  41%|████      | 815/2000 [00:00<00:00, 4086.97it/s]\rStatic sim:  61%|██████▏   | 1225/2000 [00:00<00:00, 4089.73it/s]\rStatic sim:  82%|████████▏ | 1643/2000 [00:00<00:00, 4122.91it/s]\rStatic sim: 100%|██████████| 2000/2000 [00:00<00:00, 4100.74it/s]\n\rStatic sim (mismatch):   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim (mismatch):  21%|██        | 411/2000 [00:00<00:00, 4105.55it/s]\rStatic sim (mismatch):  41%|████▏     | 826/2000 [00:00<00:00, 4129.81it/s]\rStatic sim (mismatch):  62%|██████▎   | 1250/2000 [00:00<00:00, 4176.99it/s]\rStatic sim (mismatch):  84%|████████▍ | 1687/2000 [00:00<00:00, 4238.34it/s]\rStatic sim (mismatch): 100%|██████████| 2000/2000 [00:00<00:00, 4229.28it/s]\n\rStatic sim:   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim:  21%|██▏       | 427/2000 [00:00<00:00, 4263.95it/s]\rStatic sim:  43%|████▎     | 854/2000 [00:00<00:00, 4162.13it/s]\rStatic sim:  64%|██████▍   | 1278/2000 [00:00<00:00, 4195.63it/s]\rStatic sim:  85%|████████▍ | 1698/2000 [00:00<00:00, 4136.11it/s]\rStatic sim: 100%|██████████| 2000/2000 [00:00<00:00, 4158.60it/s]\n\rStatic sim (mismatch):   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim (mismatch):  22%|██▏       | 440/2000 [00:00<00:00, 4392.15it/s]\rStatic sim (mismatch):  44%|████▍     | 884/2000 [00:00<00:00, 4415.81it/s]\rStatic sim (mismatch):  66%|██████▋   | 1326/2000 [00:00<00:00, 4414.36it/s]\rStatic sim (mismatch):  88%|████████▊ | 1769/2000 [00:00<00:00, 4419.24it/s]\rStatic sim (mismatch): 100%|██████████| 2000/2000 [00:00<00:00, 4414.20it/s]\n\rStatic sim:   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim:  20%|██        | 410/2000 [00:00<00:00, 4095.19it/s]\rStatic sim:  42%|████▏     | 832/2000 [00:00<00:00, 4166.36it/s]\rStatic sim:  63%|██████▎   | 1257/2000 [00:00<00:00, 4203.06it/s]\rStatic sim:  84%|████████▍ | 1682/2000 [00:00<00:00, 4221.08it/s]\rStatic sim: 100%|██████████| 2000/2000 [00:00<00:00, 4198.09it/s]\n\rStatic sim (mismatch):   0%|          | 0/2000 [00:00<?, ?it/s]\rStatic sim (mismatch):  21%|██▏       | 427/2000 [00:00<00:00, 4269.39it/s]\rStatic sim (mismatch):  44%|████▎     | 873/2000 [00:00<00:00, 4381.25it/s]\rStatic sim (mismatch):  66%|██████▌   | 1312/2000 [00:00<00:00, 4358.44it/s]\rStatic sim (mismatch):  87%|████████▋ | 1749/2000 [00:00<00:00, 4362.30it/s]\rStatic sim (mismatch): 100%|██████████| 2000/2000 [00:00<00:00, 4369.40it/s]\n\rContextual batches:   0%|          | 0/16 [00:00<?, ?it/s]\rContextual batches:   6%|▋         | 1/16 [00:00<00:04,  3.17it/s]\rContextual batches:  19%|█▉        | 3/16 [00:00<00:01,  6.72it/s]\rContextual batches:  31%|███▏      | 5/16 [00:00<00:01,  8.67it/s]\rContextual batches:  44%|████▍     | 7/16 [00:00<00:00, 11.04it/s]\rContextual batches:  56%|█████▋    | 9/16 [00:00<00:00, 12.31it/s]\rContextual batches:  69%|██████▉   | 11/16 [00:01<00:00, 12.79it/s]\rContextual batches:  81%|████████▏ | 13/16 [00:01<00:00, 13.42it/s]\rContextual batches:  94%|█████████▍| 15/16 [00:01<00:00, 14.09it/s]\rContextual batches: 100%|██████████| 16/16 [00:01<00:00, 11.61it/s]\n\rContextual batches:   0%|          | 0/16 [00:00<?, ?it/s]\rContextual batches:   6%|▋         | 1/16 [00:00<00:01,  7.96it/s]\rContextual batches:  19%|█▉        | 3/16 [00:00<00:01,  9.48it/s]\rContextual batches:  31%|███▏      | 5/16 [00:00<00:01,  9.57it/s]\rContextual batches:  44%|████▍     | 7/16 [00:00<00:00,  9.46it/s]\rContextual batches:  56%|█████▋    | 9/16 [00:00<00:00, 10.32it/s]\rContextual batches:  69%|██████▉   | 11/16 [00:01<00:00,  9.96it/s]\rContextual batches:  81%|████████▏ | 13/16 [00:01<00:00, 10.37it/s]\rContextual batches:  94%|█████████▍| 15/16 [00:01<00:00, 10.41it/s]\rContextual batches: 100%|██████████| 16/16 [00:01<00:00, 10.40it/s]\n\rContextual batches:   0%|          | 0/16 [00:00<?, ?it/s]\rContextual batches:  12%|█▎        | 2/16 [00:00<00:01, 12.71it/s]\rContextual batches:  25%|██▌       | 4/16 [00:00<00:00, 12.35it/s]\rContextual batches:  38%|███▊      | 6/16 [00:00<00:00, 12.62it/s]\rContextual batches:  50%|█████     | 8/16 [00:00<00:00, 13.50it/s]\rContextual batches:  62%|██████▎   | 10/16 [00:00<00:00, 13.79it/s]\rContextual batches:  75%|███████▌  | 12/16 [00:00<00:00, 14.29it/s]\rContextual batches:  88%|████████▊ | 14/16 [00:01<00:00, 14.44it/s]\rContextual batches: 100%|██████████| 16/16 [00:01<00:00, 14.45it/s]\n\rContextual batches:   0%|          | 0/16 [00:00<?, ?it/s]\rContextual batches:  12%|█▎        | 2/16 [00:00<00:01, 10.14it/s]\rContextual batches:  25%|██▌       | 4/16 [00:00<00:01, 10.83it/s]\rContextual batches:  38%|███▊      | 6/16 [00:00<00:00, 10.92it/s]\rContextual batches:  50%|█████     | 8/16 [00:00<00:00, 10.45it/s]\rContextual batches:  62%|██████▎   | 10/16 [00:00<00:00, 10.56it/s]\rContextual batches:  75%|███████▌  | 12/16 [00:01<00:00, 10.84it/s]\rContextual batches:  88%|████████▊ | 14/16 [00:01<00:00, 11.53it/s]\rContextual batches: 100%|██████████| 16/16 [00:01<00:00, 12.38it/s]\rContextual batches: 100%|██████████| 16/16 [00:01<00:00, 11.38it/s]\n\rContextual batches:   0%|          | 0/16 [00:00<?, ?it/s]\rContextual batches:  12%|█▎        | 2/16 [00:00<00:01, 12.80it/s]\rContextual batches:  25%|██▌       | 4/16 [00:00<00:00, 12.92it/s]\rContextual batches:  38%|███▊      | 6/16 [00:00<00:00, 12.89it/s]\rContextual batches:  50%|█████     | 8/16 [00:00<00:00, 13.20it/s]\rContextual batches:  62%|██████▎   | 10/16 [00:00<00:00, 13.59it/s]\rContextual batches:  75%|███████▌  | 12/16 [00:00<00:00, 14.21it/s]\rContextual batches:  88%|████████▊ | 14/16 [00:01<00:00, 14.53it/s]\rContextual batches: 100%|██████████| 16/16 [00:01<00:00, 15.78it/s]\rContextual batches: 100%|██████████| 16/16 [00:01<00:00, 14.36it/s]\n\rContextual batches:   0%|          | 0/16 [00:00<?, ?it/s]\rContextual batches:  12%|█▎        | 2/16 [00:00<00:00, 16.06it/s]\rContextual batches:  25%|██▌       | 4/16 [00:00<00:00, 17.09it/s]\rContextual batches:  38%|███▊      | 6/16 [00:00<00:00, 17.08it/s]\rContextual batches:  50%|█████     | 8/16 [00:00<00:00, 16.64it/s]\rContextual batches:  62%|██████▎   | 10/16 [00:00<00:00, 16.11it/s]\rContextual batches:  75%|███████▌  | 12/16 [00:00<00:00, 15.67it/s]\rContextual batches:  88%|████████▊ | 14/16 [00:00<00:00, 16.27it/s]\rContextual batches: 100%|██████████| 16/16 [00:00<00:00, 16.77it/s]\n\rContextual batches:   0%|          | 0/16 [00:00<?, ?it/s]\rContextual batches:  12%|█▎        | 2/16 [00:00<00:01, 13.32it/s]\rContextual batches:  25%|██▌       | 4/16 [00:00<00:00, 13.12it/s]\rContextual batches:  38%|███▊      | 6/16 [00:00<00:00, 13.07it/s]\rContextual batches:  50%|█████     | 8/16 [00:00<00:00, 13.63it/s]\rContextual batches:  62%|██████▎   | 10/16 [00:00<00:00, 13.83it/s]\rContextual batches:  75%|███████▌  | 12/16 [00:00<00:00, 14.61it/s]\rContextual batches:  88%|████████▊ | 14/16 [00:00<00:00, 14.89it/s]\rContextual batches: 100%|██████████| 16/16 [00:01<00:00, 15.70it/s]\rContextual batches: 100%|██████████| 16/16 [00:01<00:00, 14.55it/s]\n\rContextual batches:   0%|          | 0/16 [00:00<?, ?it/s]\rContextual batches:  12%|█▎        | 2/16 [00:00<00:01,  9.27it/s]\rContextual batches:  25%|██▌       | 4/16 [00:00<00:01, 10.10it/s]\rContextual batches:  38%|███▊      | 6/16 [00:00<00:01,  9.81it/s]\rContextual batches:  50%|█████     | 8/16 [00:00<00:00, 10.20it/s]\rContextual batches:  62%|██████▎   | 10/16 [00:00<00:00, 10.97it/s]\rContextual batches:  75%|███████▌  | 12/16 [00:01<00:00, 10.91it/s]\rContextual batches:  88%|████████▊ | 14/16 [00:01<00:00, 11.22it/s]\rContextual batches: 100%|██████████| 16/16 [00:01<00:00, 11.61it/s]\rContextual batches: 100%|██████████| 16/16 [00:01<00:00, 10.91it/s]\n\rContextual batches:   0%|          | 0/16 [00:00<?, ?it/s]\rContextual batches:  12%|█▎        | 2/16 [00:00<00:00, 14.10it/s]\rContextual batches:  25%|██▌       | 4/16 [00:00<00:00, 14.27it/s]\rContextual batches:  38%|███▊      | 6/16 [00:00<00:00, 15.03it/s]\rContextual batches:  50%|█████     | 8/16 [00:00<00:00, 15.11it/s]\rContextual batches:  62%|██████▎   | 10/16 [00:00<00:00, 15.69it/s]\rContextual batches:  75%|███████▌  | 12/16 [00:00<00:00, 15.89it/s]\rContextual batches:  88%|████████▊ | 14/16 [00:00<00:00, 16.18it/s]\rContextual batches: 100%|██████████| 16/16 [00:00<00:00, 16.30it/s]\n\rContextual batches:   0%|          | 0/16 [00:00<?, ?it/s]\rContextual batches:  12%|█▎        | 2/16 [00:00<00:00, 14.11it/s]\rContextual batches:  25%|██▌       | 4/16 [00:00<00:00, 14.22it/s]\rContextual batches:  38%|███▊      | 6/16 [00:00<00:00, 14.47it/s]\rContextual batches:  50%|█████     | 8/16 [00:00<00:00, 15.02it/s]\rContextual batches:  62%|██████▎   | 10/16 [00:00<00:00, 15.00it/s]\rContextual batches:  75%|███████▌  | 12/16 [00:00<00:00, 15.58it/s]\rContextual batches:  88%|████████▊ | 14/16 [00:00<00:00, 15.55it/s]\rContextual batches: 100%|██████████| 16/16 [00:01<00:00, 16.41it/s]\rContextual batches: 100%|██████████| 16/16 [00:01<00:00, 15.51it/s]\n2026-02-15 19:47:08,119 | INFO | Experiments completed\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_126","type":"reasoning","text":"**Planning result comparison script**\n\nI'm planning to implement a Python script in `src/validate_results.py` to compare metrics from two runs by checking key values (ignoring timestamps) and assessing if they match or are close."}}
{"type":"item.started","item":{"id":"item_127","type":"command_execution","command":"/bin/bash -lc \"python - << 'PY'\nimport json\nimport math\n\ndef load(path):\n    with open(path) as f:\n        return json.load(f)\n\nr1 = load('results/metrics_run1.json')\nr2 = load('results/metrics.json')\n\n# Compare key numeric fields (ignore timestamp)\nfields = ['dev_threshold','dev_accuracy','crosslingual_accuracy']\nprint('Comparison:')\nfor f in fields:\n    v1, v2 = r1[f], r2[f]\n    same = abs(v1 - v2) < 1e-6\n    print(f, v1, v2, 'same' if same else 'DIFF')\n\n# Compare stats t-tests\nfor k in ['contextual_ttest','contextual_mwu','static_polysemy_ttest']:\n    if k in r1['stats'] and k in r2['stats']:\n        v1 = r1['stats'][k]\n        v2 = r2['stats'][k]\n        print(k, v1, v2)\nPY\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_127","type":"command_execution","command":"/bin/bash -lc \"python - << 'PY'\nimport json\nimport math\n\ndef load(path):\n    with open(path) as f:\n        return json.load(f)\n\nr1 = load('results/metrics_run1.json')\nr2 = load('results/metrics.json')\n\n# Compare key numeric fields (ignore timestamp)\nfields = ['dev_threshold','dev_accuracy','crosslingual_accuracy']\nprint('Comparison:')\nfor f in fields:\n    v1, v2 = r1[f], r2[f]\n    same = abs(v1 - v2) < 1e-6\n    print(f, v1, v2, 'same' if same else 'DIFF')\n\n# Compare stats t-tests\nfor k in ['contextual_ttest','contextual_mwu','static_polysemy_ttest']:\n    if k in r1['stats'] and k in r2['stats']:\n        v1 = r1['stats'][k]\n        v2 = r2['stats'][k]\n        print(k, v1, v2)\nPY\"","aggregated_output":"Comparison:\ndev_threshold 0.9750000000000001 0.9750000000000001 same\ndev_accuracy 0.503 0.503 same\ncrosslingual_accuracy 0.53 0.53 same\ncontextual_ttest {'t': 14.56593457925549, 'p': 7.56382243383649e-47} {'t': 14.56593457925549, 'p': 7.56382243383649e-47}\ncontextual_mwu {'u': 2541088.5, 'p': 1.146819131428751e-49} {'u': 2541088.5, 'p': 1.146819131428751e-49}\nstatic_polysemy_ttest {'t': -1.0760422858818712, 'p': 0.2819559573838215} {'t': -1.0760422858818712, 'p': 0.2819559573838215}\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_128","type":"reasoning","text":"**Planning to re-run analysis for updated summaries**"}}
{"type":"item.started","item":{"id":"item_129","type":"command_execution","command":"/bin/bash -lc 'source .venv/bin/activate && python src/analyze_results.py'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_129","type":"command_execution","command":"/bin/bash -lc 'source .venv/bin/activate && python src/analyze_results.py'","aggregated_output":"","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_130","type":"agent_message","text":"**Summary**\n- Completed the full research cycle with XLM-R on MCL-WiC (cross-lingual) and MUSE dictionaries, including reproducibility rerun and validation.\n- Implemented experiments and analysis scripts in `src/run_experiments.py`, `src/data_quality.py`, `src/analyze_results.py`.\n- Produced final documentation in `REPORT.md` and `README.md`, with plots in `figures/` and metrics/tables in `results/`.\n\n**Key Results**\n- Static similarity: translation vs mismatch mean cosine `0.5131` vs `0.3747` (Cohen’s d ≈ `1.03`).\n- Contextual similarity: T vs F mean cosine `0.9847` vs `0.9822` (Welch t-test p `7.56e-47`, d ≈ `0.46`).\n- Cross-lingual WiC accuracy with dev-tuned threshold: `0.53` (slightly above chance).\n- Polysemy effect on static similarity: negligible (Cohen’s d ≈ `-0.03`, p `0.282`).\n\n**Files**\n- Planning: `planning.md`\n- Main experiment: `src/run_experiments.py`\n- Data checks: `src/data_quality.py`\n- Analysis summaries: `src/analyze_results.py`\n- Report: `REPORT.md`\n- README: `README.md`\n- Results: `results/metrics.json`, `results/*.csv`, `results/data_quality.json`\n- Figures: `figures/*.png`\n\n**Validation**\n- Re-ran `src/run_experiments.py` and compared `results/metrics.json` to `results/metrics_run1.json`; key metrics matched exactly.\n- Re-ran `src/analyze_results.py` to refresh summary tables after reproducibility pass.\n\n**Tests Run**\n- `python src/run_experiments.py` (twice)\n- `python src/data_quality.py`\n- `python src/analyze_results.py`\n\n**Notes**\n- `uv add` failed due to Hatchling editable build config; dependencies were installed via `uv pip install` and captured in `requirements.txt`.\n\n**Next Steps**\n1. Swap the static baseline to fastText or aligned MUSE vectors to isolate model-token embedding artifacts.\n2. Add XL-WiC evaluation to verify whether the same T vs F separation holds across a second benchmark."}}
{"type":"turn.completed","usage":{"input_tokens":3949164,"cached_input_tokens":3736448,"output_tokens":21063}}
